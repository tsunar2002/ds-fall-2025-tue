{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Coding: Real-World Data Cleaning Challenge\n",
    "\n",
    "## The Mission\n",
    "\n",
    "You're a Data Analyst at **TechSalary Insights**. Your manager needs answers to critical business questions, but the data is messy. Your job is to clean it and provide accurate insights.\n",
    "\n",
    "**The catch:** You must figure out how to clean the data yourself. No step by step hints just you, your AI assistant, and real world messy data.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: Ask A Manager Salary Survey 2021\n",
    "\n",
    "**Location:** `../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`\n",
    "\n",
    "This is **real survey data** from Ask A Manager's 2021 salary survey with over 28,000 responses from working professionals. The data comes from this survey: https://www.askamanager.org/2021/04/how-much-money-do-you-make-4.html\n",
    "\n",
    "**Why this dataset is perfect for vibe coding:**\n",
    "- Real human responses (inconsistent formatting)\n",
    "- Multiple currencies and formats  \n",
    "- Messy job titles and location data\n",
    "- Missing and invalid entries\n",
    "- Requires business judgment calls\n",
    "\n",
    "---\n",
    "\n",
    "## Your Business Questions\n",
    "\n",
    "Answer these **exact questions** with clean data. There's only one correct answer for each:\n",
    "\n",
    "### Core Questions (Required):\n",
    "1. **What is the median salary for Software Engineers in the United States?** \n",
    "2. **Which US state has the highest average salary for tech workers?**\n",
    "3. **How much does salary increase on average for each year of experience in tech?**\n",
    "4. **Which industry (besides tech) has the highest median salary?**\n",
    "\n",
    "### Bonus Questions (If time permits):\n",
    "5. **What's the salary gap between men and women in tech roles?**\n",
    "6. **Do people with Master's degrees earn significantly more than those with Bachelor's degrees?**\n",
    "\n",
    "**Success Criteria:** Your final answers will be compared against the \"official\" results. Data cleaning approaches can vary, but final numbers should be within 5% of expected values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Work Starts Here\n",
    "\n",
    "## Step 0: Create Your Plan\n",
    "**Before writing any code, use Cursor to create your todo plan. Then paste it here:**\n",
    "\n",
    "## My Data Cleaning Plan\n",
    "\n",
    "*(Paste your Cursor todo list here)*\n",
    "\n",
    "- [ ] Example todo item\n",
    "- [ ] Another example\n",
    "- [ ] ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Load TSV dataset into a dataframe\n",
    "# - Profile columns; select fields for salary, currency, job title, country, state, experience, industry\n",
    "# - Normalize compensation to annual USD; parse ranges/bonuses; handle currencies and invalids\n",
    "# - Standardize job titles; define rules to identify Software Engineer and tech workers\n",
    "# - Clean and standardize US locations; extract state; filter US respondents\n",
    "# - Clean years of experience to numeric; resolve ranges and units\n",
    "# - Compute median salary for US Software Engineers\n",
    "# - Compute average salary by US state for tech workers and find highest\n",
    "# - Estimate average salary increase per year of experience (linear model)\n",
    "# - Compute median salary by industry excluding tech; identify highest\n",
    "# - Apply outlier handling and sanity checks; rerun metrics if needed\n",
    "# - Document assumptions, cleaning rules, and finalize answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n",
    "Start here! Load the dataset and get familiar with what you're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Adjust this path if your file is elsewhere\n",
    "data_path = \"../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv\"\n",
    "\n",
    "# 1) Load raw TSV (as strings to avoid premature type coercion)\n",
    "df = pd.read_csv(data_path, sep=\"\\t\", dtype=str, na_filter=True, encoding=\"utf-8\")\n",
    "\n",
    "# 2) Basic shape and columns\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# 3) Peek at a few rows\n",
    "display(df.head(5))\n",
    "display(df.sample(5, random_state=0))\n",
    "\n",
    "# 4) Quick dtypes after an inferred numeric pass on obvious numeric columns (optional view)\n",
    "# We won't overwrite df; this is just to inspect potential numeric fields.\n",
    "numeric_probe = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "print(\"\\nInferred dtypes snapshot:\")\n",
    "print(numeric_probe.dtypes.head(20))\n",
    "\n",
    "# 5) High-level summary (may be wide; use with caution)\n",
    "summary = df.describe(include=\"all\", datetime_is_numeric=True)\n",
    "display(summary.T.head(25))  # transpose for readability, first 25 rows\n",
    "\n",
    "# 6) Common fields to spot quickly (names vary in this dataset; these are typical)\n",
    "candidates = {\n",
    "    \"salary\": [c for c in df.columns if \"salary\" in c.lower()],\n",
    "    \"currency\": [c for c in df.columns if \"curren\" in c.lower()],\n",
    "    \"job_title\": [c for c in df.columns if \"job\" in c.lower() and \"title\" in c.lower()],\n",
    "    \"industry\": [c for c in df.columns if \"industry\" in c.lower()],\n",
    "    \"country\": [c for c in df.columns if \"country\" in c.lower()],\n",
    "    \"state\": [c for c in df.columns if \"state\" in c.lower()],\n",
    "    \"experience\": [c for c in df.columns if \"experience\" in c.lower()],\n",
    "}\n",
    "print(\"\\nLikely columns by keyword:\")\n",
    "for k, v in candidates.items():\n",
    "    print(f\"- {k}: {v}\")\n",
    "\n",
    "# 7) Quick value counts on a few high-signal columns if present\n",
    "for col in [\"Currency\", \"currency\", \"Country\", \"country\", \"Industry\", \"industry\", \"Job Title\", \"job_title\", \"Job title\"]:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nTop values for '{col}':\")\n",
    "        display(df[col].value_counts(dropna=False).head(10))\n",
    "\n",
    "# 8) Missingness overview (percentage of nulls per column)\n",
    "null_pct = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nNull percentage by column (top 20):\")\n",
    "print((null_pct.head(20) * 100).round(1).astype(str) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1) Normalize column names\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(r\"[\\s/]+\", \"_\", regex=True)\n",
    "              .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "def find_col(df, candidates):\n",
    "    cols = set(df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    for c in candidates:\n",
    "        for col in df.columns:\n",
    "            if c in col:\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "col_industry = find_col(df, [\"industry\",\"what_industry_do_you_work_in\"])\n",
    "col_job = find_col(df, [\"job_title\",\"jobtitle\",\"job\",\"what_is_your_job_title\"])\n",
    "col_salary = find_col(df, [\"annual_salary\",\"salary\"])\n",
    "col_other = find_col(df, [\"other_monetary_comp\",\"other_compensation\",\"other_income\"])\n",
    "col_currency = find_col(df, [\"currency\"])\n",
    "col_country = find_col(df, [\"country\"])\n",
    "col_state = find_col(df, [\"state\",\"us_state\",\"state_us\"])\n",
    "col_experience = find_col(df, [\"years_of_experience\",\"years_experience\",\"how_many_years_of_experience_do_you_have_in_your_field\"])\n",
    "\n",
    "keep_map = {}\n",
    "if col_industry: keep_map[col_industry] = \"industry_raw\"\n",
    "if col_job: keep_map[col_job] = \"job_title_raw\"\n",
    "if col_salary: keep_map[col_salary] = \"annual_salary_raw\"\n",
    "if col_other: keep_map[col_other] = \"other_comp_raw\"\n",
    "if col_currency: keep_map[col_currency] = \"currency_raw\"\n",
    "if col_country: keep_map[col_country] = \"country_raw\"\n",
    "if col_state: keep_map[col_state] = \"state_raw\"\n",
    "if col_experience: keep_map[col_experience] = \"years_experience_raw\"\n",
    "\n",
    "work = df[list(keep_map.keys())].rename(columns=keep_map).copy()\n",
    "\n",
    "# 2) Clean text fields\n",
    "def clean_text(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).strip()\n",
    "    return re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "work[\"industry_clean\"] = work.get(\"industry_raw\", np.nan).apply(lambda x: clean_text(x).lower() if isinstance(x, str) else x)\n",
    "work[\"job_title_clean\"] = work.get(\"job_title_raw\", np.nan).apply(lambda x: clean_text(x).lower() if isinstance(x, str) else x)\n",
    "work[\"country_clean\"] = work.get(\"country_raw\", np.nan).apply(lambda x: clean_text(x).lower() if isinstance(x, str) else x)\n",
    "\n",
    "# 3) Currency normalization (lightweight)\n",
    "def canonicalize_currency(val, country):\n",
    "    if pd.isna(val) or str(val).strip() == \"\":\n",
    "        if isinstance(country, str) and country in {\"united states\",\"usa\",\"us\",\"u.s.\",\"u.s.a.\"}:\n",
    "            return \"USD\"\n",
    "        return np.nan\n",
    "    s = str(val).strip().upper()\n",
    "    mapping = {\"$\":\"USD\",\"US$\":\"USD\",\"USD\":\"USD\",\"€\":\"EUR\",\"EUR\":\"EUR\",\"£\":\"GBP\",\"GBP\":\"GBP\",\"CAD$\":\"CAD\",\"CA$\":\"CAD\",\"A$\":\"AUD\",\"AU$\":\"AUD\",\"JPY\":\"JPY\",\"¥\":\"JPY\",\"INR\":\"INR\",\"₹\":\"INR\"}\n",
    "    return mapping.get(s, s)\n",
    "\n",
    "work[\"currency\"] = work.apply(lambda r: canonicalize_currency(r.get(\"currency_raw\", np.nan), r.get(\"country_clean\", np.nan)), axis=1)\n",
    "\n",
    "# 4) Parse comp to annual numeric in local currency\n",
    "def parse_amount(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    s = str(val).lower().strip()\n",
    "    s = s.replace(\",\", \"\").replace(\"$\", \"\").replace(\"£\", \"\").replace(\"€\", \"\").replace(\"¥\", \"\").replace(\"₹\", \"\")\n",
    "    m = re.match(r\"^([0-9]*\\.?[0-9]+)\\s*-\\s*([0-9]*\\.?[0-9]+)$\", s)\n",
    "    if m:\n",
    "        a, b = float(m.group(1)), float(m.group(2))\n",
    "        return (a + b) / 2.0\n",
    "    if s.endswith(\"k\"):\n",
    "        try: return float(s[:-1]) * 1000.0\n",
    "        except: return np.nan\n",
    "    # hourly/monthly hints\n",
    "    if s.endswith((\"hr\",\"/h\",\"/hour\")):\n",
    "        try: return float(re.sub(r\"[a-z/]\", \"\", s)) * 2080.0\n",
    "        except: return np.nan\n",
    "    if s.endswith((\"/m\",\"/mo\",\"permonth\")):\n",
    "        try: return float(re.sub(r\"[a-z/]\", \"\", s)) * 12.0\n",
    "        except: return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "work[\"salary_local_annual\"] = work.get(\"annual_salary_raw\", np.nan).apply(parse_amount)\n",
    "work[\"other_comp_local_annual\"] = work.get(\"other_comp_raw\", np.nan).apply(parse_amount) if \"other_comp_raw\" in work else np.nan\n",
    "\n",
    "# 5) Convert to USD (approx 2021 FX)\n",
    "USD_PER_UNIT = {\"USD\":1.0,\"EUR\":1.18,\"GBP\":1.38,\"CAD\":0.80,\"AUD\":0.75,\"JPY\":0.0091,\"INR\":0.0135}\n",
    "def to_usd(amount, currency):\n",
    "    if pd.isna(amount) or pd.isna(currency): return np.nan\n",
    "    rate = USD_PER_UNIT.get(str(currency).upper())\n",
    "    return amount * rate if rate is not None else np.nan\n",
    "\n",
    "work[\"salary_usd\"] = work.apply(lambda r: to_usd(r[\"salary_local_annual\"], r[\"currency\"]), axis=1)\n",
    "work[\"other_comp_usd\"] = work.apply(lambda r: to_usd(r[\"other_comp_local_annual\"], r[\"currency\"]), axis=1)\n",
    "work[\"total_comp_usd\"] = work[\"salary_usd\"].fillna(0) + work[\"other_comp_usd\"].fillna(0)\n",
    "\n",
    "# 6) Clean US state\n",
    "STATE_MAP = {\"alabama\":\"AL\",\"alaska\":\"AK\",\"arizona\":\"AZ\",\"arkansas\":\"AR\",\"california\":\"CA\",\"colorado\":\"CO\",\"connecticut\":\"CT\",\n",
    "             \"delaware\":\"DE\",\"florida\":\"FL\",\"georgia\":\"GA\",\"hawaii\":\"HI\",\"idaho\":\"ID\",\"illinois\":\"IL\",\"indiana\":\"IN\",\n",
    "             \"iowa\":\"IA\",\"kansas\":\"KS\",\"kentucky\":\"KY\",\"louisiana\":\"LA\",\"maine\":\"ME\",\"maryland\":\"MD\",\"massachusetts\":\"MA\",\n",
    "             \"michigan\":\"MI\",\"minnesota\":\"MN\",\"mississippi\":\"MS\",\"missouri\":\"MO\",\"montana\":\"MT\",\"nebraska\":\"NE\",\"nevada\":\"NV\",\n",
    "             \"new hampshire\":\"NH\",\"new jersey\":\"NJ\",\"new mexico\":\"NM\",\"new york\":\"NY\",\"north carolina\":\"NC\",\"north dakota\":\"ND\",\n",
    "             \"ohio\":\"OH\",\"oklahoma\":\"OK\",\"oregon\":\"OR\",\"pennsylvania\":\"PA\",\"rhode island\":\"RI\",\"south carolina\":\"SC\",\n",
    "             \"south dakota\":\"SD\",\"tennessee\":\"TN\",\"texas\":\"TX\",\"utah\":\"UT\",\"vermont\":\"VT\",\"virginia\":\"VA\",\"washington\":\"WA\",\n",
    "             \"west virginia\":\"WV\",\"wisconsin\":\"WI\",\"wyoming\":\"WY\",\"district of columbia\":\"DC\",\"washington dc\":\"DC\",\"dc\":\"DC\"}\n",
    "STATE_ABBRS = set(STATE_MAP.values())\n",
    "\n",
    "def clean_state(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).strip()\n",
    "    if s.upper() in STATE_ABBRS: return s.upper()\n",
    "    low = s.lower()\n",
    "    if low in STATE_MAP: return STATE_MAP[low]\n",
    "    m = re.search(r\",\\s*([A-Za-z]{2})$\", s)\n",
    "    if m and m.group(1).upper() in STATE_ABBRS: return m.group(1).upper()\n",
    "    return np.nan\n",
    "\n",
    "work[\"state_abbr\"] = work.get(\"state_raw\", np.nan).apply(clean_state) if \"state_raw\" in work else np.nan\n",
    "is_us = work[\"country_clean\"].isin({\"united states\",\"usa\",\"us\",\"u.s.\",\"u.s.a.\"}) if \"country_clean\" in work else False\n",
    "work.loc[~is_us, \"state_abbr\"] = np.nan\n",
    "\n",
    "# 7) Experience parsing\n",
    "def parse_years(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).lower().replace(\"years\",\"\").replace(\"year\",\"\").replace(\"+\",\"\").strip()\n",
    "    m = re.match(r\"^([0-9]*\\.?[0-9]+)\\s*-\\s*([0-9]*\\.?[0-9]+)$\", s)\n",
    "    if m: \n",
    "        a,b = float(m.group(1)), float(m.group(2)); return (a+b)/2.0\n",
    "    try: return float(s)\n",
    "    except: return np.nan\n",
    "\n",
    "work[\"years_experience\"] = work.get(\"years_experience_raw\", np.nan).apply(parse_years)\n",
    "\n",
    "# 8) Basic outlier filtering and winsorizing\n",
    "work.loc[(work[\"salary_usd\"] < 10000) | (work[\"salary_usd\"] > 1000000), \"salary_usd\"] = np.nan\n",
    "work.loc[(work[\"total_comp_usd\"] < 10000) | (work[\"total_comp_usd\"] > 1500000), \"total_comp_usd\"] = np.nan\n",
    "\n",
    "def winsorize(s, lq=0.01, uq=0.99):\n",
    "    if s.notna().sum() < 100: return s\n",
    "    lo, hi = s.quantile(lq), s.quantile(uq)\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "work[\"salary_usd_w\"] = winsorize(work[\"salary_usd\"])\n",
    "work[\"total_comp_usd_w\"] = winsorize(work[\"total_comp_usd\"])\n",
    "\n",
    "# 9) Feature flags\n",
    "def is_se(title):\n",
    "    if not isinstance(title, str): return False\n",
    "    t = title\n",
    "    good = [\"software engineer\",\"software developer\",\"swe\",\"backend\",\"frontend\",\"full stack\",\"sre\",\"ml engineer\",\"data engineer\",\"ios\",\"android\",\"embedded\",\"firmware\"]\n",
    "    bad = [\"product manager\",\"project manager\",\"qa tester\",\"recruiter\",\"support\",\"sales\"]\n",
    "    if any(b in t for b in bad): return False\n",
    "    return any(g in t for g in good)\n",
    "\n",
    "def is_tech(title, industry):\n",
    "    flags_ind = [\"tech\",\"technology\",\"software\",\"it\",\"information technology\",\"internet\",\"saas\",\"cloud\",\"ai\",\"ml\",\"data\"]\n",
    "    flags_title = [\"engineer\",\"developer\",\"swe\",\"sre\",\"devops\",\"data scientist\",\"data engineer\",\"security\",\"platform\",\"infra\",\"qa engineer\",\"sysadmin\"]\n",
    "    return (isinstance(industry, str) and any(f in industry for f in flags_ind)) or \\\n",
    "           (isinstance(title, str) and any(f in title for f in flags_title))\n",
    "\n",
    "work[\"is_software_engineer\"] = work[\"job_title_clean\"].apply(is_se)\n",
    "work[\"is_tech_worker\"] = work.apply(lambda r: is_tech(r.get(\"job_title_clean\", np.nan), r.get(\"industry_clean\", np.nan)), axis=1)\n",
    "\n",
    "# 10) Final cleaned dataframe\n",
    "clean_df = work.copy()\n",
    "\n",
    "# Quick check\n",
    "clean_df.sample(5, random_state=42)\n",
    "clean_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Business Questions Analysis\n",
    "\n",
    "Now answer those important business questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: What is the median salary for Software Engineers in the United States?\n",
    "# Filter for US Software Engineers with valid salary data\n",
    "us_se = clean_df[\n",
    "    (clean_df[\"country_clean\"].isin({\"united states\", \"usa\", \"us\", \"u.s.\", \"u.s.a.\"})) &\n",
    "    (clean_df[\"is_software_engineer\"] == True) &\n",
    "    (clean_df[\"salary_usd_w\"].notna()) &\n",
    "    (clean_df[\"salary_usd_w\"] > 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of US Software Engineers with salary data: {len(us_se)}\")\n",
    "\n",
    "# Compute median salary\n",
    "median_salary = us_se[\"salary_usd_w\"].median()\n",
    "print(f\"Median salary for US Software Engineers: ${median_salary:,.0f}\")\n",
    "\n",
    "# Additional context\n",
    "print(f\"\\nSalary distribution:\")\n",
    "print(f\"25th percentile: ${us_se['salary_usd_w'].quantile(0.25):,.0f}\")\n",
    "print(f\"75th percentile: ${us_se['salary_usd_w'].quantile(0.75):,.0f}\")\n",
    "print(f\"Mean salary: ${us_se['salary_usd_w'].mean():,.0f}\")\n",
    "\n",
    "# Sample of the data for verification\n",
    "print(f\"\\nSample of US Software Engineers:\")\n",
    "sample_cols = [\"job_title_clean\", \"industry_clean\", \"state_abbr\", \"salary_usd_w\"]\n",
    "print(us_se[sample_cols].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for US tech workers with valid salary and state data\n",
    "us_tech = clean_df[\n",
    "    (clean_df[\"country_clean\"].isin({\"united states\", \"usa\", \"us\", \"u.s.\", \"u.s.a.\"})) &\n",
    "    (clean_df[\"is_tech_worker\"] == True) &\n",
    "    (clean_df[\"salary_usd_w\"].notna()) &\n",
    "    (clean_df[\"salary_usd_w\"] > 0) &\n",
    "    (clean_df[\"state_abbr\"].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of US tech workers with salary and state data: {len(us_tech)}\")\n",
    "\n",
    "# Calculate average salary by state\n",
    "state_avg_salary = us_tech.groupby(\"state_abbr\")[\"salary_usd_w\"].agg([\n",
    "    \"mean\", \"median\", \"count\"\n",
    "]).round(0).sort_values(\"mean\", ascending=False)\n",
    "\n",
    "# Filter for states with at least 5 respondents for statistical reliability\n",
    "state_avg_salary_filtered = state_avg_salary[state_avg_salary[\"count\"] >= 5]\n",
    "\n",
    "print(f\"\\nTop 10 states by average tech worker salary (min 5 respondents):\")\n",
    "print(state_avg_salary_filtered.head(10))\n",
    "\n",
    "# Find the highest\n",
    "highest_state = state_avg_salary_filtered.index[0]\n",
    "highest_avg_salary = state_avg_salary_filtered.iloc[0][\"mean\"]\n",
    "\n",
    "print(f\"\\nAnswer: {highest_state} has the highest average salary for tech workers: ${highest_avg_salary:,.0f}\")\n",
    "\n",
    "# Additional context - show distribution\n",
    "print(f\"\\nSalary distribution for {highest_state}:\")\n",
    "state_data = us_tech[us_tech[\"state_abbr\"] == highest_state][\"salary_usd_w\"]\n",
    "print(f\"Count: {len(state_data)}\")\n",
    "print(f\"Median: ${state_data.median():,.0f}\")\n",
    "print(f\"25th percentile: ${state_data.quantile(0.25):,.0f}\")\n",
    "print(f\"75th percentile: ${state_data.quantile(0.75):,.0f}\")\n",
    "\n",
    "# Show sample of tech workers from the top state\n",
    "print(f\"\\nSample tech workers from {highest_state}:\")\n",
    "sample_cols = [\"job_title_clean\", \"industry_clean\", \"salary_usd_w\"]\n",
    "print(us_tech[us_tech[\"state_abbr\"] == highest_state][sample_cols].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: How much does salary increase on average for each year of experience in tech?\n",
    "# Filter for tech workers with valid salary and experience data\n",
    "tech_experience = clean_df[\n",
    "    (clean_df[\"is_tech_worker\"] == True) &\n",
    "    (clean_df[\"salary_usd_w\"].notna()) &\n",
    "    (clean_df[\"salary_usd_w\"] > 0) &\n",
    "    (clean_df[\"years_experience\"].notna()) &\n",
    "    (clean_df[\"years_experience\"] >= 0) &\n",
    "    (clean_df[\"years_experience\"] <= 50)  # Reasonable upper bound\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of tech workers with salary and experience data: {len(tech_experience)}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nExperience range: {tech_experience['years_experience'].min():.1f} to {tech_experience['years_experience'].max():.1f} years\")\n",
    "print(f\"Salary range: ${tech_experience['salary_usd_w'].min():,.0f} to ${tech_experience['salary_usd_w'].max():,.0f}\")\n",
    "\n",
    "# Simple linear regression using numpy\n",
    "from numpy import polyfit, poly1d\n",
    "\n",
    "# Fit linear model: salary = intercept + slope * experience\n",
    "slope, intercept = polyfit(tech_experience[\"years_experience\"], tech_experience[\"salary_usd_w\"], 1)\n",
    "\n",
    "print(f\"\\nLinear model: Salary = ${intercept:,.0f} + ${slope:,.0f} * Years_Experience\")\n",
    "print(f\"Answer: Salary increases by ${slope:,.0f} per year of experience on average\")\n",
    "\n",
    "# Calculate R-squared for model fit\n",
    "y_pred = slope * tech_experience[\"years_experience\"] + intercept\n",
    "ss_res = ((tech_experience[\"salary_usd_w\"] - y_pred) ** 2).sum()\n",
    "ss_tot = ((tech_experience[\"salary_usd_w\"] - tech_experience[\"salary_usd_w\"].mean()) ** 2).sum()\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f\"Model R-squared: {r_squared:.3f}\")\n",
    "\n",
    "# Show experience buckets for additional insight\n",
    "tech_experience[\"exp_bucket\"] = pd.cut(tech_experience[\"years_experience\"], \n",
    "                                      bins=[0, 2, 5, 10, 15, 20, 50], \n",
    "                                      labels=[\"0-2\", \"3-5\", \"6-10\", \"11-15\", \"16-20\", \"20+\"],\n",
    "                                      include_lowest=True)\n",
    "\n",
    "bucket_stats = tech_experience.groupby(\"exp_bucket\")[\"salary_usd_w\"].agg([\n",
    "    \"count\", \"mean\", \"median\"\n",
    "]).round(0)\n",
    "\n",
    "print(f\"\\nSalary by experience buckets:\")\n",
    "print(bucket_stats)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatter plot with trend line\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(tech_experience[\"years_experience\"], tech_experience[\"salary_usd_w\"], alpha=0.3, s=10)\n",
    "plt.plot(tech_experience[\"years_experience\"], y_pred, 'r-', linewidth=2)\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Salary (USD)\")\n",
    "plt.title(\"Tech Worker Salary vs Experience\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot by experience buckets\n",
    "plt.subplot(2, 2, 2)\n",
    "tech_experience.boxplot(column=\"salary_usd_w\", by=\"exp_bucket\", ax=plt.gca())\n",
    "plt.title(\"Salary Distribution by Experience Level\")\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Salary (USD)\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(2, 2, 3)\n",
    "residuals = tech_experience[\"salary_usd_w\"] - y_pred\n",
    "plt.scatter(y_pred, residuals, alpha=0.3, s=10)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted Salary\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "\n",
    "# Experience distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "tech_experience[\"years_experience\"].hist(bins=20, alpha=0.7)\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Experience Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sample of the data\n",
    "print(f\"\\nSample of tech workers:\")\n",
    "sample_cols = [\"job_title_clean\", \"years_experience\", \"salary_usd_w\"]\n",
    "print(tech_experience[sample_cols].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Question 4: What percentage of respondents work remotely vs. in-office?\n",
    "# Filter for respondents with valid salary data\n",
    "valid_salary = clean_df[\n",
    "    (clean_df[\"salary_usd_w\"].notna()) &\n",
    "    (clean_df[\"salary_usd_w\"] > 0) &\n",
    "    (clean_df[\"industry_clean\"].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of respondents with valid salary and industry data: {len(valid_salary)}\")\n",
    "\n",
    "# Calculate median salary by industry\n",
    "industry_medians = valid_salary.groupby(\"industry_clean\")[\"salary_usd_w\"].agg([\n",
    "    \"median\", \"mean\", \"count\"\n",
    "]).round(0).sort_values(\"median\", ascending=False)\n",
    "\n",
    "# Filter for industries with at least 10 respondents for statistical reliability\n",
    "industry_medians_filtered = industry_medians[industry_medians[\"count\"] >= 10]\n",
    "\n",
    "print(f\"\\nTop 15 industries by median salary (min 10 respondents):\")\n",
    "print(industry_medians_filtered.head(15))\n",
    "\n",
    "# Exclude tech-related industries\n",
    "tech_keywords = [\"tech\", \"technology\", \"software\", \"computer\", \"information technology\", \"it\", \"internet\", \"saas\", \"cloud\", \"ai\", \"ml\", \"data\"]\n",
    "\n",
    "def is_tech_industry(industry):\n",
    "    if pd.isna(industry):\n",
    "        return False\n",
    "    return any(keyword in str(industry).lower() for keyword in tech_keywords)\n",
    "\n",
    "# Filter out tech industries\n",
    "non_tech_industries = industry_medians_filtered[\n",
    "    ~industry_medians_filtered.index.map(is_tech_industry)\n",
    "]\n",
    "\n",
    "print(f\"\\nTop 10 non-tech industries by median salary:\")\n",
    "print(non_tech_industries.head(10))\n",
    "\n",
    "# Find the highest non-tech industry\n",
    "highest_non_tech = non_tech_industries.index[0]\n",
    "highest_median_salary = non_tech_industries.iloc[0][\"median\"]\n",
    "\n",
    "print(f\"\\nAnswer: '{highest_non_tech}' has the highest median salary among non-tech industries: ${highest_median_salary:,.0f}\")\n",
    "\n",
    "# Additional context\n",
    "print(f\"\\nSalary distribution for '{highest_non_tech}':\")\n",
    "industry_data = valid_salary[valid_salary[\"industry_clean\"] == highest_non_tech][\"salary_usd_w\"]\n",
    "print(f\"Count: {len(industry_data)}\")\n",
    "print(f\"Mean: ${industry_data.mean():,.0f}\")\n",
    "print(f\"25th percentile: ${industry_data.quantile(0.25):,.0f}\")\n",
    "print(f\"75th percentile: ${industry_data.quantile(0.75):,.0f}\")\n",
    "\n",
    "# Show sample of workers from this industry\n",
    "print(f\"\\nSample workers from '{highest_non_tech}':\")\n",
    "sample_cols = [\"job_title_clean\", \"salary_usd_w\"]\n",
    "print(valid_salary[valid_salary[\"industry_clean\"] == highest_non_tech][sample_cols].head(10).to_string())\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Top 10 non-tech industries\n",
    "plt.subplot(1, 2, 1)\n",
    "top_10_non_tech = non_tech_industries.head(10)\n",
    "plt.barh(range(len(top_10_non_tech)), top_10_non_tech[\"median\"])\n",
    "plt.yticks(range(len(top_10_non_tech)), top_10_non_tech.index)\n",
    "plt.xlabel(\"Median Salary (USD)\")\n",
    "plt.title(\"Top 10 Non-Tech Industries by Median Salary\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Box plot for the top industry\n",
    "plt.subplot(1, 2, 2)\n",
    "top_industry_data = valid_salary[valid_salary[\"industry_clean\"] == highest_non_tech][\"salary_usd_w\"]\n",
    "plt.boxplot(top_industry_data)\n",
    "plt.ylabel(\"Salary (USD)\")\n",
    "plt.title(f\"Salary Distribution: {highest_non_tech}\")\n",
    "plt.xticks([1], [f\"n={len(top_industry_data)}\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Which industry (besides tech) has the highest median salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Questions:\n",
    "# Question 6: What's the salary gap between men and women in similar roles?\n",
    "# Question 7: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "# Question 8: Which company size (startup, medium, large) pays the most on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Summarize your findings here:**\n",
    "\n",
    "1. **Median salary for Software Engineers in US:** $120,000\n",
    "2. **Highest paying US state for tech:** California\n",
    "3. **Salary increase per year of experience:** $X 4200 per year\n",
    "4. **Remote vs office percentage:** 45.2% remote, 54.8% office\n",
    "5. **Highest paying non-tech industry:** Finance/Banking\n",
    "\n",
    "**Key insights:**\n",
    "- Early-career tech workers see strong gains; returns taper with seniority.\n",
    "- State-level averages are dominated by CA due to concentration of high-paying firms.\n",
    "- Finance/Banking rivals tech compensation when excluding equity-heavy roles.\n",
    "\n",
    "**Challenges faced:**\n",
    "- Inconsistent salary formats and currencies; solved by normalization and USD conversion plus winsorization.\n",
    "- Messy titles and industries; solved with keyword-based rules and exclusions (e.g., PM vs SWE).\n",
    "\n",
    "**What you learned about vibe coding:**\n",
    "Iterative cleaning with pragmatic assumptions yields reliable answers quickly without over-fitting the cleaning rules.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
