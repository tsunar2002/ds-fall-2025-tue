{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Coding: Real-World Data Cleaning Challenge\n",
    "\n",
    "## The Mission\n",
    "\n",
    "You're a Data Analyst at **TechSalary Insights**. Your manager needs answers to critical business questions, but the data is messy. Your job is to clean it and provide accurate insights.\n",
    "\n",
    "**The catch:** You must figure out how to clean the data yourself. No step by step hints just you, your AI assistant, and real world messy data.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: Ask A Manager Salary Survey 2021\n",
    "\n",
    "**Location:** `../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`\n",
    "\n",
    "This is **real survey data** from Ask A Manager's 2021 salary survey with over 28,000 responses from working professionals. The data comes from this survey: https://www.askamanager.org/2021/04/how-much-money-do-you-make-4.html\n",
    "\n",
    "**Why this dataset is perfect for vibe coding:**\n",
    "- Real human responses (inconsistent formatting)\n",
    "- Multiple currencies and formats  \n",
    "- Messy job titles and location data\n",
    "- Missing and invalid entries\n",
    "- Requires business judgment calls\n",
    "\n",
    "---\n",
    "\n",
    "## Your Business Questions\n",
    "\n",
    "Answer these **exact questions** with clean data. There's only one correct answer for each:\n",
    "\n",
    "### Core Questions (Required):\n",
    "1. **What is the median salary for Software Engineers in the United States?** \n",
    "2. **Which US state has the highest average salary for tech workers?**\n",
    "3. **How much does salary increase on average for each year of experience in tech?**\n",
    "4. **Which industry (besides tech) has the highest median salary?**\n",
    "\n",
    "### Bonus Questions (If time permits):\n",
    "5. **What's the salary gap between men and women in tech roles?**\n",
    "6. **Do people with Master's degrees earn significantly more than those with Bachelor's degrees?**\n",
    "\n",
    "**Success Criteria:** Your final answers will be compared against the \"official\" results. Data cleaning approaches can vary, but final numbers should be within 5% of expected values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Work Starts Here\n",
    "\n",
    "## Step 0: Create Your Plan\n",
    "**Before writing any code, use Cursor to create your todo plan. Then paste it here:**\n",
    "\n",
    "## My Data Cleaning Plan\n",
    "\n",
    "*(Paste your Cursor todo list here)*\n",
    "\n",
    "- [ ] Example todo item\n",
    "- [ ] Another example\n",
    "- [ ] ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n",
    "Start here! Load the dataset and get familiar with what you're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Week-02-Pandas-Part-2-and-DS-Overview/data/hw2data.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33mWeek-02-Pandas-Part-2-and-DS-Overview/data/hw2data.tsv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_raw = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m'\u001b[39m, df_raw.shape)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mColumns:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlist\u001b[39m(df_raw.columns))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Week-02-Pandas-Part-2-and-DS-Overview/data/hw2data.tsv'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "file_path = \"Week-02-Pandas-Part-2-and-DS-Overview/data/hw2data.tsv\"\n",
    "\n",
    "df_raw = pd.read_csv(file_path, sep='\\t')\n",
    "print('Shape:', df_raw.shape)\n",
    "print('Columns:', list(df_raw.columns))\n",
    "df_raw.head(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "\n",
    "salary_col = None\n",
    "for c in df.columns:\n",
    "    if 'salary' in c and 'hour' not in c and 'bonus' not in c:\n",
    "        salary_col = c\n",
    "        break\n",
    "\n",
    "currency_col = None\n",
    "for c in df.columns:\n",
    "    if 'currency' in c:\n",
    "        currency_col = c\n",
    "        break\n",
    "\n",
    "country_col = None\n",
    "for c in df.columns:\n",
    "    if 'country' in c:\n",
    "        country_col = c\n",
    "        break\n",
    "\n",
    "state_col = None\n",
    "for c in df.columns:\n",
    "    if c in ['state','us_state','state_territory'] or 'state' in c:\n",
    "        state_col = c\n",
    "        break\n",
    "\n",
    "job_title_col = None\n",
    "for c in df.columns:\n",
    "    if 'title' in c or 'role' in c:\n",
    "        job_title_col = c\n",
    "        break\n",
    "\n",
    "industry_col = None\n",
    "for c in df.columns:\n",
    "    if 'industry' in c:\n",
    "        industry_col = c\n",
    "        break\n",
    "\n",
    "experience_col = None\n",
    "for c in df.columns:\n",
    "    if 'years' in c and 'experience' in c:\n",
    "        experience_col = c\n",
    "        break\n",
    "\n",
    "remote_col = None\n",
    "for c in df.columns:\n",
    "    if 'remote' in c or 'work_location' in c or 'work_arrangement' in c:\n",
    "        remote_col = c\n",
    "        break\n",
    "\n",
    "\n",
    "if salary_col is not None:\n",
    "    s = df[salary_col].fillna('').astype(str)\n",
    "\n",
    "    is_range = s.str.contains('-')\n",
    "    s_range = s[is_range]\n",
    "    avg_vals = []\n",
    "    for val in s_range:\n",
    "        parts = val.split('-')\n",
    "        nums = []\n",
    "        for p in parts:\n",
    "            p_clean = ''.join(ch for ch in p if ch.isdigit() or ch == '.')\n",
    "            if p_clean != '':\n",
    "                try:\n",
    "                    nums.append(float(p_clean))\n",
    "                except:\n",
    "                    pass\n",
    "        if len(nums) == 2:\n",
    "            avg_vals.append((nums[0]+nums[1])/2.0)\n",
    "        else:\n",
    "            avg_vals.append(np.nan)\n",
    "    s.loc[is_range] = avg_vals\n",
    "    s = s.astype(str)\n",
    "    s = s.str.replace(',', '')\n",
    "    s = s.str.replace('$', '')\n",
    "    s = s.str.replace('USD', '', case=False)\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    df['salary_clean'] = s\n",
    "else:\n",
    "    df['salary_clean'] = np.nan\n",
    "\n",
    "\n",
    "df = df[(df['salary_clean'].notna()) & (df['salary_clean'] >= 10000) & (df['salary_clean'] <= 1000000)]\n",
    "\n",
    "\n",
    "if currency_col is not None:\n",
    "    cur = df[currency_col].fillna('').str.upper()\n",
    "    usd_mask = (cur == '') | (cur.str.contains('USD')) | (cur.str.contains('US DOLLAR')) | (cur == 'US$')\n",
    "    df = df[usd_mask]\n",
    "\n",
    "\n",
    "if country_col is not None:\n",
    "    cc = df[country_col].fillna('').str.strip().str.lower()\n",
    "    cc = cc.replace({'us':'united states','usa':'united states','united states of america':'united states'})\n",
    "    df['country_norm'] = cc\n",
    "else:\n",
    "    df['country_norm'] = np.nan\n",
    "\n",
    "\n",
    "df['is_us'] = df['country_norm'].fillna('').str.contains('united states')\n",
    "\n",
    "\n",
    "if state_col is not None:\n",
    "    df['state_usps'] = df[state_col].fillna('').astype(str).str.strip().str.upper()\n",
    "else:\n",
    "    df['state_usps'] = np.nan\n",
    "\n",
    "\n",
    "df['is_se'] = False\n",
    "if job_title_col is not None:\n",
    "    t = df[job_title_col].fillna('').str.lower()\n",
    "    df.loc[t.str.contains('software engineer') | t.str.contains('software developer') | t.str.contains(' swe '), 'is_se'] = True\n",
    "\n",
    "\n",
    "if industry_col is not None:\n",
    "    ind = df[industry_col].fillna('').str.lower()\n",
    "    df['industry_simple'] = ind\n",
    "    tech_mask = ind.str.contains('tech') | ind.str.contains('software') | ind.str.contains('information technology') | ind.str.contains('internet') | ind.str.contains('computer')\n",
    "    df['is_tech'] = tech_mask\n",
    "else:\n",
    "    df['industry_simple'] = ''\n",
    "    df['is_tech'] = False\n",
    "\n",
    "\n",
    "df['years_experience_clean'] = np.nan\n",
    "if experience_col is not None:\n",
    "    y = df[experience_col].fillna('').astype(str).str.lower()\n",
    "    y = y.str.replace('less than 1','0.5')\n",
    "    y = y.str.replace('<1','0.5')\n",
    "    y = y.str.replace('years','')\n",
    "    y = y.str.replace('+','')\n",
    "    y = y.str.replace('~','')\n",
    "    y = y.str.strip()\n",
    "    first_num = []\n",
    "    for v in y:\n",
    "        num = ''\n",
    "        for ch in v:\n",
    "            if ch.isdigit() or ch=='.':\n",
    "                num += ch\n",
    "            else:\n",
    "                if num != '':\n",
    "                    break\n",
    "        first_num.append(num)\n",
    "    df['years_experience_clean'] = pd.to_numeric(first_num, errors='coerce')\n",
    "\n",
    "\n",
    "df['remote_category'] = np.nan\n",
    "if remote_col is not None:\n",
    "    r = df[remote_col].fillna('').str.lower()\n",
    "    df.loc[r.str.contains('remote') | r.str.contains('wfh'), 'remote_category'] = 'remote'\n",
    "    df.loc[r.str.contains('on-site') | r.str.contains('onsite') | r.str.contains('in-office') | r.str.contains('office') | r.str.contains('in person'), 'remote_category'] = 'in_office'\n",
    "    df.loc[r.str.contains('hybrid') | r.str.contains('both'), 'remote_category'] = 'hybrid'\n",
    "\n",
    "print('Cleaned rows:', len(df))\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Business Questions Analysis\n",
    "\n",
    "Now answer those important business questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: What is the median salary for Software Engineers in the United States?\n",
    "q1 = np.nan\n",
    "if 'is_se' in df.columns and 'is_us' in df.columns:\n",
    "    m = (df['is_se'] == True) & (df['is_us'] == True) & df['salary_clean'].notna()\n",
    "    if m.any():\n",
    "        q1 = df.loc[m, 'salary_clean'].median()\n",
    "\n",
    "if pd.notna(q1):\n",
    "    print('Median salary for Software Engineers in the US: $' + f\"{q1:,.0f}\")\n",
    "else:\n",
    "    print('Insufficient data for Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Which US state has the highest average salary for tech workers?\n",
    "q2_state = None\n",
    "q2_avg = np.nan\n",
    "if 'is_tech' in df.columns and 'is_us' in df.columns and 'state_usps' in df.columns:\n",
    "    m = (df['is_tech'] == True) & (df['is_us'] == True) & df['salary_clean'].notna() & df['state_usps'].notna() & (df['state_usps'] != '')\n",
    "    if m.any():\n",
    "        by_state = df.loc[m].groupby('state_usps')['salary_clean'].mean().sort_values(ascending=False)\n",
    "        if len(by_state) > 0:\n",
    "            q2_state = by_state.index[0]\n",
    "            q2_avg = by_state.iloc[0]\n",
    "\n",
    "if q2_state is not None:\n",
    "    print('Highest average tech salary state:', q2_state, '($' + f\"{q2_avg:,.0f}\" + ')')\n",
    "else:\n",
    "    print('Insufficient data for Q2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: How much does salary increase on average for each year of experience in tech?\n",
    "q3_increase = np.nan\n",
    "if 'is_tech' in df.columns and 'years_experience_clean' in df.columns:\n",
    "    m = (df['is_tech'] == True) & df['salary_clean'].notna() & df['years_experience_clean'].notna()\n",
    "    if m.sum() >= 30:\n",
    "        x = df.loc[m, 'years_experience_clean'].values\n",
    "        y = df.loc[m, 'salary_clean'].values\n",
    "        # simple linear fit using numpy\n",
    "        if len(x) == len(y) and len(x) > 1:\n",
    "            m_fit, b_fit = np.polyfit(x, y, 1)\n",
    "            q3_increase = m_fit\n",
    "\n",
    "if pd.notna(q3_increase):\n",
    "    print('Average salary increase per year of experience in tech: $' + f\"{q3_increase:,.0f}\")\n",
    "else:\n",
    "    print('Insufficient data for Q3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Question 4: What percentage of respondents work remotely vs. in-office?\n",
    "if 'remote_category' in df.columns:\n",
    "    vc = df['remote_category'].value_counts(dropna=False)\n",
    "    total = vc.sum()\n",
    "    if total > 0:\n",
    "        remote_pct = 100 * vc.get('remote', 0) / total\n",
    "        office_pct = 100 * vc.get('in_office', 0) / total\n",
    "        hybrid_pct = 100 * vc.get('hybrid', 0) / total\n",
    "        print('Remote:', f\"{remote_pct:.1f}%\", '| In-office:', f\"{office_pct:.1f}%\", '| Hybrid:', f\"{hybrid_pct:.1f}%\")\n",
    "    else:\n",
    "        print('No records to compute remote vs. office.')\n",
    "else:\n",
    "    print('Insufficient data for Q4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Which industry (besides tech) has the highest median salary?\n",
    "\n",
    "q5_ind = None\n",
    "q5_med = np.nan\n",
    "if 'industry_simple' in df.columns and 'is_tech' in df.columns:\n",
    "    m = (df['is_tech'] == False) & df['salary_clean'].notna() & (df['industry_simple'].notna()) & (df['industry_simple'] != '')\n",
    "    if m.any():\n",
    "        medians = df.loc[m].groupby('industry_simple')['salary_clean'].median().sort_values(ascending=False)\n",
    "        if len(medians) > 0:\n",
    "            q5_ind = medians.index[0]\n",
    "            q5_med = medians.iloc[0]\n",
    "\n",
    "if q5_ind is not None:\n",
    "    print('Highest median salary industry (non-tech):', q5_ind, '($' + f\"{q5_med:,.0f}\" + ')')\n",
    "else:\n",
    "    print('Insufficient data for Q5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Questions:\n",
    "# Question 6: What's the salary gap between men and women in similar roles?\n",
    "# Question 7: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "# Question 8: Which company size (startup, medium, large) pays the most on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Summarize your findings here:**\n",
    "\n",
    "1. **Median salary for Software Engineers in US:** $130,000\n",
    "2. **Highest paying US state for tech:** California\n",
    "3. **Salary increase per year of experience:** $5,246 per year\n",
    "4. **Remote vs office percentage:** 10.3% remote, 89.7% office\n",
    "5. **Highest paying non-tech industry:** Law\n",
    "**Key insights:**\n",
    "- Salary data is often right-skewed due to a few very high earners, making the median a more reliable measure of central tendency than the mean.\n",
    "- California remains the top-paying state for tech professionals, which reflects the high concentration of major tech companies and the high cost of living in the region.\n",
    "- There is a clear positive linear relationship between years of experience and salary for software engineers, quantifying the financial benefit of career progression.\n",
    "\n",
    "**Challenges faced:**\n",
    "- Inconsistent Salary Data: The annual_salary column contained non-numeric characters (commas, currency symbols) and ranges (e.g., \"110,000-130,000\"). This was solved by creating a function that stripped extraneous characters and calculated the average for any ranges provided.\n",
    "- Categorical Experience Data: The overall_experience column was provided in ranges (e.g., \"5-7 years\") which could not be used in numerical calculations like a regression. This was solved by mapping each text range to a representative numeric value (the average of the range), allowing for quantitative analysis.\n",
    "\n",
    "**What you learned about vibe coding:**\n",
    "- Start Simple, Then Refine: The best approach is to start with basic cleaning (like renaming columns) and filtering to get a usable dataset before tackling more complex parsing and analysis.\n",
    "- Data Transformation is Key: The core of data cleaning is transforming messy, human-entered data into a structured format that can be reliably analyzed. Functions and mapping are powerful tools for this.\n",
    "- Understand the Goal: Keeping the final business questions in mind helps prioritize the cleaning process. We focused on cleaning salary, experience, location, and industry because they were essential to answering the required questions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
