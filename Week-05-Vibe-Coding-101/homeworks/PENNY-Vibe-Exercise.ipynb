{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Coding: Real-World Data Cleaning Challenge\n",
    "\n",
    "## The Mission\n",
    "\n",
    "You're a Data Analyst at **TechSalary Insights**. Your manager needs answers to critical business questions, but the data is messy. Your job is to clean it and provide accurate insights.\n",
    "\n",
    "**The catch:** You must figure out how to clean the data yourself. No step by step hints just you, your AI assistant, and real world messy data.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: Ask A Manager Salary Survey 2021\n",
    "\n",
    "**Location:** `../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`\n",
    "\n",
    "This is **real survey data** from Ask A Manager's 2021 salary survey with over 28,000 responses from working professionals. The data comes from this survey: https://www.askamanager.org/2021/04/how-much-money-do-you-make-4.html\n",
    "\n",
    "**Why this dataset is perfect for vibe coding:**\n",
    "- Real human responses (inconsistent formatting)\n",
    "- Multiple currencies and formats  \n",
    "- Messy job titles and location data\n",
    "- Missing and invalid entries\n",
    "- Requires business judgment calls\n",
    "\n",
    "---\n",
    "\n",
    "## Your Business Questions\n",
    "\n",
    "Answer these **exact questions** with clean data. There's only one correct answer for each:\n",
    "\n",
    "### Core Questions (Required):\n",
    "1. **What is the median salary for Software Engineers in the United States?** \n",
    "2. **Which US state has the highest average salary for tech workers?**\n",
    "3. **How much does salary increase on average for each year of experience in tech?**\n",
    "4. **Which industry (besides tech) has the highest median salary?**\n",
    "\n",
    "### Bonus Questions (If time permits):\n",
    "5. **What's the salary gap between men and women in tech roles?**\n",
    "6. **Do people with Master's degrees earn significantly more than those with Bachelor's degrees?**\n",
    "\n",
    "**Success Criteria:** Your final answers will be compared against the \"official\" results. Data cleaning approaches can vary, but final numbers should be within 5% of expected values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Work Starts Here\n",
    "\n",
    "## Step 0: Create Your Plan\n",
    "**Before writing any code, use Cursor to create your todo plan. Then paste it here:**\n",
    "\n",
    "## My Data Cleaning Plan\n",
    "\n",
    "*(Paste your Cursor todo list here)*\n",
    "\n",
    "- [ ] Example todo item\n",
    "- [ ] Another example\n",
    "- [ ] ...\n",
    "\n",
    "# My Data Cleaning Plan - Step 0\n",
    "\n",
    "Based on my analysis of the Ask A Manager Salary Survey dataset, here's my comprehensive data cleaning plan:\n",
    "\n",
    "## Dataset Overview\n",
    "- **Size**: ~28,000 responses from 2021 salary survey\n",
    "- **Format**: TSV file with 18 columns\n",
    "- **Key Challenges**: Multiple currencies, inconsistent formatting, messy job titles, various country/state formats\n",
    "\n",
    "## Data Quality Issues Identified\n",
    "1. **Salary Data**: Multiple currencies (USD, GBP, CAD), inconsistent formatting, potential outliers\n",
    "2. **Location Data**: Inconsistent US state formats (\"US\", \"USA\", \"United States\"), missing states\n",
    "3. **Job Titles**: Highly variable, need to identify \"Software Engineers\" and \"tech workers\"\n",
    "4. **Experience**: Range format (\"5-7 years\", \"8-10 years\") needs conversion to numeric\n",
    "5. **Industry**: Need to categorize tech vs non-tech industries\n",
    "6. **Education/Gender**: For bonus questions, need clean categories\n",
    "\n",
    "## Step-by-Step Cleaning Plan\n",
    "\n",
    "### Phase 1: Data Exploration & Setup\n",
    "1. Load dataset and examine structure, data types, missing values\n",
    "2. Identify all unique currencies and conversion rates needed\n",
    "3. Map out all unique job titles, industries, and location formats\n",
    "\n",
    "### Phase 2: Core Data Cleaning\n",
    "1. **Salary Standardization**:\n",
    "   - Convert all salaries to USD using 2021 exchange rates\n",
    "   - Handle missing/zero salaries appropriately\n",
    "   - Remove extreme outliers (likely data entry errors)\n",
    "   - Add bonus compensation to total salary\n",
    "\n",
    "2. **Location Standardization**:\n",
    "   - Standardize country names to \"United States\"\n",
    "   - Clean and standardize US state names\n",
    "   - Filter to US-only data for core questions\n",
    "\n",
    "3. **Job Title Categorization**:\n",
    "   - Create \"Software Engineer\" category (exact matches + variations)\n",
    "   - Create \"Tech Worker\" category (all computing/tech industry roles)\n",
    "   - Handle job title variations and context\n",
    "\n",
    "4. **Experience Conversion**:\n",
    "   - Convert experience ranges to midpoint numeric values\n",
    "   - Handle edge cases and missing data\n",
    "\n",
    "### Phase 3: Analysis Preparation\n",
    "1. **Industry Classification**:\n",
    "   - Identify tech vs non-tech industries\n",
    "   - Standardize industry names\n",
    "\n",
    "2. **Education & Gender Cleaning**:\n",
    "   - Standardize education levels for bonus questions\n",
    "   - Clean gender categories\n",
    "\n",
    "### Phase 4: Business Question Analysis\n",
    "1. **Question 1**: Median salary for Software Engineers in US\n",
    "2. **Question 2**: US state with highest average tech worker salary  \n",
    "3. **Question 3**: Salary increase per year of experience in tech\n",
    "4. **Question 4**: Highest median salary non-tech industry\n",
    "5. **Question 5**: Gender salary gap in tech (bonus)\n",
    "6. **Question 6**: Education level salary comparison (bonus)\n",
    "\n",
    "## Key Business Decisions\n",
    "- **Currency Conversion**: Use 2021 average exchange rates (GBP‚âà1.37, CAD‚âà0.80)\n",
    "- **Outlier Handling**: Remove salaries <$20k or >$500k as likely errors\n",
    "- **Tech Definition**: \"Computing or Tech\" industry + specific tech job titles\n",
    "- **Experience Mapping**: Use range midpoints (e.g., \"5-7 years\" = 6 years)\n",
    "\n",
    "## Success Criteria\n",
    "- Final answers within 5% of expected values\n",
    "- Clean, reproducible analysis\n",
    "- Clear documentation of cleaning decisions\n",
    "\n",
    "This plan addresses the real-world messiness of survey data while ensuring we can answer the specific business questions accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n",
    "Start here! Load the dataset and get familiar with what you're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "‚ùå File not found. Please check the file path.\n",
      "üîç DATASET OVERVIEW\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç DATASET OVERVIEW\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows √ó \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.memory_usage(deep=\u001b[38;5;28;01mTrue\u001b[39;00m).sum()\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m1024\u001b[39m**\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìä Dataset shape: {df.shape}\")\n",
    "    print(f\"üìã Columns: {len(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "\n",
    "# Data Exploration\n",
    "\n",
    "# Basic dataset information\n",
    "print(\"üîç DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print()\n",
    "\n",
    "print(\"üìã COLUMN NAMES:\")\n",
    "print(\"-\" * 30)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# Data types and missing values\n",
    "print(\"üìä DATA TYPES & MISSING VALUES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "info_df = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null %': (df.isnull().sum() / len(df) * 100).round(1)\n",
    "})\n",
    "\n",
    "print(info_df)\n",
    "\n",
    "# First few rows to understand the data structure\n",
    "print(\"üëÄ FIRST 5 ROWS\")\n",
    "print(\"=\" * 50)\n",
    "display(df.head())\n",
    "\n",
    "# Key columns for our analysis\n",
    "key_columns = [\n",
    "    'What industry do you work in?',\n",
    "    'Job title', \n",
    "    'What is your annual salary? (You\\'ll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)',\n",
    "    'Please indicate the currency',\n",
    "    'What country do you work in?',\n",
    "    'If you\\'re in the U.S., what state do you work in?',\n",
    "    'How many years of professional work experience do you have overall?',\n",
    "    'What is your highest level of education completed?',\n",
    "    'What is your gender?'\n",
    "]\n",
    "\n",
    "print(\"üéØ KEY COLUMNS FOR ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "for i, col in enumerate(key_columns, 1):\n",
    "    if col in df.columns:\n",
    "        print(f\"‚úÖ {i}. {col}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {i}. {col} - NOT FOUND\")\n",
    "\n",
    "# Let's examine the salary column more closely\n",
    "salary_col = 'What is your annual salary? (You\\'ll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)'\n",
    "\n",
    "print(\"üí∞ SALARY DATA EXPLORATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Salary column: {salary_col}\")\n",
    "print(f\"Non-null salary entries: {df[salary_col].count():,}\")\n",
    "print(f\"Null salary entries: {df[salary_col].isnull().sum():,}\")\n",
    "print()\n",
    "\n",
    "print(\"Sample salary values:\")\n",
    "print(df[salary_col].dropna().head(10).tolist())\n",
    "\n",
    "# Currency distribution\n",
    "currency_col = 'Please indicate the currency'\n",
    "print(\"üí± CURRENCY DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "currency_counts = df[currency_col].value_counts()\n",
    "print(currency_counts)\n",
    "print(f\"\\nTotal currencies: {len(currency_counts)}\")\n",
    "\n",
    "# Country distribution\n",
    "country_col = 'What country do you work in?'\n",
    "print(\"üåç COUNTRY DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "country_counts = df[country_col].value_counts().head(10)\n",
    "print(country_counts)\n",
    "print(f\"\\nTotal countries: {df[country_col].nunique()}\")\n",
    "\n",
    "# Industry distribution\n",
    "industry_col = 'What industry do you work in?'\n",
    "print(\"üè≠ INDUSTRY DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "industry_counts = df[industry_col].value_counts()\n",
    "print(industry_counts)\n",
    "print(f\"\\nTotal industries: {len(industry_counts)}\")\n",
    "\n",
    "# Check for tech-related industries\n",
    "tech_industries = industry_counts[industry_counts.index.str.contains('Tech|Computing', case=False, na=False)]\n",
    "print(f\"\\nüîß TECH-RELATED INDUSTRIES:\")\n",
    "print(tech_industries)\n",
    "\n",
    "# Job titles - let's look for Software Engineers\n",
    "job_title_col = 'Job title'\n",
    "print(\"üíº JOB TITLE EXPLORATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total unique job titles: {df[job_title_col].nunique():,}\")\n",
    "print()\n",
    "\n",
    "# Look for software engineer variations\n",
    "software_engineer_mask = df[job_title_col].str.contains('software|engineer', case=False, na=False)\n",
    "software_engineer_titles = df[software_engineer_mask][job_title_col].value_counts().head(10)\n",
    "\n",
    "print(\"üîß SOFTWARE ENGINEER JOB TITLES (Top 10):\")\n",
    "print(software_engineer_titles)\n",
    "print(f\"\\nTotal Software Engineer entries: {software_engineer_mask.sum():,}\")\n",
    "\n",
    "# US State distribution\n",
    "state_col = 'If you\\'re in the U.S., what state do you work in?'\n",
    "print(\"üá∫üá∏ US STATE DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "state_counts = df[state_col].value_counts().head(15)\n",
    "print(state_counts)\n",
    "print(f\"\\nTotal US states represented: {df[state_col].nunique()}\")\n",
    "print(f\"Missing state data: {df[state_col].isnull().sum():,}\")\n",
    "\n",
    "# Experience distribution\n",
    "exp_col = 'How many years of professional work experience do you have overall?'\n",
    "print(\"üìà EXPERIENCE DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "exp_counts = df[exp_col].value_counts()\n",
    "print(exp_counts)\n",
    "print(f\"\\nTotal experience categories: {len(exp_counts)}\")\n",
    "\n",
    "# Education distribution\n",
    "edu_col = 'What is your highest level of education completed?'\n",
    "print(\"üéì EDUCATION DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "edu_counts = df[edu_col].value_counts()\n",
    "print(edu_counts)\n",
    "print(f\"\\nTotal education levels: {len(edu_counts)}\")\n",
    "\n",
    "# Gender distribution\n",
    "gender_col = 'What is your gender?'\n",
    "print(\"üë• GENDER DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "gender_counts = df[gender_col].value_counts()\n",
    "print(gender_counts)\n",
    "print(f\"\\nTotal gender categories: {len(gender_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original dataset for cleaning\n",
    "df_clean = df.copy()\n",
    "print(\"üìã Created clean dataset copy\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Define column names for easier access\n",
    "salary_col = 'What is your annual salary? (You\\'ll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)'\n",
    "currency_col = 'Please indicate the currency'\n",
    "bonus_col = 'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.'\n",
    "country_col = 'What country do you work in?'\n",
    "state_col = 'If you\\'re in the U.S., what state do you work in?'\n",
    "industry_col = 'What industry do you work in?'\n",
    "job_title_col = 'Job title'\n",
    "exp_col = 'How many years of professional work experience do you have overall?'\n",
    "edu_col = 'What is your highest level of education completed?'\n",
    "gender_col = 'What is your gender?'\n",
    "\n",
    "print(\"‚úÖ Column references defined\")\n",
    "\n",
    "### 2.1: Salary Data Cleaning\n",
    "#First, let's tackle the most complex part - cleaning and standardizing salary data across multiple currencies.\n",
    "\n",
    "# Define 2021 exchange rates (approximate averages for the year)\n",
    "exchange_rates = {\n",
    "    'USD': 1.0,\n",
    "    'GBP': 1.37,  # 1 GBP = 1.37 USD (2021 average)\n",
    "    'CAD': 0.80,  # 1 CAD = 0.80 USD (2021 average)\n",
    "    'EUR': 1.18,  # 1 EUR = 1.18 USD (2021 average)\n",
    "    'AUD': 0.75,  # 1 AUD = 0.75 USD (2021 average)\n",
    "    'CHF': 1.09,  # 1 CHF = 1.09 USD (2021 average)\n",
    "    'SEK': 0.12,  # 1 SEK = 0.12 USD (2021 average)\n",
    "    'NOK': 0.12,  # 1 NOK = 0.12 USD (2021 average)\n",
    "    'DKK': 0.16,  # 1 DKK = 0.16 USD (2021 average)\n",
    "    'JPY': 0.009, # 1 JPY = 0.009 USD (2021 average)\n",
    "    'INR': 0.014, # 1 INR = 0.014 USD (2021 average)\n",
    "    'SGD': 0.74,  # 1 SGD = 0.74 USD (2021 average)\n",
    "    'NZD': 0.71,  # 1 NZD = 0.71 USD (2021 average)\n",
    "    'ZAR': 0.067, # 1 ZAR = 0.067 USD (2021 average)\n",
    "    'BRL': 0.19,  # 1 BRL = 0.19 USD (2021 average)\n",
    "    'MXN': 0.050, # 1 MXN = 0.050 USD (2021 average)\n",
    "    'ILS': 0.31,  # 1 ILS = 0.31 USD (2021 average)\n",
    "    'PLN': 0.26,  # 1 PLN = 0.26 USD (2021 average)\n",
    "    'CZK': 0.046, # 1 CZK = 0.046 USD (2021 average)\n",
    "    'HUF': 0.0033,# 1 HUF = 0.0033 USD (2021 average)\n",
    "    'TRY': 0.12,  # 1 TRY = 0.12 USD (2021 average)\n",
    "    'RUB': 0.014, # 1 RUB = 0.014 USD (2021 average)\n",
    "    'CNY': 0.15,  # 1 CNY = 0.15 USD (2021 average)\n",
    "    'KRW': 0.0009,# 1 KRW = 0.0009 USD (2021 average)\n",
    "    'THB': 0.030, # 1 THB = 0.030 USD (2021 average)\n",
    "    'MYR': 0.24,  # 1 MYR = 0.24 USD (2021 average)\n",
    "    'PHP': 0.020, # 1 PHP = 0.020 USD (2021 average)\n",
    "    'IDR': 0.00007,# 1 IDR = 0.00007 USD (2021 average)\n",
    "    'VND': 0.000044,# 1 VND = 0.000044 USD (2021 average)\n",
    "}\n",
    "\n",
    "print(\"üí± Exchange rates defined for 2021\")\n",
    "print(f\"Supported currencies: {len(exchange_rates)}\")\n",
    "print(\"Top currencies by frequency:\")\n",
    "print(df_clean[currency_col].value_counts().head(10))\n",
    "\n",
    "# Function to clean and convert salary to USD\n",
    "def clean_salary_to_usd(salary_str, currency_str, bonus_str=None):\n",
    "    \"\"\"\n",
    "    Clean salary string and convert to USD\n",
    "    \"\"\"\n",
    "    if pd.isna(salary_str) or salary_str == '':\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    salary_str = str(salary_str).strip()\n",
    "    \n",
    "    # Remove common non-numeric characters but keep decimal point\n",
    "    import re\n",
    "    salary_clean = re.sub(r'[^\\d.,]', '', salary_str)\n",
    "    \n",
    "    # Handle different number formats\n",
    "    if ',' in salary_clean and '.' in salary_clean:\n",
    "        # Format like \"1,234.56\" - US format\n",
    "        salary_clean = salary_clean.replace(',', '')\n",
    "    elif ',' in salary_clean:\n",
    "        # Could be European format \"1.234,56\" or thousands separator \"1,234\"\n",
    "        if salary_clean.count(',') == 1 and salary_clean.count('.') == 0:\n",
    "            # Check if it's likely thousands separator (comma near end) or decimal\n",
    "            comma_pos = salary_clean.find(',')\n",
    "            if len(salary_clean) - comma_pos <= 3:  # Likely thousands separator\n",
    "                salary_clean = salary_clean.replace(',', '')\n",
    "            else:  # Likely decimal separator\n",
    "                salary_clean = salary_clean.replace(',', '.')\n",
    "        else:\n",
    "            # Multiple commas, likely thousands separators\n",
    "            salary_clean = salary_clean.replace(',', '')\n",
    "    try:\n",
    "        salary_num = float(salary_clean)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "    \n",
    "    # Handle bonus if provided\n",
    "    bonus_num = 0\n",
    "    if bonus_str is not None and not pd.isna(bonus_str) and str(bonus_str).strip() != '':\n",
    "        try:\n",
    "            bonus_clean = re.sub(r'[^\\d.,]', '', str(bonus_str))\n",
    "            if ',' in bonus_clean:\n",
    "                bonus_clean = bonus_clean.replace(',', '')\n",
    "            bonus_num = float(bonus_clean)\n",
    "        except (ValueError, TypeError):\n",
    "            bonus_num = 0\n",
    "    \n",
    "    # Total compensation\n",
    "    total_comp = salary_num + bonus_num\n",
    "    \n",
    "    # Convert to USD\n",
    "    if pd.isna(currency_str) or currency_str not in exchange_rates:\n",
    "        return np.nan\n",
    "    \n",
    "    usd_amount = total_comp * exchange_rates[currency_str]\n",
    "    \n",
    "    return usd_amount\n",
    "\n",
    "print(\"üîß Salary cleaning function defined\")\n",
    "\n",
    "# Apply salary cleaning function\n",
    "print(\"üí∞ Cleaning salary data...\")\n",
    "\n",
    "# Create new column for cleaned USD salaries\n",
    "df_clean['salary_usd'] = df_clean.apply(\n",
    "    lambda row: clean_salary_to_usd(\n",
    "        row[salary_col], \n",
    "        row[currency_col], \n",
    "        row[bonus_col]\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Salary cleaning completed\")\n",
    "print(f\"Valid USD salaries: {df_clean['salary_usd'].notna().sum():,}\")\n",
    "print(f\"Invalid/missing salaries: {df_clean['salary_usd'].isna().sum():,}\")\n",
    "\n",
    "# Show some examples of cleaned salaries\n",
    "print(\"\\nüìä Sample of cleaned salaries:\")\n",
    "sample_data = df_clean[['salary_usd', salary_col, currency_col, bonus_col]].dropna(subset=['salary_usd']).head(10)\n",
    "display(sample_data)\n",
    "\n",
    "# Remove salary outliers (likely data entry errors)\n",
    "print(\"üîç Analyzing salary distribution for outliers...\")\n",
    "\n",
    "# Get basic statistics\n",
    "salary_stats = df_clean['salary_usd'].describe()\n",
    "print(\"Salary statistics (USD):\")\n",
    "print(salary_stats)\n",
    "\n",
    "# Define reasonable salary bounds (2021 context)\n",
    "min_salary = 20000  # $20k minimum (very low but possible for part-time/entry level)\n",
    "max_salary = 500000  # $500k maximum (very high but possible for executives)\n",
    "\n",
    "# Count outliers\n",
    "outliers_low = (df_clean['salary_usd'] < min_salary).sum()\n",
    "outliers_high = (df_clean['salary_usd'] > max_salary).sum()\n",
    "total_outliers = outliers_low + outliers_high\n",
    "\n",
    "print(f\"\\nüö® Outlier Analysis:\")\n",
    "print(f\"Salaries below ${min_salary:,}: {outliers_low:,}\")\n",
    "print(f\"Salaries above ${max_salary:,}: {outliers_high:,}\")\n",
    "print(f\"Total outliers: {total_outliers:,}\")\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = df_clean[\n",
    "    (df_clean['salary_usd'] >= min_salary) | \n",
    "    (df_clean['salary_usd'].isna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Outliers removed\")\n",
    "print(f\"Remaining records: {len(df_clean):,}\")\n",
    "print(f\"Valid salaries after cleaning: {df_clean['salary_usd'].notna().sum():,}\")\n",
    "\n",
    "### 2.2: Location Data Standardization\n",
    "#Now let's clean up the location data to standardize country and state names.\n",
    "\n",
    "# Standardize country names\n",
    "print(\"üåç Standardizing country names...\")\n",
    "\n",
    "# Create mapping for US variations\n",
    "us_variations = {\n",
    "    'United States': 'United States',\n",
    "    'US': 'United States', \n",
    "    'USA': 'United States',\n",
    "    'U.S.': 'United States',\n",
    "    'U.S.A.': 'United States',\n",
    "    'United States of America': 'United States'\n",
    "}\n",
    "\n",
    "# Apply country standardization\n",
    "df_clean['country_clean'] = df_clean[country_col].replace(us_variations)\n",
    "\n",
    "print(\"Country distribution after cleaning:\")\n",
    "print(df_clean['country_clean'].value_counts().head(10))\n",
    "\n",
    "# Filter for US data only (since our questions focus on US)\n",
    "us_mask = df_clean['country_clean'] == 'United States'\n",
    "df_us = df_clean[us_mask].copy()\n",
    "\n",
    "print(f\"\\nüá∫üá∏ US-only dataset:\")\n",
    "print(f\"US records: {len(df_us):,}\")\n",
    "print(f\"Non-US records: {len(df_clean) - len(df_us):,}\")\n",
    "print(f\"US percentage: {len(df_us)/len(df_clean)*100:.1f}%\")\n",
    "\n",
    "# Standardize US state names\n",
    "print(\"üó∫Ô∏è Standardizing US state names...\")\n",
    "\n",
    "# Create comprehensive state mapping\n",
    "state_mapping = {\n",
    "    # Standard abbreviations\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "    'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming',\n",
    "    'DC': 'District of Columbia',\n",
    "    \n",
    "    # Common variations and full names\n",
    "    'California': 'California', 'New York': 'New York', 'Texas': 'Texas', 'Florida': 'Florida',\n",
    "    'Illinois': 'Illinois', 'Pennsylvania': 'Pennsylvania', 'Ohio': 'Ohio', 'Georgia': 'Georgia',\n",
    "    'North Carolina': 'North Carolina', 'Michigan': 'Michigan', 'New Jersey': 'New Jersey',\n",
    "    'Virginia': 'Virginia', 'Washington': 'Washington', 'Arizona': 'Arizona', 'Massachusetts': 'Massachusetts',\n",
    "    'Tennessee': 'Tennessee', 'Indiana': 'Indiana', 'Missouri': 'Missouri', 'Maryland': 'Maryland',\n",
    "    'Wisconsin': 'Wisconsin', 'Colorado': 'Colorado', 'Minnesota': 'Minnesota', 'South Carolina': 'South Carolina',\n",
    "    'Alabama': 'Alabama', 'Louisiana': 'Louisiana', 'Kentucky': 'Kentucky', 'Oregon': 'Oregon',\n",
    "    'Oklahoma': 'Oklahoma', 'Connecticut': 'Connecticut', 'Utah': 'Utah', 'Iowa': 'Iowa',\n",
    "    'Nevada': 'Nevada', 'Arkansas': 'Arkansas', 'Mississippi': 'Mississippi', 'Kansas': 'Kansas',\n",
    "    'New Mexico': 'New Mexico', 'Nebraska': 'Nebraska', 'West Virginia': 'West Virginia', 'Idaho': 'Idaho',\n",
    "    'Hawaii': 'Hawaii', 'New Hampshire': 'New Hampshire', 'Maine': 'Maine', 'Montana': 'Montana',\n",
    "    'Rhode Island': 'Rhode Island', 'Delaware': 'Delaware', 'South Dakota': 'South Dakota', 'North Dakota': 'North Dakota',\n",
    "    'Alaska': 'Alaska', 'Vermont': 'Vermont', 'Wyoming': 'Wyoming',\n",
    "\n",
    "    # Special cases\n",
    "    'District of Columbia': 'District of Columbia', 'Washington DC': 'District of Columbia',\n",
    "    'Washington, DC': 'District of Columbia', 'Washington D.C.': 'District of Columbia',\n",
    "    'D.C.': 'District of Columbia', 'DC': 'District of Columbia'\n",
    "}\n",
    "\n",
    "# Apply state standardization\n",
    "df_us['state_clean'] = df_us[state_col].replace(state_mapping)\n",
    "\n",
    "print(\"State distribution after cleaning (top 15):\")\n",
    "print(df_us['state_clean'].value_counts().head(15))\n",
    "\n",
    "# Check for unmapped states\n",
    "unmapped_states = df_us[~df_us[state_col].isin(state_mapping.keys()) & df_us[state_col].notna()][state_col].unique()\n",
    "if len(unmapped_states) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Unmapped states found: {unmapped_states[:10]}\")  # Show first 10\n",
    "    print(f\"Total unmapped state entries: {len(unmapped_states)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ State standardization completed\")\n",
    "print(f\"Records with valid states: {df_us['state_clean'].notna().sum():,}\")\n",
    "print(f\"Records with missing states: {df_us['state_clean'].isna().sum():,}\")\n",
    "\n",
    "### 2.3: Job Title and Industry Classification\n",
    "#Now let's clean job titles and classify industries to identify Software Engineers and tech workers.\n",
    "\n",
    "# Clean and standardize job titles\n",
    "print(\"üíº Cleaning job titles...\")\n",
    "\n",
    "# Function to clean job titles\n",
    "def clean_job_title(title):\n",
    "    if pd.isna(title):\n",
    "        return title\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    title_clean = str(title).strip()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    title_clean = ' '.join(title_clean.split())\n",
    "    \n",
    "    # Standardize common variations\n",
    "    title_clean = title_clean.replace('Sr.', 'Senior')\n",
    "    title_clean = title_clean.replace('Jr.', 'Junior')\n",
    "    title_clean = title_clean.replace('Sr ', 'Senior ')\n",
    "    title_clean = title_clean.replace('Jr ', 'Junior ')\n",
    "    \n",
    "    return title_clean\n",
    "\n",
    "# Apply job title cleaning\n",
    "df_us['job_title_clean'] = df_us[job_title_col].apply(clean_job_title)\n",
    "\n",
    "print(\"‚úÖ Job titles cleaned\")\n",
    "print(f\"Unique job titles: {df_us['job_title_clean'].nunique():,}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSample cleaned job titles:\")\n",
    "print(df_us['job_title_clean'].value_counts().head(10))\n",
    "\n",
    "# Identify Software Engineers\n",
    "print(\"üîß Identifying Software Engineers...\")\n",
    "\n",
    "# Define patterns for Software Engineer identification\n",
    "software_engineer_patterns = [\n",
    "    'software engineer', 'software developer', 'software architect', 'software analyst',\n",
    "    'software consultant', 'software manager', 'software lead', 'software director',\n",
    "    'software specialist', 'software technician', 'software programmer', 'software designer',\n",
    "    'senior software engineer', 'principal software engineer', 'staff software engineer',\n",
    "    'lead software engineer', 'software engineering', 'software development',\n",
    "    'backend engineer', 'frontend engineer', 'full stack engineer', 'full-stack engineer',\n",
    "    'mobile developer', 'web developer', 'application developer', 'systems developer',\n",
    "    'devops engineer', 'platform engineer', 'infrastructure engineer', 'cloud engineer',\n",
    "    'data engineer', 'machine learning engineer', 'ai engineer', 'ml engineer'\n",
    "]\n",
    "\n",
    "# Create function to identify software engineers\n",
    "def is_software_engineer(title):\n",
    "    if pd.isna(title):\n",
    "        return False\n",
    "    \n",
    "    title_lower = str(title).lower()\n",
    "    \n",
    "    # Check for exact matches or contains patterns\n",
    "    for pattern in software_engineer_patterns:\n",
    "        if pattern in title_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Apply software engineer identification\n",
    "df_us['is_software_engineer'] = df_us['job_title_clean'].apply(is_software_engineer)\n",
    "\n",
    "# Count software engineers\n",
    "se_count = df_us['is_software_engineer'].sum()\n",
    "print(f\"‚úÖ Software Engineers identified: {se_count:,}\")\n",
    "\n",
    "# Show software engineer job titles\n",
    "print(\"\\nüîß Software Engineer job titles (top 15):\")\n",
    "se_titles = df_us[df_us['is_software_engineer']]['job_title_clean'].value_counts().head(15)\n",
    "print(se_titles)\n",
    "\n",
    "# Identify tech workers (broader category)\n",
    "print(\"üíª Identifying tech workers...\")\n",
    "\n",
    "# Define tech industry and job patterns\n",
    "tech_industries = [\n",
    "    'Computing or Tech', 'Technology', 'Software', 'IT', 'Information Technology',\n",
    "    'Computer', 'Tech', 'Digital', 'Cybersecurity', 'Data', 'AI', 'Machine Learning'\n",
    "]\n",
    "\n",
    "tech_job_patterns = [\n",
    "    'engineer', 'developer', 'programmer', 'analyst', 'architect', 'consultant',\n",
    "    'manager', 'director', 'lead', 'specialist', 'technician', 'designer',\n",
    "    'data scientist', 'data analyst', 'product manager', 'technical', 'systems',\n",
    "    'network', 'security', 'cloud', 'devops', 'platform', 'infrastructure',\n",
    "    'database', 'qa', 'quality assurance', 'test', 'automation', 'scrum',\n",
    "    'agile', 'product owner', 'business analyst', 'technical writer', 'support'\n",
    "]\n",
    "\n",
    "# Function to identify tech workers\n",
    "def is_tech_worker(industry, title):\n",
    "    if pd.isna(industry) and pd.isna(title):\n",
    "        return False\n",
    "    \n",
    "    # Check industry\n",
    "    if not pd.isna(industry):\n",
    "        industry_lower = str(industry).lower()\n",
    "        for tech_ind in tech_industries:\n",
    "            if tech_ind.lower() in industry_lower:\n",
    "                return True\n",
    "            \n",
    "    # Check job title\n",
    "    if not pd.isna(title):\n",
    "        title_lower = str(title).lower()\n",
    "        for pattern in tech_job_patterns:\n",
    "            if pattern in title_lower:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Apply tech worker identification\n",
    "df_us['is_tech_worker'] = df_us.apply(\n",
    "    lambda row: is_tech_worker(row[industry_col], row['job_title_clean']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Count tech workers\n",
    "tech_count = df_us['is_tech_worker'].sum()\n",
    "print(f\"‚úÖ Tech workers identified: {tech_count:,}\")\n",
    "\n",
    "# Show tech industry distribution\n",
    "print(\"\\nüíª Tech industry distribution:\")\n",
    "tech_industries_dist = df_us[df_us['is_tech_worker']][industry_col].value_counts().head(10)\n",
    "print(tech_industries_dist)\n",
    "\n",
    "### 2.4: Experience Data Conversion\n",
    "#Now let's convert experience ranges to numeric values for analysis.\n",
    "\n",
    "# Convert experience ranges to numeric values\n",
    "print(\"üìà Converting experience ranges to numeric values...\")\n",
    "\n",
    "# Define experience mapping (using midpoints of ranges)\n",
    "experience_mapping = {\n",
    "    '1 year or less': 0.5,\n",
    "    '2 - 4 years': 3,\n",
    "    '5-7 years': 6,\n",
    "    '8 - 10 years': 9,\n",
    "    '11 - 20 years': 15.5,\n",
    "    '21 - 30 years': 25.5,\n",
    "    '31 - 40 years': 35.5,\n",
    "    '41 years or more': 45\n",
    "}\n",
    "\n",
    "# Apply experience conversion\n",
    "df_us['experience_years'] = df_us[exp_col].replace(experience_mapping)\n",
    "\n",
    "print(\"Experience distribution after conversion:\")\n",
    "exp_dist = df_us['experience_years'].value_counts().sort_index()\n",
    "print(exp_dist)\n",
    "\n",
    "print(f\"\\n‚úÖ Experience conversion completed\")\n",
    "print(f\"Records with valid experience: {df_us['experience_years'].notna().sum():,}\")\n",
    "print(f\"Records with missing experience: {df_us['experience_years'].isna().sum():,}\")\n",
    "\n",
    "# Show experience statistics\n",
    "print(f\"\\nüìä Experience statistics:\")\n",
    "print(df_us['experience_years'].describe())\n",
    "\n",
    "### 2.5: Education and Gender Standardization\n",
    "#Finally, let's clean education and gender data for the bonus questions.\n",
    "\n",
    "# Standardize education levels\n",
    "print(\"üéì Standardizing education levels...\")\n",
    "\n",
    "# Define education mapping\n",
    "education_mapping = {\n",
    "    'High School': 'High School',\n",
    "    'Some college': 'Some College',\n",
    "    'College degree': 'Bachelor\\'s Degree',\n",
    "    'Bachelor\\'s degree': 'Bachelor\\'s Degree',\n",
    "    'Master\\'s degree': 'Master\\'s Degree',\n",
    "    'PhD': 'PhD',\n",
    "    'Professional degree (MD, JD, etc.)': 'Professional Degree',\n",
    "    'Some high school': 'High School',\n",
    "    'Trade school': 'Trade School',\n",
    "    'Associate degree': 'Associate Degree'\n",
    "}\n",
    "\n",
    "# Apply education standardization\n",
    "df_us['education_clean'] = df_us[edu_col].replace(education_mapping)\n",
    "\n",
    "print(\"Education distribution after cleaning:\")\n",
    "edu_dist = df_us['education_clean'].value_counts()\n",
    "print(edu_dist)\n",
    "\n",
    "print(f\"\\n‚úÖ Education standardization completed\")\n",
    "print(f\"Records with valid education: {df_us['education_clean'].notna().sum():,}\")\n",
    "\n",
    "# Standardize gender categories\n",
    "print(\"üë• Standardizing gender categories...\")\n",
    "\n",
    "# Define gender mapping\n",
    "gender_mapping = {\n",
    "    'Man': 'Man',\n",
    "    'Woman': 'Woman',\n",
    "    'Non-binary': 'Non-binary',\n",
    "    'Another option not listed here or prefer not to answer': 'Other/Prefer not to answer',\n",
    "    'Prefer not to answer': 'Other/Prefer not to answer'\n",
    "}\n",
    "\n",
    "# Apply gender standardization\n",
    "df_us['gender_clean'] = df_us[gender_col].replace(gender_mapping)\n",
    "\n",
    "print(\"Gender distribution after cleaning:\")\n",
    "gender_dist = df_us['gender_clean'].value_counts()\n",
    "print(gender_dist)\n",
    "\n",
    "print(f\"\\n‚úÖ Gender standardization completed\")\n",
    "print(f\"Records with valid gender: {df_us['gender_clean'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Business Questions Analysis\n",
    "\n",
    "Now answer those important business questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: What is the median salary for Software Engineers in the United States?\n",
    "\n",
    "print(\"üîß QUESTION 1: Software Engineer Salary Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, let's check if we have the cleaned data or need to do quick cleaning\n",
    "if 'is_software_engineer' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to identify Software Engineers from raw data...\")\n",
    "    \n",
    "    # Quick Software Engineer identification from raw data\n",
    "    job_title_col = 'Job title'\n",
    "    software_engineer_patterns = [\n",
    "        'software engineer', 'software developer', 'software architect', 'software analyst',\n",
    "        'software consultant', 'software manager', 'software lead', 'software director',\n",
    "        'software specialist', 'software technician', 'software programmer', 'software designer',\n",
    "        'senior software engineer', 'principal software engineer', 'staff software engineer',\n",
    "        'lead software engineer', 'software engineering', 'software development',\n",
    "        'backend engineer', 'frontend engineer', 'full stack engineer', 'full-stack engineer',\n",
    "        'mobile developer', 'web developer', 'application developer', 'systems developer',\n",
    "        'devops engineer', 'platform engineer', 'infrastructure engineer', 'cloud engineer',\n",
    "        'data engineer', 'machine learning engineer', 'ai engineer', 'ml engineer'\n",
    "    ]\n",
    "    \n",
    "    def is_software_engineer(title):\n",
    "        if pd.isna(title):\n",
    "            return False\n",
    "        title_lower = str(title).lower()\n",
    "        return any(pattern in title_lower for pattern in software_engineer_patterns)\n",
    "    \n",
    "    df_us['is_software_engineer'] = df_us[job_title_col].apply(is_software_engineer)\n",
    "    print(f\"‚úÖ Identified Software Engineers from raw data\")\n",
    "\n",
    "    # Filter for Software Engineers with valid salaries\n",
    "se_with_salary = df_us[\n",
    "    (df_us['is_software_engineer'] == True) & \n",
    "    (df_us['salary_usd'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Software Engineer Data:\")\n",
    "print(f\"Total Software Engineers: {df_us['is_software_engineer'].sum():,}\")\n",
    "print(f\"Software Engineers with valid salaries: {len(se_with_salary):,}\")\n",
    "\n",
    "if len(se_with_salary) == 0:\n",
    "    print(\"‚ùå No Software Engineers with valid salary data found!\")\n",
    "    print(\"Let's check what we have...\")\n",
    "    print(f\"Total records: {len(df_us):,}\")\n",
    "    print(f\"Records with salary data: {df_us['salary_usd'].notna().sum():,}\")\n",
    "    print(f\"Software Engineers (any salary): {df_us['is_software_engineer'].sum():,}\")\n",
    "else:\n",
    "    # Calculate median salary\n",
    "    median_salary = se_with_salary['salary_usd'].median()\n",
    "    \n",
    "    # Additional statistics\n",
    "    mean_salary = se_with_salary['salary_usd'].mean()\n",
    "    min_salary = se_with_salary['salary_usd'].min()\n",
    "    max_salary = se_with_salary['salary_usd'].max()\n",
    "    std_salary = se_with_salary['salary_usd'].std()\n",
    "    \n",
    "    print(f\"\\nüí∞ SOFTWARE ENGINEER SALARY STATISTICS:\")\n",
    "    print(f\"Median Salary: ${median_salary:,.0f}\")\n",
    "    print(f\"Mean Salary: ${mean_salary:,.0f}\")\n",
    "    print(f\"Min Salary: ${min_salary:,.0f}\")\n",
    "    print(f\"Max Salary: ${max_salary:,.0f}\")\n",
    "    print(f\"Standard Deviation: ${std_salary:,.0f}\")\n",
    "\n",
    "    # Show salary distribution\n",
    "    print(f\"\\nüìà Salary Distribution:\")\n",
    "    salary_quartiles = se_with_salary['salary_usd'].quantile([0.25, 0.5, 0.75])\n",
    "    print(f\"25th Percentile: ${salary_quartiles[0.25]:,.0f}\")\n",
    "    print(f\"50th Percentile (Median): ${salary_quartiles[0.5]:,.0f}\")\n",
    "    print(f\"75th Percentile: ${salary_quartiles[0.75]:,.0f}\")\n",
    "    \n",
    "    # Show some sample Software Engineer job titles and salaries\n",
    "    print(f\"\\nüîß Sample Software Engineer Job Titles & Salaries:\")\n",
    "    sample_data = se_with_salary[['Job title', 'salary_usd']].head(10)\n",
    "    for idx, row in sample_data.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['Job title']}: ${row['salary_usd']:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ ANSWER TO QUESTION 1:\")\n",
    "    print(f\"The median salary for Software Engineers in the United States is ${median_salary:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Which US state has the highest average salary for tech workers?\n",
    "\n",
    "print(\"üíª QUESTION 2: Tech Worker Salaries by State Analysis\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# First, let's check if we have the cleaned data or need to do quick cleaning\n",
    "if 'is_tech_worker' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to identify tech workers from raw data...\")\n",
    "    \n",
    "    # Quick tech worker identification from raw data\n",
    "    industry_col = 'What industry do you work in?'\n",
    "    job_title_col = 'Job title'\n",
    "    \n",
    "    # Define tech industry and job patterns\n",
    "    tech_industries = [\n",
    "        'Computing or Tech', 'Technology', 'Software', 'IT', 'Information Technology',\n",
    "        'Computer', 'Tech', 'Digital', 'Cybersecurity', 'Data', 'AI', 'Machine Learning'\n",
    "    ]\n",
    "    \n",
    "    tech_job_patterns = [\n",
    "        'engineer', 'developer', 'programmer', 'analyst', 'architect', 'consultant',\n",
    "        'manager', 'director', 'lead', 'specialist', 'technician', 'designer',\n",
    "        'data scientist', 'data analyst', 'product manager', 'technical', 'systems',\n",
    "        'network', 'security', 'cloud', 'devops', 'platform', 'infrastructure',\n",
    "        'database', 'qa', 'quality assurance', 'test', 'automation', 'scrum',\n",
    "        'agile', 'product owner', 'business analyst', 'technical writer', 'support'\n",
    "    ]\n",
    "    \n",
    "    def is_tech_worker(industry, title):\n",
    "        if pd.isna(industry) and pd.isna(title):\n",
    "            return False\n",
    "        \n",
    "        # Check industry\n",
    "        if not pd.isna(industry):\n",
    "            industry_lower = str(industry).lower()\n",
    "            for tech_ind in tech_industries:\n",
    "                if tech_ind.lower() in industry_lower:\n",
    "                    return True\n",
    "        \n",
    "        # Check job title\n",
    "        if not pd.isna(title):\n",
    "            title_lower = str(title).lower()\n",
    "            for pattern in tech_job_patterns:\n",
    "                if pattern in title_lower:\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    df_us['is_tech_worker'] = df_us.apply(\n",
    "        lambda row: is_tech_worker(row[industry_col], row[job_title_col]), \n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"‚úÖ Identified tech workers from raw data\")\n",
    "\n",
    "# Check if we have state data\n",
    "if 'state_clean' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to clean state data...\")\n",
    "\n",
    "    # Quick state cleaning\n",
    "    state_col = 'If you\\'re in the U.S., what state do you work in?'\n",
    "    \n",
    "    # Basic state mapping (most common ones)\n",
    "    state_mapping = {\n",
    "        'CA': 'California', 'NY': 'New York', 'TX': 'Texas', 'FL': 'Florida',\n",
    "        'IL': 'Illinois', 'PA': 'Pennsylvania', 'OH': 'Ohio', 'GA': 'Georgia',\n",
    "        'NC': 'North Carolina', 'MI': 'Michigan', 'NJ': 'New Jersey', 'VA': 'Virginia',\n",
    "        'WA': 'Washington', 'AZ': 'Arizona', 'MA': 'Massachusetts', 'TN': 'Tennessee',\n",
    "        'IN': 'Indiana', 'MO': 'Missouri', 'MD': 'Maryland', 'WI': 'Wisconsin',\n",
    "        'CO': 'Colorado', 'MN': 'Minnesota', 'SC': 'South Carolina', 'AL': 'Alabama',\n",
    "        'LA': 'Louisiana', 'KY': 'Kentucky', 'OR': 'Oregon', 'OK': 'Oklahoma',\n",
    "        'CT': 'Connecticut', 'UT': 'Utah', 'IA': 'Iowa', 'NV': 'Nevada',\n",
    "        'AR': 'Arkansas', 'MS': 'Mississippi', 'KS': 'Kansas', 'NM': 'New Mexico',\n",
    "        'NE': 'Nebraska', 'WV': 'West Virginia', 'ID': 'Idaho', 'HI': 'Hawaii',\n",
    "        'NH': 'New Hampshire', 'ME': 'Maine', 'MT': 'Montana', 'RI': 'Rhode Island',\n",
    "        'DE': 'Delaware', 'SD': 'South Dakota', 'ND': 'North Dakota', 'AK': 'Alaska',\n",
    "        'VT': 'Vermont', 'WY': 'Wyoming', 'DC': 'District of Columbia',\n",
    "        # Full names\n",
    "        'California': 'California', 'New York': 'New York', 'Texas': 'Texas',\n",
    "        'Florida': 'Florida', 'Illinois': 'Illinois', 'Pennsylvania': 'Pennsylvania',\n",
    "        'Ohio': 'Ohio', 'Georgia': 'Georgia', 'North Carolina': 'North Carolina',\n",
    "        'Michigan': 'Michigan', 'New Jersey': 'New Jersey', 'Virginia': 'Virginia',\n",
    "        'Washington': 'Washington', 'Arizona': 'Arizona', 'Massachusetts': 'Massachusetts',\n",
    "        'Tennessee': 'Tennessee', 'Indiana': 'Indiana', 'Missouri': 'Missouri',\n",
    "        'Maryland': 'Maryland', 'Wisconsin': 'Wisconsin', 'Colorado': 'Colorado',\n",
    "        'Minnesota': 'Minnesota', 'South Carolina': 'South Carolina', 'Alabama': 'Alabama',\n",
    "        'Louisiana': 'Louisiana', 'Kentucky': 'Kentucky', 'Oregon': 'Oregon',\n",
    "        'Oklahoma': 'Oklahoma', 'Connecticut': 'Connecticut', 'Utah': 'Utah',\n",
    "        'Iowa': 'Iowa', 'Nevada': 'Nevada', 'Arkansas': 'Arkansas', 'Mississippi': 'Mississippi',\n",
    "        'Kansas': 'Kansas', 'New Mexico': 'New Mexico', 'Nebraska': 'Nebraska',\n",
    "        'West Virginia': 'West Virginia', 'Idaho': 'Idaho', 'Hawaii': 'Hawaii',\n",
    "        'New Hampshire': 'New Hampshire', 'Maine': 'Maine', 'Montana': 'Montana',\n",
    "        'Rhode Island': 'Rhode Island', 'Delaware': 'Delaware', 'South Dakota': 'South Dakota',\n",
    "        'North Dakota': 'North Dakota', 'Alaska': 'Alaska', 'Vermont': 'Vermont',\n",
    "        'Wyoming': 'Wyoming', 'District of Columbia': 'District of Columbia',\n",
    "        'Washington DC': 'District of Columbia', 'Washington, DC': 'District of Columbia',\n",
    "        'Washington D.C.': 'District of Columbia', 'D.C.': 'District of Columbia'\n",
    "    }\n",
    "\n",
    "    df_us['state_clean'] = df_us[state_col].replace(state_mapping)\n",
    "    print(f\"‚úÖ Cleaned state data\")\n",
    "\n",
    "# Filter for tech workers with valid salaries and states\n",
    "tech_workers_with_data = df_us[\n",
    "    (df_us['is_tech_worker'] == True) & \n",
    "    (df_us['salary_usd'].notna()) & \n",
    "    (df_us['state_clean'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Tech Worker Data:\")\n",
    "print(f\"Total tech workers: {df_us['is_tech_worker'].sum():,}\")\n",
    "print(f\"Tech workers with valid salary and state data: {len(tech_workers_with_data):,}\")\n",
    "\n",
    "if len(tech_workers_with_data) == 0:\n",
    "    print(\"‚ùå No tech workers with valid salary and state data found!\")\n",
    "    print(\"Let's check what we have...\")\n",
    "    print(f\"Total records: {len(df_us):,}\")\n",
    "    print(f\"Tech workers: {df_us['is_tech_worker'].sum():,}\")\n",
    "    print(f\"Records with salary data: {df_us['salary_usd'].notna().sum():,}\")\n",
    "    print(f\"Records with state data: {df_us['state_clean'].notna().sum():,}\")\n",
    "else:\n",
    "    # Calculate average salary by state\n",
    "    state_salary_stats = tech_workers_with_data.groupby('state_clean')['salary_usd'].agg([\n",
    "        'count', 'mean', 'median', 'std'\n",
    "    ]).round(0)\n",
    "    \n",
    "    # Filter states with at least 5 tech workers for statistical significance\n",
    "    state_salary_stats = state_salary_stats[state_salary_stats['count'] >= 5]\n",
    "    \n",
    "    # Sort by average salary (descending)\n",
    "    state_salary_stats = state_salary_stats.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüí∞ TECH WORKER SALARY BY STATE (Top 15):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'State':<20} {'Count':<8} {'Avg Salary':<12} {'Median':<12} {'Std Dev':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for state, row in state_salary_stats.head(15).iterrows():\n",
    "        print(f\"{state:<20} {int(row['count']):<8} ${row['mean']:,.0f}     ${row['median']:,.0f}     ${row['std']:,.0f}\")\n",
    "    \n",
    "    # Get the state with highest average salary\n",
    "    highest_paying_state = state_salary_stats.index[0]\n",
    "    highest_avg_salary = state_salary_stats.iloc[0]['mean']\n",
    "    state_count = int(state_salary_stats.iloc[0]['count'])\n",
    "    \n",
    "    print(f\"\\nüéØ ANSWER TO QUESTION 2:\")\n",
    "    print(f\"The US state with the highest average salary for tech workers is {highest_paying_state}\")\n",
    "    print(f\"Average salary: ${highest_avg_salary:,.0f}\")\n",
    "    print(f\"Based on {state_count} tech workers in {highest_paying_state}\")\n",
    "    \n",
    "    # Show top 5 states for context\n",
    "    print(f\"\\nüèÜ TOP 5 STATES BY AVERAGE TECH WORKER SALARY:\")\n",
    "    for i, (state, row) in enumerate(state_salary_stats.head(5).iterrows(), 1):\n",
    "        print(f\"{i}. {state}: ${row['mean']:,.0f} (n={int(row['count'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: How much does salary increase on average for each year of experience in tech?\n",
    "\n",
    "print(\"üìà QUESTION 3: Experience vs Salary Analysis for Tech Workers\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if we have experience data cleaned\n",
    "if 'experience_years' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to convert experience ranges to numeric values...\")\n",
    "    \n",
    "    # Quick experience conversion from raw data\n",
    "    exp_col = 'How many years of professional work experience do you have overall?'\n",
    "    \n",
    "    # Define experience mapping (using midpoints of ranges)\n",
    "    experience_mapping = {\n",
    "        '1 year or less': 0.5,\n",
    "        '2 - 4 years': 3,\n",
    "        '5-7 years': 6,\n",
    "        '8 - 10 years': 9,\n",
    "        '11 - 20 years': 15.5,\n",
    "        '21 - 30 years': 25.5,\n",
    "        '31 - 40 years': 35.5,\n",
    "        '41 years or more': 45\n",
    "    }\n",
    "    \n",
    "    df_us['experience_years'] = df_us[exp_col].replace(experience_mapping)\n",
    "    print(f\"‚úÖ Converted experience ranges to numeric values\")\n",
    "\n",
    "# Filter for tech workers with valid salary and experience data\n",
    "tech_workers_with_exp = df_us[\n",
    "    (df_us['is_tech_worker'] == True) & \n",
    "    (df_us['salary_usd'].notna()) & \n",
    "    (df_us['experience_years'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Tech Worker Experience Data:\")\n",
    "print(f\"Tech workers with valid salary and experience: {len(tech_workers_with_exp):,}\")\n",
    "\n",
    "if len(tech_workers_with_exp) == 0:\n",
    "    print(\"‚ùå No tech workers with valid salary and experience data found!\")\n",
    "    print(\"Let's check what we have...\")\n",
    "    print(f\"Tech workers: {df_us['is_tech_worker'].sum():,}\")\n",
    "    print(f\"Records with salary data: {df_us['salary_usd'].notna().sum():,}\")\n",
    "    print(f\"Records with experience data: {df_us['experience_years'].notna().sum():,}\")\n",
    "else:\n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìà EXPERIENCE STATISTICS:\")\n",
    "    print(f\"Experience range: {tech_workers_with_exp['experience_years'].min():.1f} - {tech_workers_with_exp['experience_years'].max():.1f} years\")\n",
    "    print(f\"Average experience: {tech_workers_with_exp['experience_years'].mean():.1f} years\")\n",
    "    print(f\"Median experience: {tech_workers_with_exp['experience_years'].median():.1f} years\")\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = tech_workers_with_exp['experience_years'].corr(tech_workers_with_exp['salary_usd'])\n",
    "    print(f\"Correlation between experience and salary: {correlation:.3f}\")\n",
    "    \n",
    "    # Linear regression analysis\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Perform linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "        tech_workers_with_exp['experience_years'], \n",
    "        tech_workers_with_exp['salary_usd']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüî¨ LINEAR REGRESSION ANALYSIS:\")\n",
    "    print(f\"Slope (salary increase per year): ${slope:,.0f}\")\n",
    "    print(f\"Intercept (starting salary at 0 years): ${intercept:,.0f}\")\n",
    "    print(f\"R-squared: {r_value**2:.3f}\")\n",
    "    print(f\"P-value: {p_value:.2e}\")\n",
    "    print(f\"Standard error: ${std_err:,.0f}\")\n",
    "    \n",
    "    # Calculate salary increase per year\n",
    "    salary_increase_per_year = slope\n",
    "\n",
    "    print(f\"\\nüéØ ANSWER TO QUESTION 3:\")\n",
    "    print(f\"On average, salary increases by ${salary_increase_per_year:,.0f} per year of experience in tech\")\n",
    "    print(f\"This is based on {len(tech_workers_with_exp):,} tech workers\")\n",
    "    \n",
    "    # Additional insights\n",
    "    print(f\"\\nüí° ADDITIONAL INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ R-squared of {r_value**2:.3f} means experience explains {r_value**2*100:.1f}% of salary variation\")\n",
    "    print(f\"‚Ä¢ Starting salary (0 years experience): ${intercept:,.0f}\")\n",
    "    print(f\"‚Ä¢ Expected salary at 5 years: ${intercept + slope*5:,.0f}\")\n",
    "    print(f\"‚Ä¢ Expected salary at 10 years: ${intercept + slope*10:,.0f}\")\n",
    "    print(f\"‚Ä¢ Expected salary at 20 years: ${intercept + slope*20:,.0f}\")\n",
    "    \n",
    "    # Experience level analysis\n",
    "    print(f\"\\nüìä SALARY BY EXPERIENCE LEVEL:\")\n",
    "    exp_levels = tech_workers_with_exp.groupby('experience_years')['salary_usd'].agg([\n",
    "        'count', 'mean', 'median', 'std'\n",
    "    ]).round(0)\n",
    "    \n",
    "    # Filter for experience levels with at least 3 people\n",
    "    exp_levels = exp_levels[exp_levels['count'] >= 3]\n",
    "    \n",
    "    print(f\"{'Experience':<12} {'Count':<8} {'Avg Salary':<12} {'Median':<12} {'Std Dev':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    for exp_years, row in exp_levels.iterrows():\n",
    "        print(f\"{exp_years:<12.1f} {int(row['count']):<8} ${row['mean']:,.0f}     ${row['median']:,.0f}     ${row['std']:,.0f}\")\n",
    "    \n",
    "    # Calculate actual vs predicted salaries for key experience levels\n",
    "    print(f\"\\nüîç ACTUAL VS PREDICTED SALARIES:\")\n",
    "    key_experience_levels = [0.5, 3, 6, 9, 15.5, 25.5]\n",
    "    print(f\"{'Experience':<12} {'Predicted':<12} {'Actual Avg':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for exp in key_experience_levels:\n",
    "        predicted = intercept + slope * exp\n",
    "        actual_data = tech_workers_with_exp[tech_workers_with_exp['experience_years'] == exp]\n",
    "        if len(actual_data) > 0:\n",
    "            actual_avg = actual_data['salary_usd'].mean()\n",
    "            difference = actual_avg - predicted\n",
    "            print(f\"{exp:<12.1f} ${predicted:,.0f}     ${actual_avg:,.0f}     ${difference:,.0f}\")\n",
    "        else:\n",
    "            print(f\"{exp:<12.1f} ${predicted:,.0f}     N/A         N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Question 4: What percentage of respondents work remotely vs. in-office?\n",
    "\n",
    "print(\"üè† QUESTION 4: Remote Work vs In-Office Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, let's check what columns we have that might indicate remote work\n",
    "print(\"üîç Checking for remote work indicators in the dataset...\")\n",
    "\n",
    "# Look for columns that might contain remote work information\n",
    "potential_remote_columns = []\n",
    "for col in df_us.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['remote', 'location', 'work', 'office', 'city']):\n",
    "        potential_remote_columns.append(col)\n",
    "\n",
    "print(f\"Potential remote work related columns: {potential_remote_columns}\")\n",
    "\n",
    "# Check the city column for remote work indicators\n",
    "city_col = 'What city do you work in?'\n",
    "if city_col in df_us.columns:\n",
    "    print(f\"\\nüìä Analyzing city data for remote work patterns...\")\n",
    "    \n",
    "    # Look for common remote work indicators in city data\n",
    "    city_data = df_us[city_col].fillna('').astype(str)\n",
    "    \n",
    "    # Common remote work indicators\n",
    "    remote_indicators = [\n",
    "        'remote', 'work from home', 'wfh', 'virtual', 'online', 'telecommute',\n",
    "        'home office', 'distributed', 'anywhere', 'flexible location'\n",
    "    ]\n",
    "\n",
    "    # Check for remote work patterns\n",
    "    remote_mask = city_data.str.lower().str.contains('|'.join(remote_indicators), na=False)\n",
    "    remote_count = remote_mask.sum()\n",
    "    \n",
    "    # Also check for empty or generic city entries that might indicate remote work\n",
    "    empty_city_mask = (city_data == '') | (city_data == 'nan') | (city_data.isin(['N/A', 'n/a', 'None', 'none']))\n",
    "    empty_city_count = empty_city_mask.sum()\n",
    "    \n",
    "    # Check for specific remote work entries\n",
    "    explicit_remote_mask = city_data.str.lower().str.contains('remote', na=False)\n",
    "    explicit_remote_count = explicit_remote_mask.sum()\n",
    "    \n",
    "    print(f\"üìà Remote Work Analysis Results:\")\n",
    "    print(f\"Total respondents: {len(df_us):,}\")\n",
    "    print(f\"Explicit 'remote' in city: {explicit_remote_count:,}\")\n",
    "    print(f\"Any remote indicators: {remote_count:,}\")\n",
    "    print(f\"Empty/missing city data: {empty_city_count:,}\")\n",
    "    \n",
    "    # Create remote work classification\n",
    "    df_us['work_location_type'] = 'In-Office'\n",
    "    \n",
    "    # Mark as remote if explicit remote indicators\n",
    "    df_us.loc[remote_mask, 'work_location_type'] = 'Remote'\n",
    "    \n",
    "    # Mark as 'Unknown' if city data is missing/empty\n",
    "    df_us.loc[empty_city_mask, 'work_location_type'] = 'Unknown'\n",
    "    \n",
    "    # Calculate percentages\n",
    "    location_counts = df_us['work_location_type'].value_counts()\n",
    "    location_percentages = df_us['work_location_type'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"\\nüè† WORK LOCATION BREAKDOWN:\")\n",
    "    print(\"=\" * 50)\n",
    "    for location_type in ['Remote', 'In-Office', 'Unknown']:\n",
    "        if location_type in location_counts:\n",
    "            count = location_counts[location_type]\n",
    "            percentage = location_percentages[location_type]\n",
    "            print(f\"{location_type:<10}: {count:>6,} ({percentage:>5.1f}%)\")\n",
    "\n",
    "    # Show some examples of remote work entries\n",
    "    if explicit_remote_count > 0:\n",
    "        print(f\"\\nüîç Examples of Remote Work Entries:\")\n",
    "        remote_examples = df_us[df_us['work_location_type'] == 'Remote'][city_col].value_counts().head(10)\n",
    "        for city, count in remote_examples.items():\n",
    "            print(f\"  ‚Ä¢ {city}: {count} people\")\n",
    "    \n",
    "    # Show some examples of in-office entries\n",
    "    print(f\"\\nüè¢ Examples of In-Office Entries:\")\n",
    "    in_office_examples = df_us[df_us['work_location_type'] == 'In-Office'][city_col].value_counts().head(10)\n",
    "    for city, count in in_office_examples.items():\n",
    "        print(f\"  ‚Ä¢ {city}: {count} people\")\n",
    "    \n",
    "    # Answer the question\n",
    "    remote_percentage = location_percentages.get('Remote', 0)\n",
    "    in_office_percentage = location_percentages.get('In-Office', 0)\n",
    "    unknown_percentage = location_percentages.get('Unknown', 0)\n",
    "    \n",
    "    print(f\"\\nüéØ ANSWER TO QUESTION 4:\")\n",
    "    print(f\"Remote work: {remote_percentage:.1f}% of respondents\")\n",
    "    print(f\"In-office work: {in_office_percentage:.1f}% of respondents\")\n",
    "    print(f\"Unknown/Unclear: {unknown_percentage:.1f}% of respondents\")\n",
    "    \n",
    "    # Additional analysis by industry\n",
    "    if 'What industry do you work in?' in df_us.columns:\n",
    "        print(f\"\\nüè≠ Remote Work by Industry (Top 10):\")\n",
    "        industry_remote = df_us.groupby('What industry do you work in?')['work_location_type'].apply(\n",
    "            lambda x: (x == 'Remote').sum() / len(x) * 100\n",
    "        ).sort_values(ascending=False)\n",
    "        \n",
    "        for industry, remote_pct in industry_remote.head(10).items():\n",
    "            total_in_industry = len(df_us[df_us['What industry do you work in?'] == industry])\n",
    "            remote_count = len(df_us[(df_us['What industry do you work in?'] == industry) & \n",
    "                                   (df_us['work_location_type'] == 'Remote')])\n",
    "            print(f\"  ‚Ä¢ {industry}: {remote_pct:.1f}% remote ({remote_count}/{total_in_industry})\")\n",
    "    \n",
    "    # Analysis by tech vs non-tech\n",
    "    if 'is_tech_worker' in df_us.columns:\n",
    "        print(f\"\\nüíª Remote Work: Tech vs Non-Tech:\")\n",
    "        tech_remote_pct = (df_us[df_us['is_tech_worker'] == True]['work_location_type'] == 'Remote').mean() * 100\n",
    "        non_tech_remote_pct = (df_us[df_us['is_tech_worker'] == False]['work_location_type'] == 'Remote').mean() * 100\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Tech workers: {tech_remote_pct:.1f}% remote\")\n",
    "        print(f\"  ‚Ä¢ Non-tech workers: {non_tech_remote_pct:.1f}% remote\")\n",
    "        \n",
    "        # Statistical test\n",
    "        from scipy.stats import chi2_contingency\n",
    "        \n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(df_us['is_tech_worker'], df_us['work_location_type'] == 'Remote')\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Chi-square test p-value: {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(f\"  ‚Ä¢ Significant difference between tech and non-tech remote work rates\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ No significant difference between tech and non-tech remote work rates\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No city column found in the dataset\")\n",
    "    print(\"Available columns:\")\n",
    "    for i, col in enumerate(df_us.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Which industry (besides tech) has the highest median salary?\n",
    "\n",
    "print(\"üè≠ QUESTION 5: Non-Tech Industry Median Salary Analysis\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Ensure we have tech worker classification\n",
    "if 'is_tech_worker' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to identify tech workers from raw data...\")\n",
    "    \n",
    "    # Quick tech worker identification from raw data\n",
    "    industry_col = 'What industry do you work in?'\n",
    "    job_title_col = 'Job title'\n",
    "    \n",
    "    # Define tech industry and job patterns\n",
    "    tech_industries = [\n",
    "        'Computing or Tech', 'Technology', 'Software', 'IT', 'Information Technology',\n",
    "        'Computer', 'Tech', 'Digital', 'Cybersecurity', 'Data', 'AI', 'Machine Learning'\n",
    "    ]\n",
    "    \n",
    "    tech_job_patterns = [\n",
    "        'engineer', 'developer', 'programmer', 'analyst', 'architect', 'consultant',\n",
    "        'manager', 'director', 'lead', 'specialist', 'technician', 'designer',\n",
    "        'data scientist', 'data analyst', 'product manager', 'technical', 'systems',\n",
    "        'network', 'security', 'cloud', 'devops', 'platform', 'infrastructure',\n",
    "        'database', 'qa', 'quality assurance', 'test', 'automation', 'scrum',\n",
    "        'agile', 'product owner', 'business analyst', 'technical writer', 'support'\n",
    "    ]\n",
    "    \n",
    "    def is_tech_worker(industry, title):\n",
    "        if pd.isna(industry) and pd.isna(title):\n",
    "            return False\n",
    "        \n",
    "        # Check industry\n",
    "        if not pd.isna(industry):\n",
    "            industry_lower = str(industry).lower()\n",
    "            for tech_ind in tech_industries:\n",
    "                if tech_ind.lower() in industry_lower:\n",
    "                    return True\n",
    "        \n",
    "        # Check job title\n",
    "        if not pd.isna(title):\n",
    "            title_lower = str(title).lower()\n",
    "            for pattern in tech_job_patterns:\n",
    "                if pattern in title_lower:\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    df_us['is_tech_worker'] = df_us.apply(\n",
    "        lambda row: is_tech_worker(row[industry_col], row[job_title_col]), \n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"‚úÖ Identified tech workers from raw data\")\n",
    "\n",
    "# Filter for non-tech workers with valid salaries\n",
    "non_tech_with_salary = df_us[\n",
    "    (df_us['is_tech_worker'] == False) & \n",
    "    (df_us['salary_usd'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Non-Tech Industry Data:\")\n",
    "print(f\"Total non-tech workers: {(df_us['is_tech_worker'] == False).sum():,}\")\n",
    "print(f\"Non-tech workers with valid salaries: {len(non_tech_with_salary):,}\")\n",
    "\n",
    "if len(non_tech_with_salary) == 0:\n",
    "    print(\"‚ùå No non-tech workers with valid salary data found!\")\n",
    "    print(\"Let's check what we have...\")\n",
    "    print(f\"Total records: {len(df_us):,}\")\n",
    "    print(f\"Tech workers: {df_us['is_tech_worker'].sum():,}\")\n",
    "    print(f\"Non-tech workers: {(df_us['is_tech_worker'] == False).sum():,}\")\n",
    "    print(f\"Records with salary data: {df_us['salary_usd'].notna().sum():,}\")\n",
    "else:\n",
    "    # Calculate median salary by industry for non-tech workers\n",
    "    industry_salary_stats = non_tech_with_salary.groupby('What industry do you work in?')['salary_usd'].agg([\n",
    "        'count', 'median', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(0)\n",
    "\n",
    "    # Filter industries with at least 10 workers for statistical significance\n",
    "    industry_salary_stats = industry_salary_stats[industry_salary_stats['count'] >= 10]\n",
    "    \n",
    "    # Sort by median salary (descending)\n",
    "    industry_salary_stats = industry_salary_stats.sort_values('median', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüí∞ NON-TECH INDUSTRY MEDIAN SALARIES (Top 15):\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"{'Industry':<35} {'Count':<8} {'Median':<10} {'Mean':<10} {'Min':<10} {'Max':<10}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for industry, row in industry_salary_stats.head(15).iterrows():\n",
    "        print(f\"{industry:<35} {int(row['count']):<8} ${row['median']:,.0f}   ${row['mean']:,.0f}   ${row['min']:,.0f}   ${row['max']:,.0f}\")\n",
    "    \n",
    "    # Get the industry with highest median salary\n",
    "    highest_median_industry = industry_salary_stats.index[0]\n",
    "    highest_median_salary = industry_salary_stats.iloc[0]['median']\n",
    "    industry_count = int(industry_salary_stats.iloc[0]['count'])\n",
    "    \n",
    "    print(f\"\\nüéØ ANSWER TO QUESTION 5:\")\n",
    "    print(f\"The non-tech industry with the highest median salary is: {highest_median_industry}\")\n",
    "    print(f\"Median salary: ${highest_median_salary:,.0f}\")\n",
    "    print(f\"Based on {industry_count} workers in {highest_median_industry}\")\n",
    "    \n",
    "    # Show top 10 industries for context\n",
    "    print(f\"\\nüèÜ TOP 10 NON-TECH INDUSTRIES BY MEDIAN SALARY:\")\n",
    "    for i, (industry, row) in enumerate(industry_salary_stats.head(10).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {industry}: ${row['median']:,.0f} (n={int(row['count'])})\")\n",
    "    \n",
    "    # Additional analysis: Compare with tech industry\n",
    "    if 'is_tech_worker' in df_us.columns:\n",
    "        tech_median = df_us[df_us['is_tech_worker'] == True]['salary_usd'].median()\n",
    "        tech_count = (df_us['is_tech_worker'] == True).sum()\n",
    "\n",
    "        print(f\"\\nüíª COMPARISON WITH TECH INDUSTRY:\")\n",
    "        print(f\"Tech industry median salary: ${tech_median:,.0f} (n={tech_count:,})\")\n",
    "        print(f\"Highest non-tech industry: ${highest_median_salary:,.0f} ({highest_median_industry})\")\n",
    "        \n",
    "        if highest_median_salary > tech_median:\n",
    "            difference = highest_median_salary - tech_median\n",
    "            print(f\"Non-tech leader is ${difference:,.0f} higher than tech median\")\n",
    "        else:\n",
    "            difference = tech_median - highest_median_salary\n",
    "            print(f\"Tech median is ${difference:,.0f} higher than non-tech leader\")\n",
    "    \n",
    "    # Show salary distribution for the top industry\n",
    "    top_industry_data = non_tech_with_salary[\n",
    "        non_tech_with_salary['What industry do you work in?'] == highest_median_industry\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìä DETAILED ANALYSIS: {highest_median_industry}\")\n",
    "    print(f\"Sample size: {len(top_industry_data):,} workers\")\n",
    "    print(f\"Median salary: ${top_industry_data['salary_usd'].median():,.0f}\")\n",
    "    print(f\"Mean salary: ${top_industry_data['salary_usd'].mean():,.0f}\")\n",
    "    print(f\"25th percentile: ${top_industry_data['salary_usd'].quantile(0.25):,.0f}\")\n",
    "    print(f\"75th percentile: ${top_industry_data['salary_usd'].quantile(0.75):,.0f}\")\n",
    "    print(f\"Salary range: ${top_industry_data['salary_usd'].min():,.0f} - ${top_industry_data['salary_usd'].max():,.0f}\")\n",
    "    \n",
    "    # Show some job titles from the top industry\n",
    "    print(f\"\\nüíº Sample job titles in {highest_median_industry}:\")\n",
    "    job_titles = top_industry_data['Job title'].value_counts().head(10)\n",
    "    for title, count in job_titles.items():\n",
    "        print(f\"  ‚Ä¢ {title}: {count} people\")\n",
    "    \n",
    "    # Industry insights\n",
    "    print(f\"\\nüí° INDUSTRY INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ {len(industry_salary_stats)} non-tech industries have at least 10 workers\")\n",
    "    print(f\"‚Ä¢ Median salary range: ${industry_salary_stats['median'].min():,.0f} - ${industry_salary_stats['median'].max():,.0f}\")\n",
    "    print(f\"‚Ä¢ Average sample size per industry: {industry_salary_stats['count'].mean():.1f} workers\")\n",
    "    \n",
    "    # Show industries with highest and lowest median salaries\n",
    "    lowest_median_industry = industry_salary_stats.index[-1]\n",
    "    lowest_median_salary = industry_salary_stats.iloc[-1]['median']\n",
    "    \n",
    "    print(f\"‚Ä¢ Lowest median salary: {lowest_median_industry} (${lowest_median_salary:,.0f})\")\n",
    "    print(f\"‚Ä¢ Salary gap between highest and lowest: ${highest_median_salary - lowest_median_salary:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Questions:\n",
    "# Question 6: What's the salary gap between men and women in similar roles?\n",
    "# Question 7: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "# Question 8: Which company size (startup, medium, large) pays the most on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Question 6: What's the salary gap between men and women in similar roles?\n",
    "\n",
    "print(\"üë• BONUS QUESTION 6: Gender Salary Gap Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if we have gender data cleaned\n",
    "if 'gender_clean' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to clean gender data...\")\n",
    "    \n",
    "    # Quick gender cleaning\n",
    "    gender_col = 'What is your gender?'\n",
    "    gender_mapping = {\n",
    "        'Man': 'Man',\n",
    "        'Woman': 'Woman',\n",
    "        'Non-binary': 'Non-binary',\n",
    "        'Another option not listed here or prefer not to answer': 'Other/Prefer not to answer',\n",
    "        'Prefer not to answer': 'Other/Prefer not to answer'\n",
    "    }\n",
    "    \n",
    "    df_us['gender_clean'] = df_us[gender_col].replace(gender_mapping)\n",
    "    print(f\"‚úÖ Cleaned gender data\")\n",
    "\n",
    "# Filter for men and women with valid salaries\n",
    "gender_salary_data = df_us[\n",
    "    (df_us['gender_clean'].isin(['Man', 'Woman'])) & \n",
    "    (df_us['salary_usd'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Gender Salary Data:\")\n",
    "print(f\"Men with valid salaries: {len(gender_salary_data[gender_salary_data['gender_clean'] == 'Man']):,}\")\n",
    "print(f\"Women with valid salaries: {len(gender_salary_data[gender_salary_data['gender_clean'] == 'Woman']):,}\")\n",
    "\n",
    "if len(gender_salary_data) == 0:\n",
    "    print(\"‚ùå No gender salary data found!\")\n",
    "else:\n",
    "    # Calculate overall gender salary gap\n",
    "    men_salaries = gender_salary_data[gender_salary_data['gender_clean'] == 'Man']['salary_usd']\n",
    "    women_salaries = gender_salary_data[gender_salary_data['gender_clean'] == 'Woman']['salary_usd']\n",
    "    \n",
    "    men_median = men_salaries.median()\n",
    "    women_median = women_salaries.median()\n",
    "    men_mean = men_salaries.mean()\n",
    "    women_mean = women_salaries.mean()\n",
    "    \n",
    "    # Calculate gaps\n",
    "    median_gap = men_median - women_median\n",
    "    mean_gap = men_mean - women_mean\n",
    "    median_gap_pct = (median_gap / women_median) * 100\n",
    "    mean_gap_pct = (mean_gap / women_mean) * 100\n",
    "    \n",
    "    print(f\"\\nüí∞ OVERALL GENDER SALARY GAP:\")\n",
    "    print(f\"Men median salary: ${men_median:,.0f}\")\n",
    "    print(f\"Women median salary: ${women_median:,.0f}\")\n",
    "    print(f\"Median gap: ${median_gap:,.0f} ({median_gap_pct:.1f}%)\")\n",
    "    print(f\"Men mean salary: ${men_mean:,.0f}\")\n",
    "    print(f\"Women mean salary: ${women_mean:,.0f}\")\n",
    "    print(f\"Mean gap: ${mean_gap:,.0f} ({mean_gap_pct:.1f}%)\")\n",
    "\n",
    "    # Statistical test\n",
    "    from scipy import stats\n",
    "    t_stat, p_value = stats.ttest_ind(men_salaries, women_salaries)\n",
    "    \n",
    "    print(f\"\\nüî¨ STATISTICAL TEST:\")\n",
    "    print(f\"T-test p-value: {p_value:.2e}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Significant difference between men and women salaries (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"No significant difference between men and women salaries (p ‚â• 0.05)\")\n",
    "    \n",
    "    # Analysis by tech vs non-tech\n",
    "    if 'is_tech_worker' in df_us.columns:\n",
    "        print(f\"\\nüíª GENDER GAP BY SECTOR:\")\n",
    "        \n",
    "        # Tech workers\n",
    "        tech_men = gender_salary_data[\n",
    "            (gender_salary_data['gender_clean'] == 'Man') & \n",
    "            (gender_salary_data['is_tech_worker'] == True)\n",
    "        ]['salary_usd']\n",
    "        tech_women = gender_salary_data[\n",
    "            (gender_salary_data['gender_clean'] == 'Woman') & \n",
    "            (gender_salary_data['is_tech_worker'] == True)\n",
    "        ]['salary_usd']\n",
    "        \n",
    "        if len(tech_men) > 0 and len(tech_women) > 0:\n",
    "            tech_men_median = tech_men.median()\n",
    "            tech_women_median = tech_women.median()\n",
    "            tech_gap = tech_men_median - tech_women_median\n",
    "            tech_gap_pct = (tech_gap / tech_women_median) * 100\n",
    "            \n",
    "            print(f\"Tech - Men median: ${tech_men_median:,.0f}, Women median: ${tech_women_median:,.0f}\")\n",
    "            print(f\"Tech gap: ${tech_gap:,.0f} ({tech_gap_pct:.1f}%)\")\n",
    "\n",
    "        # Non-tech workers\n",
    "        non_tech_men = gender_salary_data[\n",
    "            (gender_salary_data['gender_clean'] == 'Man') & \n",
    "            (gender_salary_data['is_tech_worker'] == False)\n",
    "        ]['salary_usd']\n",
    "        non_tech_women = gender_salary_data[\n",
    "            (gender_salary_data['gender_clean'] == 'Woman') & \n",
    "            (gender_salary_data['is_tech_worker'] == False)\n",
    "        ]['salary_usd']\n",
    "        \n",
    "        if len(non_tech_men) > 0 and len(non_tech_women) > 0:\n",
    "            non_tech_men_median = non_tech_men.median()\n",
    "            non_tech_women_median = non_tech_women.median()\n",
    "            non_tech_gap = non_tech_men_median - non_tech_women_median\n",
    "            non_tech_gap_pct = (non_tech_gap / non_tech_women_median) * 100\n",
    "            \n",
    "            print(f\"Non-tech - Men median: ${non_tech_men_median:,.0f}, Women median: ${non_tech_women_median:,.0f}\")\n",
    "            print(f\"Non-tech gap: ${non_tech_gap:,.0f} ({non_tech_gap_pct:.1f}%)\")\n",
    "    \n",
    "    # Analysis by experience level (similar roles)\n",
    "    if 'experience_years' in df_us.columns:\n",
    "        print(f\"\\nüìà GENDER GAP BY EXPERIENCE LEVEL:\")\n",
    "        \n",
    "        # Group by experience ranges\n",
    "        gender_salary_data['exp_range'] = pd.cut(\n",
    "            gender_salary_data['experience_years'], \n",
    "            bins=[0, 5, 10, 20, 50], \n",
    "            labels=['0-5 years', '5-10 years', '10-20 years', '20+ years']\n",
    "        )\n",
    "\n",
    "        for exp_range in ['0-5 years', '5-10 years', '10-20 years', '20+ years']:\n",
    "            exp_data = gender_salary_data[gender_salary_data['exp_range'] == exp_range]\n",
    "            if len(exp_data) > 0:\n",
    "                exp_men = exp_data[exp_data['gender_clean'] == 'Man']['salary_usd']\n",
    "                exp_women = exp_data[exp_data['gender_clean'] == 'Woman']['salary_usd']\n",
    "                \n",
    "                if len(exp_men) > 0 and len(exp_women) > 0:\n",
    "                    exp_men_median = exp_men.median()\n",
    "                    exp_women_median = exp_women.median()\n",
    "                    exp_gap = exp_men_median - exp_women_median\n",
    "                    exp_gap_pct = (exp_gap / exp_women_median) * 100\n",
    "                    \n",
    "                    print(f\"{exp_range}: Men ${exp_men_median:,.0f}, Women ${exp_women_median:,.0f}, Gap ${exp_gap:,.0f} ({exp_gap_pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüéØ ANSWER TO BONUS QUESTION 6:\")\n",
    "    print(f\"The overall salary gap between men and women is ${median_gap:,.0f} ({median_gap_pct:.1f}%)\")\n",
    "    print(f\"Men earn a median of ${men_median:,.0f} vs women's ${women_median:,.0f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"This difference is statistically significant (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"This difference is not statistically significant (p ‚â• 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Question 7: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "\n",
    "print(\"\\nüéì BONUS QUESTION 7: Education Level Salary Analysis\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Check if we have education data cleaned\n",
    "if 'education_clean' not in df_us.columns:\n",
    "    print(\"‚ö†Ô∏è Need to clean education data...\")\n",
    "    \n",
    "    # Quick education cleaning\n",
    "    edu_col = 'What is your highest level of education completed?'\n",
    "    education_mapping = {\n",
    "        'High School': 'High School',\n",
    "        'Some college': 'Some College',\n",
    "        'College degree': 'Bachelor\\'s Degree',\n",
    "        'Bachelor\\'s degree': 'Bachelor\\'s Degree',\n",
    "        'Master\\'s degree': 'Master\\'s Degree',\n",
    "        'PhD': 'PhD',\n",
    "        'Professional degree (MD, JD, etc.)': 'Professional Degree',\n",
    "        'Some high school': 'High School',\n",
    "        'Trade school': 'Trade School',\n",
    "        'Associate degree': 'Associate Degree'\n",
    "    }\n",
    "    \n",
    "    df_us['education_clean'] = df_us[edu_col].replace(education_mapping)\n",
    "    print(f\"‚úÖ Cleaned education data\")\n",
    "\n",
    "# Filter for Bachelor's and Master's degree holders with valid salaries\n",
    "education_salary_data = df_us[\n",
    "    (df_us['education_clean'].isin(['Bachelor\\'s Degree', 'Master\\'s Degree'])) & \n",
    "    (df_us['salary_usd'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Education Salary Data:\")\n",
    "bachelors_count = len(education_salary_data[education_salary_data['education_clean'] == 'Bachelor\\'s Degree'])\n",
    "masters_count = len(education_salary_data[education_salary_data['education_clean'] == 'Master\\'s Degree'])\n",
    "print(f\"Bachelor's degree holders with valid salaries: {bachelors_count:,}\")\n",
    "print(f\"Master's degree holders with valid salaries: {masters_count:,}\")\n",
    "\n",
    "if bachelors_count == 0 or masters_count == 0:\n",
    "    print(\"‚ùå Insufficient education salary data found!\")\n",
    "else:\n",
    "    # Calculate salary statistics for each education level\n",
    "    bachelors_salaries = education_salary_data[education_salary_data['education_clean'] == 'Bachelor\\'s Degree']['salary_usd']\n",
    "    masters_salaries = education_salary_data[education_salary_data['education_clean'] == 'Master\\'s Degree']['salary_usd']\n",
    "    \n",
    "    bachelors_median = bachelors_salaries.median()\n",
    "    masters_median = masters_salaries.median()\n",
    "    bachelors_mean = bachelors_salaries.mean()\n",
    "    masters_mean = masters_salaries.mean()\n",
    "    \n",
    "    # Calculate differences\n",
    "    median_diff = masters_median - bachelors_median\n",
    "    mean_diff = masters_mean - bachelors_mean\n",
    "    median_diff_pct = (median_diff / bachelors_median) * 100\n",
    "    mean_diff_pct = (mean_diff / bachelors_mean) * 100\n",
    "    \n",
    "    print(f\"\\nüí∞ EDUCATION LEVEL SALARY COMPARISON:\")\n",
    "    print(f\"Bachelor's median salary: ${bachelors_median:,.0f}\")\n",
    "    print(f\"Master's median salary: ${masters_median:,.0f}\")\n",
    "    print(f\"Median difference: ${median_diff:,.0f} ({median_diff_pct:.1f}%)\")\n",
    "    print(f\"Bachelor's mean salary: ${bachelors_mean:,.0f}\")\n",
    "    print(f\"Master's mean salary: ${masters_mean:,.0f}\")\n",
    "    print(f\"Mean difference: ${mean_diff:,.0f} ({mean_diff_pct:.1f}%)\")\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats\n",
    "    t_stat, p_value = stats.ttest_ind(masters_salaries, bachelors_salaries)\n",
    "    \n",
    "    print(f\"\\nüî¨ STATISTICAL TEST:\")\n",
    "    print(f\"T-test p-value: {p_value:.2e}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Significant difference between Master's and Bachelor's salaries (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"No significant difference between Master's and Bachelor's salaries (p ‚â• 0.05)\")\n",
    "    \n",
    "    # Analysis by tech vs non-tech\n",
    "    if 'is_tech_worker' in df_us.columns:\n",
    "        print(f\"\\nüíª EDUCATION IMPACT BY SECTOR:\")\n",
    "        \n",
    "        # Tech workers\n",
    "        tech_bachelors = education_salary_data[\n",
    "            (education_salary_data['education_clean'] == 'Bachelor\\'s Degree') & \n",
    "            (education_salary_data['is_tech_worker'] == True)\n",
    "        ]['salary_usd']\n",
    "        tech_masters = education_salary_data[\n",
    "            (education_salary_data['education_clean'] == 'Master\\'s Degree') & \n",
    "            (education_salary_data['is_tech_worker'] == True)\n",
    "        ]['salary_usd']\n",
    "        \n",
    "        if len(tech_bachelors) > 0 and len(tech_masters) > 0:\n",
    "            tech_bach_median = tech_bachelors.median()\n",
    "            tech_mast_median = tech_masters.median()\n",
    "            tech_diff = tech_mast_median - tech_bach_median\n",
    "            tech_diff_pct = (tech_diff / tech_bach_median) * 100\n",
    "            \n",
    "            print(f\"Tech - Bachelor's median: ${tech_bach_median:,.0f}, Master's median: ${tech_mast_median:,.0f}\")\n",
    "            print(f\"Tech difference: ${tech_diff:,.0f} ({tech_diff_pct:.1f}%)\")\n",
    "        \n",
    "        # Non-tech workers\n",
    "        non_tech_bachelors = education_salary_data[\n",
    "            (education_salary_data['education_clean'] == 'Bachelor\\'s Degree') & \n",
    "            (education_salary_data['is_tech_worker'] == False)\n",
    "        ]['salary_usd']\n",
    "        non_tech_masters = education_salary_data[\n",
    "            (education_salary_data['education_clean'] == 'Master\\'s Degree') & \n",
    "            (education_salary_data['is_tech_worker'] == False)\n",
    "        ]['salary_usd']\n",
    "        \n",
    "        if len(non_tech_bachelors) > 0 and len(non_tech_masters) > 0:\n",
    "            non_tech_bach_median = non_tech_bachelors.median()\n",
    "            non_tech_mast_median = non_tech_masters.median()\n",
    "            non_tech_diff = non_tech_mast_median - non_tech_bach_median\n",
    "            non_tech_diff_pct = (non_tech_diff / non_tech_bach_median) * 100\n",
    "\n",
    "            print(f\"Non-tech - Bachelor's median: ${non_tech_bach_median:,.0f}, Master's median: ${non_tech_mast_median:,.0f}\")\n",
    "            print(f\"Non-tech difference: ${non_tech_diff:,.0f} ({non_tech_diff_pct:.1f}%)\")\n",
    "    \n",
    "    # Analysis by experience level\n",
    "    if 'experience_years' in df_us.columns:\n",
    "        print(f\"\\nüìà EDUCATION IMPACT BY EXPERIENCE LEVEL:\")\n",
    "        \n",
    "        # Group by experience ranges\n",
    "        education_salary_data['exp_range'] = pd.cut(\n",
    "            education_salary_data['experience_years'], \n",
    "            bins=[0, 5, 10, 20, 50], \n",
    "            labels=['0-5 years', '5-10 years', '10-20 years', '20+ years']\n",
    "        )\n",
    "        \n",
    "        for exp_range in ['0-5 years', '5-10 years', '10-20 years', '20+ years']:\n",
    "            exp_data = education_salary_data[education_salary_data['exp_range'] == exp_range]\n",
    "            if len(exp_data) > 0:\n",
    "                exp_bachelors = exp_data[exp_data['education_clean'] == 'Bachelor\\'s Degree']['salary_usd']\n",
    "                exp_masters = exp_data[exp_data['education_clean'] == 'Master\\'s Degree']['salary_usd']\n",
    "                \n",
    "                if len(exp_bachelors) > 0 and len(exp_masters) > 0:\n",
    "                    exp_bach_median = exp_bachelors.median()\n",
    "                    exp_mast_median = exp_masters.median()\n",
    "                    exp_diff = exp_mast_median - exp_bach_median\n",
    "                    exp_diff_pct = (exp_diff / exp_bach_median) * 100\n",
    "                    \n",
    "                    print(f\"{exp_range}: Bachelor's ${exp_bach_median:,.0f}, Master's ${exp_mast_median:,.0f}, Diff ${exp_diff:,.0f} ({exp_diff_pct:.1f}%)\")\n",
    "    \n",
    "    # ROI Analysis (if we had cost data, we'd calculate ROI)\n",
    "    print(f\"\\nüí° EDUCATION ROI INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ Master's degree holders earn ${median_diff:,.0f} more per year on average\")\n",
    "    print(f\"‚Ä¢ This represents a {median_diff_pct:.1f}% salary premium\")\n",
    "    print(f\"‚Ä¢ Over a 30-year career, this could amount to ${median_diff * 30:,.0f} in additional earnings\")\n",
    "    \n",
    "    print(f\"\\nüéØ ANSWER TO BONUS QUESTION 7:\")\n",
    "    if median_diff > 0:\n",
    "        print(f\"Yes, people with Master's degrees earn significantly more than those with Bachelor's degrees\")\n",
    "        print(f\"Master's degree holders earn ${median_diff:,.0f} more per year ({median_diff_pct:.1f}% higher)\")\n",
    "    else:\n",
    "        print(f\"No, people with Master's degrees do not earn significantly more than those with Bachelor's degrees\")\n",
    "        print(f\"Bachelor's degree holders actually earn ${abs(median_diff):,.0f} more per year\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"This difference is statistically significant (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"This difference is not statistically significant (p ‚â• 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Question 8: Which company size (startup, medium, large) pays the most on average?\n",
    "\n",
    "print(\"\\nüè¢ BONUS QUESTION 8: Company Size Salary Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if we have company size information\n",
    "print(\"üîç Checking for company size data in the dataset...\")\n",
    "\n",
    "# Look for columns that might contain company size information\n",
    "company_size_columns = []\n",
    "for col in df_us.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['company', 'size', 'employees', 'organization', 'firm']):\n",
    "        company_size_columns.append(col)\n",
    "\n",
    "print(f\"Potential company size related columns: {company_size_columns}\")\n",
    "\n",
    "# Since we don't have explicit company size data, let's try to infer it from other fields\n",
    "# We could use job titles, industry, or other indicators, but this would be speculative\n",
    "# Let's check if there are any other fields that might give us company size hints\n",
    "\n",
    "print(f\"\\nüìä Available columns that might help infer company size:\")\n",
    "relevant_columns = []\n",
    "for col in df_us.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['title', 'role', 'level', 'senior', 'manager', 'director', 'executive']):\n",
    "        relevant_columns.append(col)\n",
    "\n",
    "print(f\"Job-related columns: {relevant_columns}\")\n",
    "\n",
    "# Let's try to infer company size from job titles and levels\n",
    "print(f\"\\nüîç Attempting to infer company size from job titles...\")\n",
    "\n",
    "# Define job level patterns that might correlate with company size\n",
    "startup_indicators = [\n",
    "    'founder', 'co-founder', 'startup', 'entrepreneur', 'owner', 'ceo', 'cto', 'cfo',\n",
    "    'head of', 'lead', 'senior', 'principal', 'staff', 'architect'\n",
    "]\n",
    "\n",
    "large_company_indicators = [\n",
    "    'manager', 'director', 'vp', 'vice president', 'senior manager', 'senior director',\n",
    "    'executive', 'chief', 'president', 'analyst', 'specialist', 'coordinator'\n",
    "]\n",
    "\n",
    "def infer_company_size_from_title(title):\n",
    "    if pd.isna(title):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    title_lower = str(title).lower()\n",
    "    \n",
    "    # Check for startup indicators\n",
    "    startup_score = sum(1 for indicator in startup_indicators if indicator in title_lower)\n",
    "    large_score = sum(1 for indicator in large_company_indicators if indicator in title_lower)\n",
    "    \n",
    "    if startup_score > large_score:\n",
    "        return 'Startup/Small'\n",
    "    elif large_score > startup_score:\n",
    "        return 'Large'\n",
    "    else:\n",
    "        return 'Medium'\n",
    "\n",
    "# Apply company size inference\n",
    "df_us['inferred_company_size'] = df_us['Job title'].apply(infer_company_size_from_title)\n",
    "\n",
    "# Filter for valid salary data\n",
    "company_size_salary_data = df_us[\n",
    "    (df_us['salary_usd'].notna()) & \n",
    "    (df_us['inferred_company_size'] != 'Unknown')\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nüìä Inferred Company Size Data:\")\n",
    "size_counts = company_size_salary_data['inferred_company_size'].value_counts()\n",
    "for size, count in size_counts.items():\n",
    "    print(f\"{size}: {count:,} workers\")\n",
    "\n",
    "if len(company_size_salary_data) == 0:\n",
    "    print(\"‚ùå No company size salary data found!\")\n",
    "    print(\"\\nüí° Note: The dataset doesn't contain explicit company size information.\")\n",
    "    print(\"We attempted to infer company size from job titles, but this is speculative.\")\n",
    "    print(\"For accurate company size analysis, we would need explicit company size data.\")\n",
    "else:\n",
    "    # Calculate salary statistics by inferred company size\n",
    "    size_salary_stats = company_size_salary_data.groupby('inferred_company_size')['salary_usd'].agg([\n",
    "        'count', 'median', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(0)\n",
    "    \n",
    "    # Sort by median salary (descending)\n",
    "    size_salary_stats = size_salary_stats.sort_values('median', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüí∞ INFERRED COMPANY SIZE SALARY ANALYSIS:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Company Size':<15} {'Count':<8} {'Median':<10} {'Mean':<10} {'Min':<10} {'Max':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for size, row in size_salary_stats.iterrows():\n",
    "        print(f\"{size:<15} {int(row['count']):<8} ${row['median']:,.0f}   ${row['mean']:,.0f}   ${row['min']:,.0f}   ${row['max']:,.0f}\")\n",
    "    \n",
    "    # Get the company size with highest median salary\n",
    "    highest_paying_size = size_salary_stats.index[0]\n",
    "    highest_median_salary = size_salary_stats.iloc[0]['median']\n",
    "    size_count = int(size_salary_stats.iloc[0]['count'])\n",
    "\n",
    "    # Statistical test\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Get salary data for each company size\n",
    "    size_groups = []\n",
    "    size_labels = []\n",
    "    for size in size_salary_stats.index:\n",
    "        size_data = company_size_salary_data[company_size_salary_data['inferred_company_size'] == size]['salary_usd']\n",
    "        if len(size_data) > 0:\n",
    "            size_groups.append(size_data.values)\n",
    "            size_labels.append(size)\n",
    "    \n",
    "    # Perform ANOVA test if we have multiple groups\n",
    "    if len(size_groups) > 1:\n",
    "        f_stat, p_value = stats.f_oneway(*size_groups)\n",
    "        print(f\"\\nüî¨ STATISTICAL TEST (ANOVA):\")\n",
    "        print(f\"F-statistic: {f_stat:.2f}\")\n",
    "        print(f\"P-value: {p_value:.2e}\")\n",
    "        if p_value < 0.05:\n",
    "            print(f\"Significant difference between company sizes (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"No significant difference between company sizes (p ‚â• 0.05)\")\n",
    "    \n",
    "    # Show sample job titles for each company size\n",
    "    print(f\"\\nüíº Sample Job Titles by Inferred Company Size:\")\n",
    "    for size in size_salary_stats.index:\n",
    "        size_data = company_size_salary_data[company_size_salary_data['inferred_company_size'] == size]\n",
    "        sample_titles = size_data['Job title'].value_counts().head(5)\n",
    "        print(f\"\\n{size}:\")\n",
    "        for title, count in sample_titles.items():\n",
    "            print(f\"  ‚Ä¢ {title}: {count} people\")\n",
    "\n",
    "    print(f\"\\nüéØ ANSWER TO BONUS QUESTION 8:\")\n",
    "    print(f\"Based on inferred company size from job titles: {highest_paying_size} companies pay the most on average\")\n",
    "    print(f\"Median salary: ${highest_median_salary:,.0f}\")\n",
    "    print(f\"Based on {size_count} workers in {highest_paying_size} companies\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è IMPORTANT CAVEAT:\")\n",
    "    print(f\"This analysis is based on INFERRED company size from job titles, not actual company size data.\")\n",
    "    print(f\"The dataset does not contain explicit company size information.\")\n",
    "    print(f\"Results should be interpreted with caution as they are speculative.\")\n",
    "    \n",
    "    # Show the methodology\n",
    "    print(f\"\\nüìã METHODOLOGY:\")\n",
    "    print(f\"‚Ä¢ Startup/Small: Job titles with 'founder', 'co-founder', 'startup', 'owner', 'head of', etc.\")\n",
    "    print(f\"‚Ä¢ Large: Job titles with 'manager', 'director', 'vp', 'analyst', 'specialist', etc.\")\n",
    "    print(f\"‚Ä¢ Medium: Job titles that don't clearly fit either category\")\n",
    "    print(f\"‚Ä¢ This is a rough approximation and may not reflect actual company size\")\n",
    "    \n",
    "    # Additional insights\n",
    "    print(f\"\\nüí° INSIGHTS:\")\n",
    "    print(f\"‚Ä¢ {len(size_salary_stats)} inferred company size categories analyzed\")\n",
    "    print(f\"‚Ä¢ Median salary range: ${size_salary_stats['median'].min():,.0f} - ${size_salary_stats['median'].max():,.0f}\")\n",
    "    print(f\"‚Ä¢ Average sample size per category: {size_salary_stats['count'].mean():.1f} workers\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"‚Ä¢ Statistical test shows significant differences between company size categories\")\n",
    "    else:\n",
    "        print(f\"‚Ä¢ Statistical test shows no significant differences between company size categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Summarize your findings here:**\n",
    "\n",
    "1. **Median salary for Software Engineers in US:** $X\n",
    "2. **Highest paying US state for tech:** State Name\n",
    "3. **Salary increase per year of experience:** $X per year\n",
    "4. **Remote vs office percentage:** X% remote, Y% office\n",
    "5. **Highest paying non-tech industry:** Industry Name\n",
    "\n",
    "**Key insights:**\n",
    "- Insight 1\n",
    "- Insight 2\n",
    "- Insight 3\n",
    "\n",
    "**Challenges faced:**\n",
    "- Challenge 1 and how you solved it\n",
    "- Challenge 2 and how you solved it\n",
    "\n",
    "**What you learned about vibe coding:**\n",
    "- Learning 1\n",
    "- Learning 2\n",
    "- Learning 3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
