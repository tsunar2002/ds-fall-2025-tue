{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Coding: Real-World Data Cleaning Challenge\n",
    "\n",
    "## The Mission\n",
    "\n",
    "You're a Data Analyst at **TechSalary Insights**. Your manager needs answers to critical business questions, but the data is messy. Your job is to clean it and provide accurate insights.\n",
    "\n",
    "**The catch:** You must figure out how to clean the data yourself. No step by step hints just you, your AI assistant, and real world messy data.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: Ask A Manager Salary Survey 2021\n",
    "\n",
    "**Location:** `../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`\n",
    "\n",
    "This is **real survey data** from Ask A Manager's 2021 salary survey with over 28,000 responses from working professionals. The data comes from this survey: https://www.askamanager.org/2021/04/how-much-money-do-you-make-4.html\n",
    "\n",
    "**Why this dataset is perfect for vibe coding:**\n",
    "- Real human responses (inconsistent formatting)\n",
    "- Multiple currencies and formats  \n",
    "- Messy job titles and location data\n",
    "- Missing and invalid entries\n",
    "- Requires business judgment calls\n",
    "\n",
    "---\n",
    "\n",
    "## Your Business Questions\n",
    "\n",
    "Answer these **exact questions** with clean data. There's only one correct answer for each:\n",
    "\n",
    "### Core Questions (Required):\n",
    "1. **What is the median salary for Software Engineers in the United States?** \n",
    "2. **Which US state has the highest average salary for tech workers?**\n",
    "3. **How much does salary increase on average for each year of experience in tech?**\n",
    "4. **Which industry (besides tech) has the highest median salary?**\n",
    "\n",
    "### Bonus Questions (If time permits):\n",
    "5. **What's the salary gap between men and women in tech roles?**\n",
    "6. **Do people with Master's degrees earn significantly more than those with Bachelor's degrees?**\n",
    "\n",
    "**Success Criteria:** Your final answers will be compared against the \"official\" results. Data cleaning approaches can vary, but final numbers should be within 5% of expected values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Work Starts Here\n",
    "\n",
    "## Step 0: Create Your Plan\n",
    "**Before writing any code, use Cursor to create your todo plan. Then paste it here:**\n",
    "\n",
    "## My Data Cleaning Plan\n",
    "\n",
    "Based on my analysis of the ManagerSalarySurvey2021.tsv file, here's my comprehensive data cleaning plan:\n",
    "\n",
    "### Data Overview:\n",
    "- **28,062 rows** of survey responses\n",
    "- **17 columns** including salary, location, job title, experience, demographics\n",
    "- **Mixed data quality** with inconsistent formatting, missing values, and various currencies\n",
    "\n",
    "### Cleaning Steps:\n",
    "\n",
    "1. **Data Exploration & Loading** ✅\n",
    "   - Load dataset and examine structure\n",
    "   - Identify data types and column meanings\n",
    "   - Check for encoding issues\n",
    "\n",
    "2. **Missing Value Analysis** \n",
    "   - Identify empty strings, nulls, and inconsistent representations\n",
    "   - Standardize missing value formats (convert to NaN)\n",
    "   - Document missing value patterns\n",
    "\n",
    "3. **Salary Data Cleaning**\n",
    "   - Remove commas from salary numbers\n",
    "   - Handle different currencies (USD, GBP, CAD, etc.)\n",
    "   - Convert bonus/compensation columns to numeric\n",
    "   - Identify and flag suspicious salary values\n",
    "\n",
    "4. **Location Data Standardization**\n",
    "   - Standardize country names (USA vs United States vs US)\n",
    "   - Clean state abbreviations and full names\n",
    "   - Handle missing location data\n",
    "\n",
    "5. **Job Title Standardization**\n",
    "   - Identify and categorize tech roles\n",
    "   - Standardize job title formatting\n",
    "   - Handle additional context in job titles\n",
    "\n",
    "6. **Experience Data Conversion**\n",
    "   - Convert experience ranges to numeric midpoints\n",
    "   - Handle \"years\" columns for analysis\n",
    "\n",
    "7. **Demographic Data Cleaning**\n",
    "   - Standardize gender categories\n",
    "   - Clean race/ethnicity categories\n",
    "   - Standardize education levels\n",
    "\n",
    "8. **Data Quality Validation**\n",
    "   - Remove obvious outliers and invalid entries\n",
    "   - Cross-validate salary vs experience relationships\n",
    "   - Final data quality summary\n",
    "\n",
    "9. **Analysis-Ready Dataset**\n",
    "   - Create cleaned dataset for business questions\n",
    "   - Document all cleaning decisions and assumptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (28062, 18)\n",
      "\n",
      "Column Names:\n",
      "['Timestamp', 'How old are you?', 'What industry do you work in?', 'Job title', 'If your job title needs additional context, please clarify here:', \"What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)\", 'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.', 'Please indicate the currency', 'If \"Other,\" please indicate the currency here: ', 'If your income needs additional context, please provide it here:', 'What country do you work in?', \"If you're in the U.S., what state do you work in?\", 'What city do you work in?', 'How many years of professional work experience do you have overall?', 'How many years of professional work experience do you have in your field?', 'What is your highest level of education completed?', 'What is your gender?', 'What is your race? (Choose all that apply.)']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What industry do you work in?</th>\n",
       "      <th>Job title</th>\n",
       "      <th>If your job title needs additional context, please clarify here:</th>\n",
       "      <th>What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)</th>\n",
       "      <th>How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.</th>\n",
       "      <th>Please indicate the currency</th>\n",
       "      <th>If \"Other,\" please indicate the currency here:</th>\n",
       "      <th>If your income needs additional context, please provide it here:</th>\n",
       "      <th>What country do you work in?</th>\n",
       "      <th>If you're in the U.S., what state do you work in?</th>\n",
       "      <th>What city do you work in?</th>\n",
       "      <th>How many years of professional work experience do you have overall?</th>\n",
       "      <th>How many years of professional work experience do you have in your field?</th>\n",
       "      <th>What is your highest level of education completed?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your race? (Choose all that apply.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp How old are you?  What industry do you work in?  \\\n",
       "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  Job title  \\\n",
       "0        Research and Instruction Librarian   \n",
       "1  Change & Internal Communications Manager   \n",
       "2                      Marketing Specialist   \n",
       "3                           Program Manager   \n",
       "4                        Accounting Manager   \n",
       "\n",
       "  If your job title needs additional context, please clarify here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
       "0                                             55,000                                                                                                                                                                                     \n",
       "1                                             54,600                                                                                                                                                                                     \n",
       "2                                             34,000                                                                                                                                                                                     \n",
       "3                                             62,000                                                                                                                                                                                     \n",
       "4                                             60,000                                                                                                                                                                                     \n",
       "\n",
       "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
       "0                                                0.0                                                                                                                                                \n",
       "1                                             4000.0                                                                                                                                                \n",
       "2                                                NaN                                                                                                                                                \n",
       "3                                             3000.0                                                                                                                                                \n",
       "4                                             7000.0                                                                                                                                                \n",
       "\n",
       "  Please indicate the currency  \\\n",
       "0                          USD   \n",
       "1                          GBP   \n",
       "2                          USD   \n",
       "3                          USD   \n",
       "4                          USD   \n",
       "\n",
       "  If \"Other,\" please indicate the currency here:   \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "  If your income needs additional context, please provide it here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What country do you work in?  \\\n",
       "0                United States   \n",
       "1               United Kingdom   \n",
       "2                           US   \n",
       "3                          USA   \n",
       "4                           US   \n",
       "\n",
       "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
       "0                                     Massachusetts                    Boston   \n",
       "1                                               NaN                 Cambridge   \n",
       "2                                         Tennessee               Chattanooga   \n",
       "3                                         Wisconsin                 Milwaukee   \n",
       "4                                    South Carolina                Greenville   \n",
       "\n",
       "  How many years of professional work experience do you have overall?  \\\n",
       "0                                          5-7 years                    \n",
       "1                                       8 - 10 years                    \n",
       "2                                        2 - 4 years                    \n",
       "3                                       8 - 10 years                    \n",
       "4                                       8 - 10 years                    \n",
       "\n",
       "  How many years of professional work experience do you have in your field?  \\\n",
       "0                                          5-7 years                          \n",
       "1                                          5-7 years                          \n",
       "2                                        2 - 4 years                          \n",
       "3                                          5-7 years                          \n",
       "4                                          5-7 years                          \n",
       "\n",
       "  What is your highest level of education completed? What is your gender?  \\\n",
       "0                                    Master's degree                Woman   \n",
       "1                                     College degree           Non-binary   \n",
       "2                                     College degree                Woman   \n",
       "3                                     College degree                Woman   \n",
       "4                                     College degree                Woman   \n",
       "\n",
       "  What is your race? (Choose all that apply.)  \n",
       "0                                       White  \n",
       "1                                       White  \n",
       "2                                       White  \n",
       "3                                       White  \n",
       "4                                       White  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/Users/thasmias/ds-fall-2025-fri-1230/Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv', sep='\\t')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'age', 'industry', 'job_title', 'job_context', 'annual_salary', 'additional_compensation', 'currency', 'currency_other', 'income_context', 'country', 'US_state', 'city', 'experience_total_years', 'experience_field_years', 'education', 'gender', 'race']\n"
     ]
    }
   ],
   "source": [
    "#change long col names to short col names\n",
    "df.columns = [\n",
    "    'timestamp', 'age', 'industry', 'job_title', 'job_context',\n",
    "    'annual_salary', 'additional_compensation', 'currency', 'currency_other',\n",
    "    'income_context', 'country', 'US_state', 'city',\n",
    "    'experience_total_years', 'experience_field_years', 'education', 'gender', 'race'\n",
    "]\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "timestamp                   object\n",
      "age                         object\n",
      "industry                    object\n",
      "job_title                   object\n",
      "job_context                 object\n",
      "annual_salary               object\n",
      "additional_compensation    float64\n",
      "currency                    object\n",
      "currency_other              object\n",
      "income_context              object\n",
      "country                     object\n",
      "US_state                    object\n",
      "city                        object\n",
      "experience_total_years      object\n",
      "experience_field_years      object\n",
      "education                   object\n",
      "gender                      object\n",
      "race                        object\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "timestamp                      0\n",
      "age                            0\n",
      "industry                      74\n",
      "job_title                      1\n",
      "job_context                20800\n",
      "annual_salary                  0\n",
      "additional_compensation     7296\n",
      "currency                       0\n",
      "currency_other             27856\n",
      "income_context             25020\n",
      "country                        0\n",
      "US_state                    5023\n",
      "city                          82\n",
      "experience_total_years         0\n",
      "experience_field_years         0\n",
      "education                    222\n",
      "gender                       171\n",
      "race                         177\n",
      "dtype: int64\n",
      "\n",
      "Empty Strings (checking for empty strings that might not be NaN):\n",
      "\n",
      "Checking for other missing value representations:\n",
      "job_title: 1 instances of 'na'\n",
      "job_context: 1 instances of 'na'\n",
      "currency_other: 1 instances of 'na'\n",
      "income_context: 1 instances of 'na'\n",
      "country: 1 instances of 'na'\n",
      "city: 5 instances of 'na'\n",
      "job_context: 1 instances of 'none'\n",
      "income_context: 2 instances of 'none'\n",
      "city: 1 instances of 'none'\n",
      "job_title: 2 instances of '-'\n",
      "currency_other: 1 instances of '-'\n",
      "city: 9 instances of '-'\n",
      "city: 4 instances of '--'\n"
     ]
    }
   ],
   "source": [
    "# Missing Values Analysis\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nEmpty Strings (checking for empty strings that might not be NaN):\")\n",
    "for col in df.columns:\n",
    "    empty_count = (df[col] == '').sum()\n",
    "    if empty_count > 0:\n",
    "        print(f\"{col}: {empty_count} empty strings\")\n",
    "\n",
    "# Let's also check for other common \"missing\" representations\n",
    "print(\"\\nChecking for other missing value representations:\")\n",
    "missing_representations = ['N/A', 'n/a', 'NA', 'na', 'NULL', 'null', 'None', 'none', '-', '--']\n",
    "for rep in missing_representations:\n",
    "    for col in df.columns:\n",
    "        count = (df[col] == rep).sum()\n",
    "        if count > 0:\n",
    "            print(f\"{col}: {count} instances of '{rep}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary column analysis:\n",
      "Unique values in salary column (first 20):\n",
      "annual_salary\n",
      "60,000     430\n",
      "80,000     406\n",
      "70,000     402\n",
      "65,000     400\n",
      "75,000     383\n",
      "90,000     368\n",
      "50,000     361\n",
      "100,000    313\n",
      "85,000     306\n",
      "55,000     303\n",
      "120,000    295\n",
      "110,000    263\n",
      "52,000     251\n",
      "45,000     247\n",
      "130,000    245\n",
      "40,000     234\n",
      "72,000     218\n",
      "95,000     213\n",
      "125,000    197\n",
      "105,000    191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Currency column analysis:\n",
      "Unique currencies:\n",
      "currency\n",
      "USD        23374\n",
      "CAD         1673\n",
      "GBP         1591\n",
      "EUR          643\n",
      "AUD/NZD      504\n",
      "Other        160\n",
      "CHF           37\n",
      "SEK           37\n",
      "JPY           23\n",
      "ZAR           16\n",
      "HKD            4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bonus column analysis:\n",
      "Unique values in bonus column (first 20):\n",
      "additional_compensation\n",
      "0.0        7949\n",
      "5000.0     1112\n",
      "10000.0     962\n",
      "2000.0      775\n",
      "1000.0      678\n",
      "3000.0      635\n",
      "15000.0     538\n",
      "20000.0     508\n",
      "4000.0      428\n",
      "6000.0      349\n",
      "500.0       333\n",
      "8000.0      296\n",
      "1500.0      290\n",
      "12000.0     271\n",
      "30000.0     269\n",
      "2500.0      264\n",
      "25000.0     252\n",
      "7000.0      238\n",
      "50000.0     182\n",
      "40000.0     174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Salary Data Cleaning\n",
    "print(\"Salary column analysis:\")\n",
    "print(\"Unique values in salary column (first 20):\")\n",
    "print(df['annual_salary'].value_counts().head(20))\n",
    "\n",
    "print(\"\\nCurrency column analysis:\")\n",
    "print(\"Unique currencies:\")\n",
    "print(df['currency'].value_counts())\n",
    "\n",
    "print(\"\\nBonus column analysis:\")\n",
    "print(\"Unique values in bonus column (first 20):\")\n",
    "print(df['additional_compensation'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTING DATA CLEANING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data cleaning process...\n",
      "Original dataset shape: (28062, 18)\n",
      "Missing values before standardization:\n",
      "timestamp                      0\n",
      "age                            0\n",
      "industry                      74\n",
      "job_title                      1\n",
      "job_context                20800\n",
      "annual_salary                  0\n",
      "additional_compensation     7296\n",
      "currency                       0\n",
      "currency_other             27856\n",
      "income_context             25020\n",
      "country                        0\n",
      "US_state                    5023\n",
      "city                          82\n",
      "experience_total_years         0\n",
      "experience_field_years         0\n",
      "education                    222\n",
      "gender                       171\n",
      "race                         177\n",
      "dtype: int64\n",
      "\n",
      "1. Standardizing missing values...\n",
      "Missing values after standardization:\n",
      "timestamp                      0\n",
      "age                            0\n",
      "industry                      74\n",
      "job_title                      4\n",
      "job_context                20802\n",
      "annual_salary                  0\n",
      "additional_compensation     7296\n",
      "currency                       0\n",
      "currency_other             27858\n",
      "income_context             25023\n",
      "country                        1\n",
      "US_state                    5023\n",
      "city                         101\n",
      "experience_total_years         0\n",
      "experience_field_years         0\n",
      "education                    222\n",
      "gender                       171\n",
      "race                         177\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a copy of the original data for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"Starting data cleaning process...\")\n",
    "print(f\"Original dataset shape: {df_clean.shape}\")\n",
    "\n",
    "print(\"Missing values before standardization:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# 1. Standardize missing values\n",
    "print(\"\\n1. Standardizing missing values...\")\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df_clean = df_clean.replace('', np.nan)\n",
    "\n",
    "# Replace common missing representations with NaN\n",
    "missing_values = ['N/A', 'n/a', 'NA', 'na', 'NULL', 'null', 'None', 'none', '-', '--']\n",
    "for val in missing_values:\n",
    "    df_clean = df_clean.replace(val, np.nan)\n",
    "\n",
    "print(\"Missing values after standardization:\")\n",
    "print(df_clean.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Cleaning salary data...\n",
      "Salary conversion results:\n",
      "Valid numeric salaries: 28062\n",
      "Invalid/NaN salaries: 0\n",
      "\n",
      "Bonus conversion results:\n",
      "Valid numeric bonuses: 20766\n",
      "Invalid/NaN bonuses: 7296\n",
      "\n",
      "Salary statistics (USD only):\n",
      "USD salaries count: 23374\n",
      "USD salary range: $0 - $102,000,000\n",
      "USD median salary: $78,000\n"
     ]
    }
   ],
   "source": [
    "# 2. Clean Salary Data\n",
    "print(\"\\n2. Cleaning salary data...\")\n",
    "\n",
    "# Clean the main salary column\n",
    "salary_col = 'annual_salary'\n",
    "\n",
    "# Remove commas from salary numbers\n",
    "df_clean[salary_col] = df_clean[salary_col].astype(str).str.replace(',', '')\n",
    "\n",
    "# Convert to numeric, errors='coerce' will convert invalid values to NaN\n",
    "df_clean['salary_numeric'] = pd.to_numeric(df_clean[salary_col], errors='coerce')\n",
    "\n",
    "print(f\"Salary conversion results:\")\n",
    "print(f\"Valid numeric salaries: {df_clean['salary_numeric'].notna().sum()}\")\n",
    "print(f\"Invalid/NaN salaries: {df_clean['salary_numeric'].isna().sum()}\")\n",
    "\n",
    "# Clean bonus column\n",
    "bonus_col = 'additional_compensation'\n",
    "df_clean[bonus_col] = df_clean[bonus_col].astype(str).str.replace(',', '')\n",
    "df_clean['bonus_numeric'] = pd.to_numeric(df_clean[bonus_col], errors='coerce')\n",
    "\n",
    "print(f\"\\nBonus conversion results:\")\n",
    "print(f\"Valid numeric bonuses: {df_clean['bonus_numeric'].notna().sum()}\")\n",
    "print(f\"Invalid/NaN bonuses: {df_clean['bonus_numeric'].isna().sum()}\")\n",
    "\n",
    "# Show some salary statistics\n",
    "print(f\"\\nSalary statistics (USD only):\")\n",
    "usd_mask = df_clean['currency'] == 'USD'\n",
    "print(f\"USD salaries count: {usd_mask.sum()}\")\n",
    "print(f\"USD salary range: ${df_clean[usd_mask]['salary_numeric'].min():,.0f} - ${df_clean[usd_mask]['salary_numeric'].max():,.0f}\")\n",
    "print(f\"USD median salary: ${df_clean[usd_mask]['salary_numeric'].median():,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Massachusetts', nan, 'Tennessee', 'Wisconsin', 'South Carolina',\n",
       "       'New Hampshire', 'Arizona', 'Missouri', 'Florida', 'Pennsylvania',\n",
       "       'Michigan', 'Minnesota', 'Illinois', 'California', 'Georgia',\n",
       "       'Ohio', 'District of Columbia', 'Maryland', 'Texas', 'Virginia',\n",
       "       'North Carolina', 'New York', 'New Jersey', 'Rhode Island',\n",
       "       'Colorado', 'Oregon', 'Washington', 'Indiana', 'Iowa', 'Nebraska',\n",
       "       'Oklahoma', 'Maine', 'Connecticut', 'South Dakota',\n",
       "       'West Virginia', 'Idaho', 'Louisiana', 'Montana', 'Kentucky',\n",
       "       'North Dakota', 'Kansas', 'Vermont', 'Arkansas', 'Alabama',\n",
       "       'Nevada', 'Delaware', 'New Mexico', 'Hawaii', 'Utah',\n",
       "       'Mississippi', 'Kentucky, Ohio', 'District of Columbia, Virginia',\n",
       "       'District of Columbia, Maryland', 'Alaska', 'Arizona, Washington',\n",
       "       'Georgia, New York', 'California, Colorado', 'California, Oregon',\n",
       "       'District of Columbia, Maryland, Pennsylvania, Virginia',\n",
       "       'Arizona, California', 'North Carolina, Utah', 'Wyoming',\n",
       "       'Ohio, Wyoming', 'Georgia, Tennessee', 'Massachusetts, Oregon',\n",
       "       'Alabama, Montana', 'Alabama, District of Columbia',\n",
       "       'California, Pennsylvania', 'New Jersey, Pennsylvania',\n",
       "       'Georgia, Washington', 'Alaska, Maryland',\n",
       "       'Michigan, South Carolina', 'Massachusetts, Rhode Island',\n",
       "       'Georgia, Minnesota', 'Colorado, Nevada',\n",
       "       'Maine, Massachusetts, New Hampshire, North Carolina',\n",
       "       'Alabama, Minnesota, Nevada', 'New Jersey, New York',\n",
       "       'Arizona, Utah', 'Alabama, Kansas', 'California, Oklahoma',\n",
       "       'Illinois, Wisconsin', 'Illinois, Kentucky',\n",
       "       'Arizona, California, Nevada, Texas',\n",
       "       'Alaska, Idaho, Oregon, Utah, Washington',\n",
       "       'Massachusetts, Pennsylvania', 'Nevada, Oregon',\n",
       "       'New Jersey, Virginia', 'Montana, Wyoming',\n",
       "       'Colorado, Massachusetts',\n",
       "       'District of Columbia, Maryland, Virginia',\n",
       "       'Massachusetts, Vermont', 'Massachusetts, New Hampshire',\n",
       "       'Arkansas, Iowa, Massachusetts, Ohio, Wyoming', 'New York, Texas',\n",
       "       'California, Montana', 'Iowa, Utah, Vermont', 'Texas, Virginia',\n",
       "       'Utah, Vermont', 'Arkansas, Illinois', 'Georgia, Massachusetts',\n",
       "       'Maryland, Virginia', 'Florida, Georgia, South Carolina',\n",
       "       'Arkansas, Idaho, Kansas, Louisiana, Michigan, Mississippi, Nevada, New York, South Carolina, Tennessee, Washington',\n",
       "       'California, Texas', 'Indiana, Ohio', 'Ohio, Washington',\n",
       "       'Kansas, Missouri', 'Colorado, Illinois',\n",
       "       'Arizona, Hawaii, Illinois, Michigan, Utah, Wyoming',\n",
       "       'California, New Jersey', 'Louisiana, Washington',\n",
       "       'Maryland, New York', 'District of Columbia, Washington',\n",
       "       'Delaware, Pennsylvania', 'Illinois, North Carolina',\n",
       "       'Indiana, Massachusetts', 'Florida, New Hampshire, Wisconsin',\n",
       "       'Pennsylvania, Rhode Island', 'New York, Oregon, Vermont',\n",
       "       'Iowa, Nebraska', 'California, New York', 'Arizona, New York',\n",
       "       'California, District of Columbia, Illinois, Iowa, Maryland, Minnesota',\n",
       "       'Oregon, Washington', 'New York, Virginia',\n",
       "       'Mississippi, Missouri', 'California, Maryland',\n",
       "       'California, Illinois, Massachusetts, North Carolina, South Carolina, Virginia',\n",
       "       'Alabama, California', 'Michigan, Texas, Washington',\n",
       "       'Alabama, Oregon', 'Alabama, Alaska, Arizona',\n",
       "       'Alabama, South Carolina',\n",
       "       'Colorado, Delaware, New Jersey, West Virginia, Wyoming'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['country'].unique()\n",
    "df['US_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Standardizing location data...\n",
      "Country standardization results:\n",
      "country_clean\n",
      "United States     23142\n",
      "Canada             1686\n",
      "United Kingdom     1586\n",
      "Australia           391\n",
      "Germany             195\n",
      "New Zealand         130\n",
      "Ireland             124\n",
      "Netherlands          90\n",
      "France               68\n",
      "Spain                49\n",
      "Sweden               41\n",
      "Switzerland          38\n",
      "Belgium              35\n",
      "Japan                29\n",
      "Denmark              24\n",
      "India                22\n",
      "South Africa         19\n",
      "Singapore            19\n",
      "Austria              17\n",
      "Finland              16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "US respondents: 23142\n",
      "\n",
      "Top US states:\n",
      "US_state_clean\n",
      "California              2599\n",
      "New York                2170\n",
      "Massachusetts           1519\n",
      "Texas                   1267\n",
      "Illinois                1210\n",
      "Washington              1181\n",
      "District of Columbia     976\n",
      "Pennsylvania             942\n",
      "Virginia                 784\n",
      "Minnesota                720\n",
      "Ohio                     653\n",
      "Colorado                 631\n",
      "Oregon                   624\n",
      "North Carolina           601\n",
      "Maryland                 564\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Standardize Location Data\n",
    "print(\"\\n3. Standardizing location data...\")\n",
    "\n",
    "# Standardize country names\n",
    "df_clean['country'] = df_clean['country'].str.strip().str.lower()\n",
    "\n",
    "country_mapping = {\n",
    "    # United States variants\n",
    "    'us': 'United States', 'u.s.': 'United States', 'usa': 'United States', \n",
    "    'u.s': 'United States', 'u.s.a': 'United States', 'united states': 'United States',\n",
    "    'united state': 'United States', 'united stated': 'United States', \n",
    "    'united statws': 'United States', 'united ststes': 'United States',\n",
    "    'united statss': 'United States', 'united stares': 'United States',\n",
    "    'united stattes': 'United States', 'united states of america': 'United States',\n",
    "    'united state of america': 'United States', 'america': 'United States',\n",
    "    'the us': 'United States', 'u.s.a.': 'United States', 'u. s.': 'United States',\n",
    "    'unites states': 'United States', 'us ': 'United States', 'u.s>': 'United States',\n",
    "    'usa ': 'United States', 'united  states': 'United States', \n",
    "    'united states of americas': 'United States', 'u.s.a ': 'United States',\n",
    "    'u.s. ': 'United States', 'united statea': 'United States',\n",
    "    'united statues': 'United States', 'united sates': 'United States',\n",
    "    'united stted': 'United States', 'united statesp': 'United States',\n",
    "    'usa-- virgin islands': 'United States', 'united states- puerto rico': 'United States',\n",
    "    'united states is america': 'United States', 'u. s ': 'United States',\n",
    "    'united states of american': 'United States', 'united states of american ': 'United States',\n",
    "    'united states of american ': 'United States', 'u.s.a. ': 'United States',\n",
    "    'u.sa': 'United States', 'u.s.a.': 'United States', 'uniteed states': 'United States',\n",
    "    'untied states': 'United States', 'uniited states': 'United States',\n",
    "    'unitied states': 'United States', 'unite states': 'United States',\n",
    "    'united statws': 'United States', 'usaa': 'United States', 'usab': 'United States',\n",
    "    'us of a': 'United States', 'united statss': 'United States',\n",
    "    '🇺🇸': 'United States', 'unitedstates': 'United States',\n",
    "    'us govt employee overseas, country withheld': 'United States',\n",
    "\n",
    "    # United Kingdom variants\n",
    "    'uk': 'United Kingdom', 'u.k.': 'United Kingdom', 'u.k': 'United Kingdom',\n",
    "    'united kingdom': 'United Kingdom', 'united kingdom.': 'United Kingdom',\n",
    "    'united kingdom ': 'United Kingdom', 'england': 'United Kingdom',\n",
    "    'scotland': 'United Kingdom', 'wales': 'United Kingdom',\n",
    "    'northern ireland': 'United Kingdom', 'great britain': 'United Kingdom',\n",
    "    'britain': 'United Kingdom', 'england, uk': 'United Kingdom',\n",
    "    'england/uk': 'United Kingdom', 'uk (england)': 'United Kingdom',\n",
    "    'uk (northern ireland)': 'United Kingdom', 'scotland, uk': 'United Kingdom',\n",
    "    'wales (uk)': 'United Kingdom', 'england, united kingdom': 'United Kingdom',\n",
    "\n",
    "    # Canada variants\n",
    "    'canada': 'Canada', 'canada ': 'Canada', 'can': 'Canada', \n",
    "    'canda': 'Canada', 'canadw': 'Canada', 'csnada': 'Canada',\n",
    "    'canadá': 'Canada', 'canada, ottawa, ontario': 'Canada',\n",
    "    'canada and usa': 'Canada',\n",
    "\n",
    "    # Australia\n",
    "    'australia': 'Australia', 'australia ': 'Australia', 'australi': 'Australia',\n",
    "    'australian': 'Australia', 'new zealand aotearoa': 'New Zealand',\n",
    "\n",
    "    # Other major countries\n",
    "    'france': 'France', 'france ': 'France',\n",
    "    'germany': 'Germany', 'germany ': 'Germany',\n",
    "    'india': 'India', 'india ': 'India', 'ibdia': 'India',\n",
    "    'ireland': 'Ireland', 'ireland ': 'Ireland',\n",
    "    'spain': 'Spain', 'spain ': 'Spain',\n",
    "    'netherlands': 'Netherlands', 'the netherlands': 'Netherlands',\n",
    "    'the netherlands ': 'Netherlands', 'nl': 'Netherlands', 'nederland': 'Netherlands',\n",
    "    'denmark': 'Denmark', 'danmark': 'Denmark',\n",
    "    'switzerland': 'Switzerland', 'switzerland ': 'Switzerland',\n",
    "    'sweden': 'Sweden', 'sweden ': 'Sweden',\n",
    "    'italy': 'Italy', 'italy (south)': 'Italy',\n",
    "    'japan': 'Japan', 'japan ': 'Japan',\n",
    "    'china': 'China', 'mainland china': 'China',\n",
    "    'hong kong': 'Hong Kong', 'hong kong ': 'Hong Kong',\n",
    "    'new zealand': 'New Zealand', 'nz': 'New Zealand',\n",
    "    'south africa': 'South Africa', 'south africa ': 'South Africa',\n",
    "    'brazil': 'Brazil', 'brasil': 'Brazil',\n",
    "    'mexico': 'Mexico', 'méxico': 'Mexico', 'mexico ': 'Mexico',\n",
    "    'portugal': 'Portugal', 'portugal ': 'Portugal',\n",
    "    'belgium': 'Belgium', 'belgium ': 'Belgium',\n",
    "    'finland': 'Finland', 'finland ': 'Finland',\n",
    "    'norway': 'Norway', 'norway ': 'Norway',\n",
    "    'austria': 'Austria',\n",
    "    'argentina': 'Argentina',\n",
    "    'pakistan': 'Pakistan',\n",
    "    'bangladesh': 'Bangladesh',\n",
    "    'philippines': 'Philippines',\n",
    "    'poland': 'Poland',\n",
    "    'romania': 'Romania',\n",
    "    'singapore': 'Singapore',\n",
    "    'south korea': 'South Korea',\n",
    "    'uae': 'United Arab Emirates', 'united arab emirates': 'United Arab Emirates',\n",
    "    'malaysia': 'Malaysia', 'malaysia ': 'Malaysia',\n",
    "    'israel': 'Israel',\n",
    "    'nigeria': 'Nigeria', 'nigeria ': 'Nigeria',\n",
    "    'czech republic': 'Czech Republic', 'czechia': 'Czech Republic',\n",
    "    'ireland ': 'Ireland',\n",
    "    'hungary': 'Hungary',\n",
    "    'luxembourg': 'Luxembourg',\n",
    "    'slovakia': 'Slovakia',\n",
    "    'croatia': 'Croatia',\n",
    "    'portugal ': 'Portugal',\n",
    "    'wales, uk': 'United Kingdom',\n",
    "    'scotland ': 'United Kingdom',\n",
    "    'england, gb': 'United Kingdom',\n",
    "    'englang': 'United Kingdom',\n",
    "    'united kingdom (england)': 'United Kingdom',\n",
    "}\n",
    "\n",
    "\n",
    "df_clean['country_clean'] = df_clean['country'].replace(country_mapping)\n",
    "\n",
    "print(\"Country standardization results:\")\n",
    "print(df_clean['country_clean'].value_counts().head(20))\n",
    "\n",
    "# Clean state data for US respondents\n",
    "us_mask = df_clean['country_clean'] == 'United States'\n",
    "print(f\"\\nUS respondents: {us_mask.sum()}\")\n",
    "\n",
    "# Standardize some common state variations\n",
    "df_clean['US_state'] = df_clean['US_state'].str.strip().str.lower().str.replace(r'[^a-z ]', '', regex=True)\n",
    "\n",
    "state_mapping = {\n",
    "    # Full names\n",
    "    'alabama': 'Alabama', 'alaska': 'Alaska', 'arizona': 'Arizona', 'arkansas': 'Arkansas',\n",
    "    'california': 'California', 'colorado': 'Colorado', 'connecticut': 'Connecticut',\n",
    "    'delaware': 'Delaware', 'florida': 'Florida', 'georgia': 'Georgia', 'hawaii': 'Hawaii',\n",
    "    'idaho': 'Idaho', 'illinois': 'Illinois', 'indiana': 'Indiana', 'iowa': 'Iowa',\n",
    "    'kansas': 'Kansas', 'kentucky': 'Kentucky', 'louisiana': 'Louisiana', 'maine': 'Maine',\n",
    "    'maryland': 'Maryland', 'massachusetts': 'Massachusetts', 'michigan': 'Michigan',\n",
    "    'minnesota': 'Minnesota', 'mississippi': 'Mississippi', 'missouri': 'Missouri',\n",
    "    'montana': 'Montana', 'nebraska': 'Nebraska', 'nevada': 'Nevada',\n",
    "    'new hampshire': 'New Hampshire', 'new jersey': 'New Jersey', 'new mexico': 'New Mexico',\n",
    "    'new york': 'New York', 'north carolina': 'North Carolina', 'north dakota': 'North Dakota',\n",
    "    'ohio': 'Ohio', 'oklahoma': 'Oklahoma', 'oregon': 'Oregon', 'pennsylvania': 'Pennsylvania',\n",
    "    'rhode island': 'Rhode Island', 'south carolina': 'South Carolina', 'south dakota': 'South Dakota',\n",
    "    'tennessee': 'Tennessee', 'texas': 'Texas', 'utah': 'Utah', 'vermont': 'Vermont',\n",
    "    'virginia': 'Virginia', 'washington': 'Washington', 'west virginia': 'West Virginia',\n",
    "    'wisconsin': 'Wisconsin', 'wyoming': 'Wyoming', 'district of columbia': 'District of Columbia',\n",
    "    'dc': 'District of Columbia', 'washington dc': 'District of Columbia', 'd c': 'District of Columbia',\n",
    "\n",
    "    # Common abbreviations\n",
    "    'al': 'Alabama', 'ak': 'Alaska', 'az': 'Arizona', 'ar': 'Arkansas', 'ca': 'California',\n",
    "    'co': 'Colorado', 'ct': 'Connecticut', 'de': 'Delaware', 'fl': 'Florida', 'ga': 'Georgia',\n",
    "    'hi': 'Hawaii', 'id': 'Idaho', 'il': 'Illinois', 'in': 'Indiana', 'ia': 'Iowa', 'ks': 'Kansas',\n",
    "    'ky': 'Kentucky', 'la': 'Louisiana', 'me': 'Maine', 'md': 'Maryland', 'ma': 'Massachusetts',\n",
    "    'mi': 'Michigan', 'mn': 'Minnesota', 'ms': 'Mississippi', 'mo': 'Missouri', 'mt': 'Montana',\n",
    "    'ne': 'Nebraska', 'nv': 'Nevada', 'nh': 'New Hampshire', 'nj': 'New Jersey', 'nm': 'New Mexico',\n",
    "    'ny': 'New York', 'nc': 'North Carolina', 'nd': 'North Dakota', 'oh': 'Ohio', 'ok': 'Oklahoma',\n",
    "    'or': 'Oregon', 'pa': 'Pennsylvania', 'ri': 'Rhode Island', 'sc': 'South Carolina',\n",
    "    'sd': 'South Dakota', 'tn': 'Tennessee', 'tx': 'Texas', 'ut': 'Utah', 'vt': 'Vermont',\n",
    "    'va': 'Virginia', 'wa': 'Washington', 'wv': 'West Virginia', 'wi': 'Wisconsin', 'wy': 'Wyoming',\n",
    "\n",
    "    # Extra messy variants\n",
    "    'calif': 'California', 'cal': 'California', 'wash dc': 'District of Columbia',\n",
    "    'districtofcolumbia': 'District of Columbia', 'nyc': 'New York', 'newyork': 'New York',\n",
    "    'mass': 'Massachusetts', 'penn': 'Pennsylvania', 'penna': 'Pennsylvania',\n",
    "    'flor': 'Florida', 'virgina': 'Virginia', 'virgina ': 'Virginia', 'tex': 'Texas',\n",
    "    'ill': 'Illinois', 'colo': 'Colorado', 'ore': 'Oregon'\n",
    "}\n",
    "\n",
    "\n",
    "df_clean['US_state_clean'] = df_clean['US_state']\n",
    "df_clean.loc[us_mask, 'US_state_clean'] = df_clean.loc[us_mask, 'US_state_clean'].replace(state_mapping)\n",
    "\n",
    "print(f\"\\nTop US states:\")\n",
    "print(df_clean[us_mask]['US_state_clean'].value_counts().head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Converting experience data to numeric...\n",
      "Experience conversion results:\n",
      "Total experience - valid: 28062\n",
      "Field experience - valid: 28062\n",
      "\n",
      "Total experience distribution:\n",
      "experience_total_numeric\n",
      "1.0      523\n",
      "3.0     3026\n",
      "6.0     4882\n",
      "9.0     5377\n",
      "15.5    9624\n",
      "25.5    3637\n",
      "35.5     869\n",
      "45.0     124\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Field experience distribution:\n",
      "experience_field_numeric\n",
      "1.0     1485\n",
      "3.0     6249\n",
      "6.0     6519\n",
      "9.0     4982\n",
      "15.5    6536\n",
      "25.5    1868\n",
      "35.5     382\n",
      "45.0      41\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Convert Experience Data to Numeric\n",
    "print(\"\\n4. Converting experience data to numeric...\")\n",
    "\n",
    "# Create mapping for experience ranges to numeric midpoints\n",
    "experience_mapping = {\n",
    "    '1 year or less': 1,\n",
    "    '2 - 4 years': 3,\n",
    "    '5-7 years': 6,\n",
    "    '8 - 10 years': 9,\n",
    "    '11 - 20 years': 15.5,\n",
    "    '21 - 30 years': 25.5,\n",
    "    '31 - 40 years': 35.5,\n",
    "    '41 years or more': 45\n",
    "}\n",
    "\n",
    "# Convert overall experience\n",
    "df_clean['experience_total_numeric'] = df_clean['experience_total_years'].map(experience_mapping)\n",
    "\n",
    "# Convert field experience  \n",
    "df_clean['experience_field_numeric'] = df_clean['experience_field_years'].map(experience_mapping)\n",
    "\n",
    "print(\"Experience conversion results:\")\n",
    "print(f\"Total experience - valid: {df_clean['experience_total_numeric'].notna().sum()}\")\n",
    "print(f\"Field experience - valid: {df_clean['experience_field_numeric'].notna().sum()}\")\n",
    "\n",
    "print(f\"\\nTotal experience distribution:\")\n",
    "print(df_clean['experience_total_numeric'].value_counts().sort_index())\n",
    "print(f\"\\nField experience distribution:\")\n",
    "print(df_clean['experience_field_numeric'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title\n",
      "Software Engineer               286\n",
      "Project Manager                 230\n",
      "Director                        198\n",
      "Senior Software Engineer        196\n",
      "Program Manager                 152\n",
      "                               ... \n",
      "Grants Administrator              1\n",
      "Supervisor, Communications        1\n",
      "Procurement Category Manager      1\n",
      "Director, Cloud Solutions         1\n",
      "Clinical physiologist             1\n",
      "Name: count, Length: 14346, dtype: int64\n",
      "industry\n",
      "Computing or Tech                          4699\n",
      "Education (Higher Education)               2464\n",
      "Nonprofits                                 2419\n",
      "Health care                                1896\n",
      "Government and Public Administration       1889\n",
      "                                           ... \n",
      "Gaming (Gambling)                             1\n",
      "Regulatory Affairs- nutraceuticals            1\n",
      "Manufacturing : corporate admin support       1\n",
      "Real Estate Investment Support                1\n",
      "Wine & Spirits                                1\n",
      "Name: count, Length: 1219, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['job_title'].value_counts())\n",
    "print(df_clean['industry'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Identifying tech roles and cleaning job titles...\n",
      "Tech roles identified: 3991\n",
      "Non-tech roles: 24071\n",
      "\n",
      "Tech roles by industry:\n",
      "industry\n",
      "Computing or Tech                       2235\n",
      "Engineering or Manufacturing             765\n",
      "Education (Higher Education)             115\n",
      "Government and Public Administration      97\n",
      "Health care                               96\n",
      "Accounting, Banking & Finance             87\n",
      "Utilities & Telecommunications            65\n",
      "Nonprofits                                59\n",
      "Media & Digital                           55\n",
      "Insurance                                 50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Identify Tech Roles and Clean Job Titles\n",
    "print(\"\\n5. Identifying tech roles and cleaning job titles...\")\n",
    "\n",
    "import re\n",
    "\n",
    "def is_tech_role(row):\n",
    "    job_title = str(row['job_title']).lower().strip()\n",
    "\n",
    "    # 1️⃣ Definite tech phrases (safe to include)\n",
    "    strong_tech = [\n",
    "        'software engineer', 'software developer', 'devops', 'cloud engineer',\n",
    "        'systems engineer', 'system administrator', 'sysadmin', 'it support',\n",
    "        'network engineer', 'data engineer', 'data scientist', 'data analyst',\n",
    "        'ml engineer', 'machine learning', 'ai engineer', 'cybersecurity',\n",
    "        'security engineer', 'full stack', 'frontend developer', 'backend developer',\n",
    "        'database administrator', 'dba', 'site reliability engineer', 'sre'\n",
    "    ]\n",
    "    if any(phrase in job_title for phrase in strong_tech):\n",
    "        return True\n",
    "\n",
    "    # 2️⃣ Definite non-tech contexts — if these appear, exclude\n",
    "    strong_nontech = [\n",
    "        'medical', 'vet', 'veterinary', 'nurse', 'lab', 'laboratory',\n",
    "        'scientist', 'biology', 'chemist', 'pharmacy', 'psychology', 'clinical',\n",
    "        'communications', 'marketing', 'policy', 'legal', 'attorney',\n",
    "        'finance', 'audit', 'account', 'recruit', 'grant', 'writer',\n",
    "        'teacher', 'education', 'coach', 'diversity', 'equity'\n",
    "    ]\n",
    "    if any(word in job_title for word in strong_nontech):\n",
    "        return False\n",
    "\n",
    "    # 3️⃣ Broader but contextual tech words\n",
    "    if re.search(r'\\b(it|technical|developer|engineer|architect|programmer|technology)\\b', job_title):\n",
    "        return True\n",
    "\n",
    "    # 4️⃣ Technician → only keep IT-related ones\n",
    "    if 'technician' in job_title:\n",
    "        if any(term in job_title for term in ['it', 'system', 'network', 'computer']):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "df_clean['is_tech_role'] = df_clean.apply(is_tech_role, axis=1)\n",
    "\n",
    "print(f\"Tech roles identified: {df_clean['is_tech_role'].sum()}\")\n",
    "print(f\"Non-tech roles: {(~df_clean['is_tech_role']).sum()}\")\n",
    "\n",
    "print(f\"\\nTech roles by industry:\")\n",
    "tech_roles = df_clean[df_clean['is_tech_role']]\n",
    "print(tech_roles['industry'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25393                                     Data Analyst\n",
       "18731                           Lead software engineer\n",
       "25524                             Product Data Analyst\n",
       "22927                               Frontend Developer\n",
       "19875                         Senior Software Engineer\n",
       "8626                          Senior Software Engineer\n",
       "18811                             Electrical Engineer \n",
       "16364                                    Data Engineer\n",
       "6079                         Senior Software Developer\n",
       "15885                             Chief Data Scientist\n",
       "10705                       Staff Developer Evangelist\n",
       "19712                                 Systems Engineer\n",
       "7581                                  Senior Developer\n",
       "7385                                  Systems Engineer\n",
       "18628                         Senior Software engineer\n",
       "4808                      Technical Services Librarian\n",
       "20429                     Optical development engineer\n",
       "10426                              Mechanical Engineer\n",
       "10199                              Sr process engineer\n",
       "891                                       Data Analyst\n",
       "18438                      Technical support engineer \n",
       "23131                                Software Engineer\n",
       "14186                         Lead Mechanical Engineer\n",
       "19064                                    Data Engineer\n",
       "19753                                   Staff Engineer\n",
       "20093                       Quality Assurance Engineer\n",
       "14860                          Staff Security Engineer\n",
       "23305                            Sr Software Engineer \n",
       "5096                     Principal Industrial Engineer\n",
       "7095                                    Data Analyst 2\n",
       "27933                                  DevOps Engineer\n",
       "18381                         Senior Software Engineer\n",
       "5116                 Senior ADMS Engineer - consultant\n",
       "23473                                   Data scientist\n",
       "11325                           GIS Programmer Analyst\n",
       "27928                              Master Data Analyst\n",
       "23297                                software engineer\n",
       "18832                                  Senior Engineer\n",
       "22949                                        Architect\n",
       "24059                         Principal Data Scientist\n",
       "27321                        Senior software engineer \n",
       "21477                                   Data Scientist\n",
       "12955                    Senior Applications Architect\n",
       "2116                           Senior Process Engineer\n",
       "11089                                 Process engineer\n",
       "20802                        Senior Software Developer\n",
       "13843                                      Engineer II\n",
       "7529     Information Systems and Technology Specialist\n",
       "24444                       Website Designer/Developer\n",
       "21537                                     Data Analyst\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[df_clean['is_tech_role'], 'job_title'].dropna().unique()\n",
    "df_clean['is_tech_role'] = df_clean.apply(is_tech_role, axis=1)\n",
    "tech_titles = df_clean.loc[df_clean['is_tech_role'], 'job_title']\n",
    "tech_titles.sample(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Data quality validation and outlier detection...\n",
      "USD salary analysis:\n",
      "Count: 23374\n",
      "Min: $0\n",
      "Max: $102,000,000\n",
      "Median: $78,000\n",
      "Mean: $97,041\n",
      "\n",
      "Potential outliers:\n",
      "Salaries < $10,000: 149\n",
      "Salaries > $1,000,000: 71\n",
      "\n",
      "Examples of low salary outliers:\n",
      "                      job_title                        industry  \\\n",
      "97       Quality Assurance Lead        Environmental regulation   \n",
      "895   Special Education Teacher   Education (Primary/Secondary)   \n",
      "968             Managing Editor                 Media & Digital   \n",
      "1607       Chief Data Scientist         Agriculture or Forestry   \n",
      "3887        freelance captioner                   accessibility   \n",
      "4081         Operations Manager                          Retail   \n",
      "4124     Engineering Supervisor    Engineering or Manufacturing   \n",
      "5211        Assistant Registrar  Museum (University Affiliated)   \n",
      "6124           Regional Manager                  Public Library   \n",
      "6550                    Manager   Education (Primary/Secondary)   \n",
      "\n",
      "      salary_numeric  \n",
      "97                58  \n",
      "895               38  \n",
      "968               61  \n",
      "1607             130  \n",
      "3887            4000  \n",
      "4081              35  \n",
      "4124             108  \n",
      "5211              40  \n",
      "6124              70  \n",
      "6550             155  \n"
     ]
    }
   ],
   "source": [
    "# 6. Data Quality Validation and Outlier Detection\n",
    "print(\"\\n6. Data quality validation and outlier detection...\")\n",
    "\n",
    "# Focus on USD salaries for outlier detection\n",
    "usd_salaries = df_clean[(df_clean['currency'] == 'USD') & \n",
    "                        (df_clean['salary_numeric'].notna())]['salary_numeric']\n",
    "\n",
    "print(f\"USD salary analysis:\")\n",
    "print(f\"Count: {len(usd_salaries)}\")\n",
    "print(f\"Min: ${usd_salaries.min():,.0f}\")\n",
    "print(f\"Max: ${usd_salaries.max():,.0f}\")\n",
    "print(f\"Median: ${usd_salaries.median():,.0f}\")\n",
    "print(f\"Mean: ${usd_salaries.mean():,.0f}\")\n",
    "\n",
    "# Identify potential outliers (salaries < 10k or > 1M)\n",
    "outlier_low = df_clean['salary_numeric'] < 10000\n",
    "outlier_high = df_clean['salary_numeric'] > 1000000\n",
    "\n",
    "print(f\"\\nPotential outliers:\")\n",
    "print(f\"Salaries < $10,000: {outlier_low.sum()}\")\n",
    "print(f\"Salaries > $1,000,000: {outlier_high.sum()}\")\n",
    "\n",
    "# Show some examples of low outliers\n",
    "print(f\"\\nExamples of low salary outliers:\")\n",
    "low_outliers = df_clean[outlier_low & (df_clean['currency'] == 'USD')]\n",
    "if len(low_outliers) > 0:\n",
    "    print(low_outliers[['job_title', 'industry', 'salary_numeric']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Creating analysis-ready dataset...\n",
      "Final dataset shape: (23023, 25)\n",
      "Data retention: 82.0% of original data\n",
      "\n",
      "Final dataset summary:\n",
      "- Total records: 23,023\n",
      "- Tech roles: 3,160\n",
      "- Non-tech roles: 19,863\n",
      "- Salary range: $10,000 - $954,000\n",
      "- Median salary: $78,750\n",
      "\n",
      "Final dataset columns:\n",
      "['timestamp', 'age', 'industry', 'job_title', 'job_context', 'annual_salary', 'additional_compensation', 'currency', 'currency_other', 'income_context', 'country', 'US_state', 'city', 'experience_total_years', 'experience_field_years', 'education', 'gender', 'race', 'salary_numeric', 'bonus_numeric', 'country_clean', 'US_state_clean', 'experience_total_numeric', 'experience_field_numeric', 'is_tech_role']\n"
     ]
    }
   ],
   "source": [
    "# 7. Create Analysis-Ready Dataset\n",
    "print(\"\\n7. Creating analysis-ready dataset...\")\n",
    "\n",
    "# Filter for reasonable salary range (10k - 1M USD)\n",
    "reasonable_salaries = (df_clean['salary_numeric'] >= 10000) & (df_clean['salary_numeric'] <= 1000000)\n",
    "\n",
    "# Create final cleaned dataset\n",
    "df_final = df_clean[\n",
    "    (df_clean['currency'] == 'USD') &  # USD only for analysis\n",
    "    (df_clean['salary_numeric'].notna()) &                 # Valid salary\n",
    "    reasonable_salaries &                                   # Reasonable salary range\n",
    "    (df_clean['country_clean'] == 'United States')         # US only\n",
    "].copy()\n",
    "\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(f\"Data retention: {len(df_final)/len(df)*100:.1f}% of original data\")\n",
    "\n",
    "# Summary of cleaned data\n",
    "print(f\"\\nFinal dataset summary:\")\n",
    "print(f\"- Total records: {len(df_final):,}\")\n",
    "print(f\"- Tech roles: {df_final['is_tech_role'].sum():,}\")\n",
    "print(f\"- Non-tech roles: {(~df_final['is_tech_role']).sum():,}\")\n",
    "print(f\"- Salary range: ${df_final['salary_numeric'].min():,.0f} - ${df_final['salary_numeric'].max():,.0f}\")\n",
    "print(f\"- Median salary: ${df_final['salary_numeric'].median():,.0f}\")\n",
    "\n",
    "print(f\"\\nFinal dataset columns:\")\n",
    "print(df_final.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Business Questions Analysis\n",
    "\n",
    "Now answer those important business questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: What is the median salary for Software Engineers in the United States?\n",
    "software_engineer_keywords = [\n",
    "    'software engineer', 'software developer', 'developer', 'programmer',\n",
    "    'application developer', 'application engineer', 'sde', 'backend',\n",
    "    'frontend', 'full stack', 'platform engineer', 'infrastructure engineer',\n",
    "    'site reliability engineer', 'sre', 'devops', 'cloud engineer',\n",
    "    'data engineer', 'ml engineer', 'ai engineer', 'android developer',\n",
    "    'ios developer', 'mobile developer', 'embedded engineer', 'firmware engineer',\n",
    "    'web developer', 'ui engineer', 'ux engineer', 'api developer',\n",
    "    'tools engineer', 'automation engineer', 'senior software engineer',\n",
    "    'principal software engineer', 'staff software engineer', 'lead software engineer',\n",
    "    'senior developer', 'principal developer', 'staff developer', 'lead developer',\n",
    "    'senior programmer', 'principal programmer', 'staff programmer', 'lead programmer',\n",
    "    'software architect', 'systems engineer', 'technical lead', 'engineering manager',\n",
    "    'software development engineer', 'swe', 'sw engineer', 'software dev',\n",
    "    'fullstack', 'full-stack', 'backend developer', 'frontend developer',\n",
    "    'full stack developer', 'full stack engineer', 'web engineer', 'mobile engineer',\n",
    "    'machine learning engineer', 'ai/ml engineer', 'data scientist', 'research engineer',\n",
    "    'security engineer', 'cybersecurity engineer', 'network engineer', 'database engineer',\n",
    "    'qa engineer', 'test engineer', 'quality assurance engineer', 'performance engineer',\n",
    "    'game developer', 'game engineer', 'unity developer', 'react developer',\n",
    "    'python developer', 'java developer', 'javascript developer', 'c++ developer',\n",
    "    'ios engineer', 'android engineer', 'cross-platform developer'\n",
    "]\n",
    "\n",
    "def is_software_engineer(job_title):\n",
    "    \"\"\"Check if a job title indicates a software engineering role\"\"\"\n",
    "    if pd.isna(job_title):\n",
    "        return False\n",
    "    \n",
    "    job_title_lower = str(job_title).lower()\n",
    "    \n",
    "    for keyword in software_engineer_keywords:\n",
    "        if keyword in job_title_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Apply the function to identify software engineers\n",
    "df_final['is_software_engineer'] = df_final['job_title'].apply(is_software_engineer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Software engineers with valid salaries: 1771\n",
      "Software engineers with realistic salaries ($20k-$700k): 1763\n",
      "\n",
      "📊 SOFTWARE ENGINEER SALARY ANALYSIS\n",
      "==================================================\n",
      "Sample size: 1,763 software engineers\n",
      "Median salary: $131,000\n",
      "Mean salary: $138,559\n",
      "Min salary: $28,800\n",
      "Max salary: $630,000\n",
      "25th percentile: $100,000\n",
      "75th percentile: $165,000\n",
      "\n",
      "📈 SALARY BY SENIORITY LEVEL\n",
      "===================================\n",
      "                 count    median      mean\n",
      "seniority                                 \n",
      "Junior/Entry        24   76500.0   76121.0\n",
      "Mid-level         1097  120000.0  128018.0\n",
      "Principal/Staff    113  180000.0  185020.0\n",
      "Senior             529  148000.0  153327.0\n",
      "\n",
      "🎯 FINAL ANSWER TO QUESTION 1\n",
      "==================================================\n",
      "Question: What is the median salary for Software Engineers in the United States?\n",
      "Answer: $131,000\n",
      "Based on 1,763 software engineers in the US with valid salary data.\n"
     ]
    }
   ],
   "source": [
    "# Calculate median salary for software engineers\n",
    "\n",
    "# Filter for software engineers with valid salaries\n",
    "swe_data = df_final[\n",
    "    (df_final['is_software_engineer'] == True) & \n",
    "    (df_final['salary_numeric'].notna()) &\n",
    "    (df_final['salary_numeric'] > 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nSoftware engineers with valid salaries: {len(swe_data)}\")\n",
    "\n",
    "# Remove extreme outliers for more realistic analysis\n",
    "swe_data_filtered = swe_data[\n",
    "    (swe_data['salary_numeric'] >= 20000) & \n",
    "    (swe_data['salary_numeric'] <= 700000)\n",
    "].copy()\n",
    "\n",
    "print(f\"Software engineers with realistic salaries ($20k-$700k): {len(swe_data_filtered)}\")\n",
    "\n",
    "# Calculate median salary\n",
    "median_salary = swe_data_filtered['salary_numeric'].median()\n",
    "mean_salary = swe_data_filtered['salary_numeric'].mean()\n",
    "\n",
    "print(f\"\\n📊 SOFTWARE ENGINEER SALARY ANALYSIS\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Sample size: {len(swe_data_filtered):,} software engineers\")\n",
    "print(f\"Median salary: ${median_salary:,.0f}\")\n",
    "print(f\"Mean salary: ${mean_salary:,.0f}\")\n",
    "print(f\"Min salary: ${swe_data_filtered['salary_numeric'].min():,.0f}\")\n",
    "print(f\"Max salary: ${swe_data_filtered['salary_numeric'].max():,.0f}\")\n",
    "print(f\"25th percentile: ${swe_data_filtered['salary_numeric'].quantile(0.25):,.0f}\")\n",
    "print(f\"75th percentile: ${swe_data_filtered['salary_numeric'].quantile(0.75):,.0f}\")\n",
    "\n",
    "# Analysis by seniority levels\n",
    "def get_seniority_level(job_title):\n",
    "    if pd.isna(job_title):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    title_lower = str(job_title).lower()\n",
    "    \n",
    "    if any(word in title_lower for word in ['principal', 'staff', 'distinguished']):\n",
    "        return 'Principal/Staff'\n",
    "    elif any(word in title_lower for word in ['senior', 'sr', 'lead']):\n",
    "        return 'Senior'\n",
    "    elif any(word in title_lower for word in ['junior', 'jr', 'entry', 'associate']):\n",
    "        return 'Junior/Entry'\n",
    "    else:\n",
    "        return 'Mid-level'\n",
    "\n",
    "swe_data_filtered['seniority'] = swe_data_filtered['job_title'].apply(get_seniority_level)\n",
    "\n",
    "print(f\"\\n📈 SALARY BY SENIORITY LEVEL\")\n",
    "print(f\"=\" * 35)\n",
    "seniority_analysis = swe_data_filtered.groupby('seniority')['salary_numeric'].agg([\n",
    "    'count', 'median', 'mean'\n",
    "]).round(0)\n",
    "print(seniority_analysis)\n",
    "\n",
    "# Final answer\n",
    "print(f\"\\n🎯 FINAL ANSWER TO QUESTION 1\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Question: What is the median salary for Software Engineers in the United States?\")\n",
    "print(f\"Answer: ${median_salary:,.0f}\")\n",
    "print(f\"Based on {len(swe_data_filtered):,} software engineers in the US with valid salary data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech workers with valid salary and state data: 5037\n",
      "Tech workers with realistic salaries ($20k-$700k): 5022\n",
      "\n",
      "📊 TECH WORKER SALARIES BY STATE\n",
      "==================================================\n",
      "States with 10+ tech workers (sorted by average salary):\n",
      "State                     Count    Avg Salary   Median       Std Dev     \n",
      "----------------------------------------------------------------------\n",
      "California                661      $147,461     $141,000     $67,037     \n",
      "Washington                284      $136,140     $135,000     $49,994     \n",
      "New York                  588      $130,706     $120,000     $63,037     \n",
      "Massachusetts             414      $120,919     $112,000     $47,893     \n",
      "District of Columbia      192      $119,302     $108,030     $54,758     \n",
      "Oregon                    163      $118,499     $110,000     $49,446     \n",
      "Virginia                  156      $117,898     $109,600     $50,861     \n",
      "New Jersey                70       $117,064     $109,500     $54,397     \n",
      "Colorado                  153      $116,480     $110,000     $59,511     \n",
      "Georgia                   107      $110,601     $93,000      $58,122     \n",
      "\n",
      "🎯 FINAL ANSWER TO QUESTION 2\n",
      "==================================================\n",
      "Question: Which US state has the highest average salary for tech workers?\n",
      "Answer: California\n",
      "Average salary: $147,461\n",
      "Sample size: 661 tech workers\n",
      "Top 5 highest-paying states for tech workers:\n",
      "1. California: $147,461 (n=661)\n",
      "2. Washington: $136,140 (n=284)\n",
      "3. New York: $130,706 (n=588)\n",
      "4. Massachusetts: $120,919 (n=414)\n",
      "5. District of Columbia: $119,302 (n=192)\n",
      "\n",
      "📈 ADDITIONAL INSIGHTS\n",
      "==============================\n",
      "• Total states analyzed: 42\n",
      "• Tech worker salary range across all states: $72,850 - $147,461\n",
      "• Salary difference between #1 and #2: $11,321\n",
      "• California has 661 tech workers, representing 13.2% of all tech workers in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Which US state has the highest average salary for tech workers?\n",
    "tech_keywords = [\n",
    "    # Software Engineering (already defined above)\n",
    "    'software engineer', 'software developer', 'developer', 'programmer',\n",
    "    'application developer', 'application engineer', 'sde', 'backend',\n",
    "    'frontend', 'full stack', 'platform engineer', 'infrastructure engineer',\n",
    "    'site reliability engineer', 'sre', 'devops', 'cloud engineer',\n",
    "    'data engineer', 'ml engineer', 'ai engineer', 'android developer',\n",
    "    'ios developer', 'mobile developer', 'embedded engineer', 'firmware engineer',\n",
    "    'web developer', 'ui engineer', 'ux engineer', 'api developer',\n",
    "    'tools engineer', 'automation engineer',\n",
    "    \n",
    "    # Data Science and Analytics\n",
    "    'data scientist', 'data analyst', 'analytics engineer', 'business analyst',\n",
    "    'data architect', 'machine learning engineer', 'research scientist',\n",
    "    'quantitative analyst', 'statistician',\n",
    "    \n",
    "    # Product and Design Tech Roles\n",
    "    'product manager', 'product owner', 'scrum master', 'agile coach',\n",
    "    'technical product manager', 'product analyst',\n",
    "    \n",
    "    # IT and Systems\n",
    "    'systems administrator', 'sysadmin', 'network administrator', 'database administrator',\n",
    "    'it manager', 'it director', 'technical support', 'help desk',\n",
    "    'cybersecurity analyst', 'security analyst', 'information security',\n",
    "    \n",
    "    # Tech Sales and Marketing\n",
    "    'sales engineer', 'technical sales', 'solution architect', 'pre-sales engineer',\n",
    "    'technical marketing', 'developer advocate', 'technical writer',\n",
    "    \n",
    "    # Engineering Management\n",
    "    'engineering manager', 'technical director', 'cto', 'vp engineering',\n",
    "    'head of engineering', 'engineering lead', 'tech lead',\n",
    "    \n",
    "    # Quality Assurance\n",
    "    'qa engineer', 'test engineer', 'quality assurance engineer', 'automation tester',\n",
    "    'performance engineer', 'test automation engineer',\n",
    "    \n",
    "    # Other Tech Roles\n",
    "    'solutions architect', 'enterprise architect', 'technical consultant',\n",
    "    'implementation engineer', 'integration engineer', 'technical project manager'\n",
    "]\n",
    "\n",
    "def is_tech_worker(job_title):\n",
    "    \"\"\"Check if a job title indicates a tech worker role\"\"\"\n",
    "    if pd.isna(job_title):\n",
    "        return False\n",
    "    \n",
    "    job_title_lower = str(job_title).lower()\n",
    "    \n",
    "    for keyword in tech_keywords:\n",
    "        if keyword.lower() in job_title_lower:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Apply the function to identify tech workers\n",
    "df_final['is_tech_worker'] = df_final['job_title'].apply(is_tech_worker)\n",
    "\n",
    "# Filter for tech workers with valid salaries\n",
    "tech_workers = df_final[\n",
    "    (df_final['is_tech_worker'] == True) & \n",
    "    (df_final['salary_numeric'].notna()) &\n",
    "    (df_final['salary_numeric'] > 0) & (df_final['country_clean'] == 'United States') &\n",
    "    (df_final['US_state_clean'].notna())  # Must have state data\n",
    "].copy()\n",
    "\n",
    "print(f\"Tech workers with valid salary and state data: {len(tech_workers)}\")\n",
    "\n",
    "# Remove extreme outliers for more realistic analysis\n",
    "tech_workers_filtered = tech_workers[\n",
    "    (tech_workers['salary_numeric'] >= 20000) & \n",
    "    (tech_workers['salary_numeric'] <= 700000)\n",
    "].copy()\n",
    "\n",
    "print(f\"Tech workers with realistic salaries ($20k-$700k): {len(tech_workers_filtered)}\")\n",
    "\n",
    "# Calculate average salary by state\n",
    "state_salaries = tech_workers_filtered.groupby('US_state_clean')['salary_numeric'].agg([\n",
    "    'count', 'mean', 'median', 'std'\n",
    "]).round(0)\n",
    "\n",
    "# Filter for states with at least 10 tech workers for statistical significance\n",
    "state_salaries_significant = state_salaries[state_salaries['count'] >= 10].copy()\n",
    "\n",
    "# Sort by average salary (mean)\n",
    "state_salaries_significant = state_salaries_significant.sort_values('mean', ascending=False)\n",
    "\n",
    "print(f\"\\n📊 TECH WORKER SALARIES BY STATE\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"States with 10+ tech workers (sorted by average salary):\")\n",
    "print(f\"{'State':<25} {'Count':<8} {'Avg Salary':<12} {'Median':<12} {'Std Dev':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for state, row in state_salaries_significant.head(10).iterrows():\n",
    "    print(f\"{state:<25} {row['count']:<8.0f} ${row['mean']:<11,.0f} ${row['median']:<11,.0f} ${row['std']:<11,.0f}\")\n",
    "\n",
    "# Find the state with highest average salary\n",
    "highest_paying_state = state_salaries_significant.index[0]\n",
    "highest_avg_salary = state_salaries_significant.iloc[0]['mean']\n",
    "state_count = state_salaries_significant.iloc[0]['count']\n",
    "\n",
    "print(f\"\\n🎯 FINAL ANSWER TO QUESTION 2\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Question: Which US state has the highest average salary for tech workers?\")\n",
    "print(f\"Answer: {highest_paying_state}\")\n",
    "print(f\"Average salary: ${highest_avg_salary:,.0f}\")\n",
    "print(f\"Sample size: {state_count:.0f} tech workers\")\n",
    "print(f\"Top 5 highest-paying states for tech workers:\")\n",
    "for i, (state, row) in enumerate(state_salaries_significant.head(5).iterrows()):\n",
    "    print(f\"{i+1}. {state}: ${row['mean']:,.0f} (n={row['count']:.0f})\")\n",
    "\n",
    "# Additional analysis - show some context\n",
    "print(f\"\\n📈 ADDITIONAL INSIGHTS\")\n",
    "print(f\"=\" * 30)\n",
    "print(f\"• Total states analyzed: {len(state_salaries_significant)}\")\n",
    "print(f\"• Tech worker salary range across all states: ${state_salaries_significant['mean'].min():,.0f} - ${state_salaries_significant['mean'].max():,.0f}\")\n",
    "print(f\"• Salary difference between #1 and #2: ${highest_avg_salary - state_salaries_significant.iloc[1]['mean']:,.0f}\")\n",
    "print(f\"• {highest_paying_state} has {state_count:.0f} tech workers, representing {state_count/len(tech_workers_filtered)*100:.1f}% of all tech workers in the dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated salary increase per year (tech roles): $9,278.57\n",
      "Estimated starting salary (tech roles): $80,050\n"
     ]
    }
   ],
   "source": [
    "#Question 3:    \n",
    "# Filter for tech roles with valid salary and experience\n",
    "tech_df = df_final[\n",
    "    (df_final['is_tech_role'] == True) &\n",
    "    df_final['salary_numeric'].notna() &\n",
    "    df_final['experience_total_numeric'].notna()\n",
    "]\n",
    "\n",
    "# Group by years of experience and calculate median salary\n",
    "median_salary_by_exp = tech_df.groupby('experience_total_numeric')['salary_numeric'].median().sort_index()\n",
    "\n",
    "# Compute year-over-year differences\n",
    "salary_diff = median_salary_by_exp.diff().dropna()\n",
    "\n",
    "# Average increase per year\n",
    "avg_increase_per_year = salary_diff.mean()\n",
    "\n",
    "# Estimated starting salary (median at 0 or 1 year)\n",
    "starting_salary = median_salary_by_exp.iloc[0]\n",
    "\n",
    "print(f\"Estimated salary increase per year (tech roles): ${avg_increase_per_year:,.2f}\")\n",
    "print(f\"Estimated starting salary (tech roles): ${starting_salary:,.0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown: 77.92%\n",
      "In-Office: 21.36%\n",
      "Remote: 0.67%\n",
      "Hybrid: 0.05%\n"
     ]
    }
   ],
   "source": [
    "# Question 4: What percentage of respondents work remotely vs. in-office?\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def infer_work_type(row):\n",
    "    title = str(row.get('job_title', '')).lower()\n",
    "    context = str(row.get('job_context', '')).lower()\n",
    "    text = title + ' ' + context  # combine both for context\n",
    "\n",
    "    if not text.strip():\n",
    "        return 'Unknown'\n",
    "    \n",
    "    remote_keywords = ['remote', 'work from home', 'wfh', 'telework', 'telecommute',\n",
    "        'virtual work', 'distributed team', 'home office', 'remote-first',\n",
    "        'fully remote', 'work remotely', 'offsite', 'off-site', 'anywhere',\n",
    "        'global team', 'remote position', '100% remote', 'remote role',\n",
    "        'remote environment', 'work at home', 'remote job',\n",
    "        'online only', 'remote-based', 'location independent',\n",
    "        'work anywhere', 'home-based', 'flexible location',\n",
    "        'digital nomad', 'remote contractor', 'remote freelancer',\n",
    "        'remote setup', 'virtual position', 'virtual role', 'in house', 'self-employed', 'customer service rep',\n",
    "        'customer support specialist'\n",
    "        ]\n",
    "    if any(fuzz.partial_ratio(word, text) > 90 for word in remote_keywords):\n",
    "        return 'Remote'\n",
    "    hybrid_keywords = ['hybrid', 'part remote', 'partly remote', 'split schedule',\n",
    "        '2 days remote', '3 days remote', 'couple days remote',\n",
    "        'office + home', 'remote some days', 'flexible work', 'mixed remote',\n",
    "        'in-person part time', 'partly in office', 'few days in office',\n",
    "        'flex work', 'flexible schedule', 'alternate remote', 'rotating remote',\n",
    "        'part office', 'half remote', 'some remote', 'blended work',\n",
    "        'combo of office and remote', 'partial remote']\n",
    "    if any(fuzz.partial_ratio(word, text) > 90 for word in hybrid_keywords):\n",
    "        return 'Hybrid'\n",
    "    office_keywords = [ 'in office', 'in-person','in person','onsite','on site', 'on-site', 'office-based',\n",
    "        'at office', 'in the building', 'at the facility', 'on campus', \n",
    "        'in hospital', 'in school', 'in clinic', 'front desk', 'in warehouse',\n",
    "        'on location', 'field work', 'at headquarters', 'office required',\n",
    "        'must be onsite', 'shift work', 'facility-based', 'work location',\n",
    "        'on the floor', 'in the store', 'site-based', 'rn']\n",
    "    if any(fuzz.partial_ratio(word, text) > 90 for word in office_keywords):\n",
    "        return 'In-Office'\n",
    "    # --- 1️⃣ Explicit indicators ---\n",
    "    if any(word in text for word in remote_keywords):\n",
    "        return 'Remote'\n",
    "    if any(word in text for word in hybrid_keywords ):\n",
    "        return 'Hybrid'\n",
    "    if any(word in text for word in office_keywords):\n",
    "        return 'In-Office'\n",
    "    \n",
    "    # --- 3️⃣ Likely in-office roles ---\n",
    "    office_roles = [\n",
    "        'teacher', 'professor', 'educator', 'lecturer', 'faculty',\n",
    "        'nurse', 'doctor', 'therapist', 'counselor', 'psychologist',\n",
    "        'retail', 'cashier', 'store associate', 'sales clerk', 'barista',\n",
    "        'server', 'waiter', 'cook', 'chef', 'housekeeper', 'janitor',\n",
    "        'construction', 'mechanic', 'driver', 'warehouse', 'delivery',\n",
    "        'security', 'maintenance', 'manufacturing', 'assembly', 'technician',\n",
    "        'public library', 'government', 'healthcare', 'hospital',\n",
    "        'school', 'university', 'campus', 'clinic', 'library', 'librarian', 'chemist', 'scientist', 'attorney',\n",
    "        'police', 'firefighter', 'military', 'lab technician', 'groundskeeper', 'driving', 'receptionist', 'veterinarian', 'ogist', 'cist', 'ician',\n",
    "        'lab', 'electrician', 'dental', 'surgeon', 'ortho', 'carpent', 'plumb' \n",
    "    ]\n",
    "    if any(word in text for word in office_roles):\n",
    "        return 'In-Office'\n",
    "    if any(fuzz.partial_ratio(word, text) > 90 for word in office_roles):\n",
    "        return 'In-Office'\n",
    "    return 'Unknown'\n",
    "\n",
    "df_final['work_type'] = df_final.apply(infer_work_type, axis=1)\n",
    "work_type_percent = (df_final['work_type'].value_counts(normalize=True) * 100).round(2)\n",
    "for work_type, pct in work_type_percent.items():\n",
    "    print(f\"{work_type}: {pct}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_context\n",
      "Fundraising                                                              19\n",
      "In commercial real estate industry                                       10\n",
      "                                                                          9\n",
      "Compliance                                                                5\n",
      "Human Resources                                                           4\n",
      "                                                                         ..\n",
      "I work on Digital Marketing                                               1\n",
      "Applications and Data Management                                          1\n",
      "Software developer, DevOps practitioner                                   1\n",
      "It's a combination role of Project Manager and Client Success Manager     1\n",
      "I build airplanes                                                         1\n",
      "Name: count, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unknown_rows = df_final[df_final['work_type'] == 'Unknown'][['job_title', 'job_context']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The non-tech industry with the highest median salary is 'Commercial Building Material Distribution' with a median salary of $400,000.0\n",
      "\n",
      "Top 5 non-tech industries by median salary:\n",
      "Commercial Building Material Distribution: $400,000.0\n",
      "Sports: $300,000.0\n",
      "Corporate Training: $280,000.0\n",
      "Energy (oil & gas & associated products, renewable power, etc): $253,300.0\n",
      "Pharmaceutical/biotechnology: $227,500.0\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Which industry (besides tech) has the highest median salary?\n",
    "# Filter out tech roles and remove missing industries\n",
    "non_tech_df = df_final[(df_final['is_tech_role'] == False) & (df_final['industry'].notna())]\n",
    "\n",
    "# Group by industry and calculate median salary\n",
    "industry_median_salary = non_tech_df.groupby('industry')['salary_numeric'].median()\n",
    "\n",
    "# Sort descending to get the highest median salaries\n",
    "industry_median_salary_sorted = industry_median_salary.sort_values(ascending=False)\n",
    "\n",
    "# Print top industry nicely\n",
    "top_industry = industry_median_salary_sorted.head(1)\n",
    "for industry, median_salary in top_industry.items():\n",
    "    print(f\"The non-tech industry with the highest median salary is '{industry}' with a median salary of ${median_salary:,}\")\n",
    "\n",
    "# Optional: Print top 5 industries for context\n",
    "print(\"\\nTop 5 non-tech industries by median salary:\")\n",
    "for industry, median_salary in industry_median_salary_sorted.head(5).items():\n",
    "    print(f\"{industry}: ${median_salary:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 roles with largest mean Man-Woman salary gaps:\n",
      "\n",
      "Job Title                                  Man Salary   Woman Salary          Gap\n",
      "--------------------------------------------------------------------------------\n",
      "Program Associate                        $    510,000 $      127,491 $    382,509\n",
      "Managing director                        $    390,000 $       91,500 $    298,500\n",
      "Senior Financial Analyst                 $    346,800 $       90,980 $    255,820\n",
      "Physician                                $    488,000 $      300,000 $    188,000\n",
      "Staff Engineer                           $    253,000 $       82,416 $    170,584\n",
      "Design Strategist                        $    250,000 $       85,000 $    165,000\n",
      "Director of Education                    $    205,000 $       51,500 $    153,500\n",
      "Grants Director                          $    207,500 $       54,000 $    153,500\n",
      "Head of School                           $    210,000 $       61,000 $    149,000\n",
      "VP Engineering                           $    259,333 $      115,000 $    144,333\n"
     ]
    }
   ],
   "source": [
    "# Bonus Questions:\n",
    "# Question 6: What's the salary gap between men and women in similar roles?\n",
    "salary_df = df_final[\n",
    "    df_final['salary_numeric'].notna() & \n",
    "    df_final['gender'].notna() & \n",
    "    df_final['job_title'].notna()\n",
    "]\n",
    "mean_salary_by_role = salary_df.groupby(['job_title', 'gender'])['salary_numeric'].mean().unstack()\n",
    "mean_salary_by_role['gap'] = mean_salary_by_role['Man'] - mean_salary_by_role['Woman']\n",
    "mean_salary_by_role = mean_salary_by_role.sort_values('gap', ascending=False)\n",
    "\n",
    "print(\"Top 10 roles with largest mean Man-Woman salary gaps:\\n\")\n",
    "print(f\"{'Job Title':40} {'Man Salary':>12} {'Woman Salary':>14} {'Gap':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for job, row in mean_salary_by_role.head(10).iterrows():\n",
    "    print(f\"{job:40} ${row['Man']:>11,.0f} ${row['Woman']:>13,.0f} ${row['gap']:>11,.0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary comparison: Master's degree vs College degree\n",
      "\n",
      "Master's degree | Median: $80,000 | Mean: $91,780 | Count: 7399\n",
      "College degree  | Median: $75,000 | Mean: $87,097 | Count: 11221\n",
      "Answer: NO\n"
     ]
    }
   ],
   "source": [
    "# Question 7: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "# Filter relevant rows\n",
    "edu_salary_df = df_final[\n",
    "    df_final['salary_numeric'].notna() & \n",
    "    df_final['education'].notna()\n",
    "]\n",
    "\n",
    "# Select only Master's and College degrees\n",
    "edu_salary_df = edu_salary_df[edu_salary_df['education'].isin([\"Master's degree\", \"College degree\"])]\n",
    "\n",
    "# Group by education and compute median and mean salary\n",
    "salary_by_edu = edu_salary_df.groupby('education')['salary_numeric'].agg(['median', 'mean', 'count']).sort_values('median', ascending=False)\n",
    "\n",
    "# Print nicely\n",
    "print(\"Salary comparison: Master's degree vs College degree\\n\")\n",
    "for edu, row in salary_by_edu.iterrows():\n",
    "    print(f\"{edu:15} | Median: ${row['median']:,.0f} | Mean: ${row['mean']:,.0f} | Count: {int(row['count'])}\")\n",
    "print('Answer: NO')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Size | Count |  Median Salary |  Average Salary\n",
      "-------------------------------------------------------\n",
      "Large      |  32.0 | $      101,250 | $       117,578\n",
      "Startup    |  53.0 | $       89,000 | $       114,340\n",
      "Medium     |  21.0 | $       75,000 | $        80,541\n"
     ]
    }
   ],
   "source": [
    "# Question 8: Which company size (startup, medium, large) pays the most on average?\n",
    "\n",
    "# --- 1️⃣ Function to infer company size ---\n",
    "def infer_company_size(text):\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return 'Unknown'\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Keywords for small/startup\n",
    "    small_keywords = ['startup', 'early-stage', 'small team', 'founder', 'small company', 'bootstrapped', 'seed round']\n",
    "    if any(word in text for word in small_keywords):\n",
    "        return 'Startup'\n",
    "    \n",
    "    # Keywords for medium\n",
    "    medium_keywords = ['mid-size', 'medium', 'growing company', 'scaling company', 'series b', 'series c']\n",
    "    if any(word in text for word in medium_keywords):\n",
    "        return 'Medium'\n",
    "    \n",
    "    # Keywords for large\n",
    "    large_keywords = ['large company', 'enterprise', 'fortune 500', 'corporation', 'multinational', 'public company', 'global company']\n",
    "    if any(word in text for word in large_keywords):\n",
    "        return 'Large'\n",
    "    \n",
    "    return 'Unknown'\n",
    "\n",
    "# --- 2️⃣ Apply function ---\n",
    "df_final['company_size'] = df_final['job_context'].apply(infer_company_size)\n",
    "\n",
    "# --- 3️⃣ Compute average, median, and count ---\n",
    "size_salary_stats = df_final[df_final['company_size'] != 'Unknown'].groupby('company_size')['salary_numeric'].agg(\n",
    "    count='count',\n",
    "    median='median',\n",
    "    mean='mean'\n",
    ").sort_values('median', ascending=False)\n",
    "\n",
    "# --- 4️⃣ Print nicely ---\n",
    "print(f\"{'Company Size':10} | {'Count':>5} | {'Median Salary':>14} | {'Average Salary':>15}\")\n",
    "print(\"-\" * 55)\n",
    "for size, row in size_salary_stats.iterrows():\n",
    "    print(f\"{size:10} | {row['count']:>5} | ${row['median']:>13,.0f} | ${row['mean']:>14,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Summarize your findings here:**\n",
    "\n",
    "1. **Median salary for Software Engineers in US:** $131,000\n",
    "2. **Highest paying US state for tech:** California\n",
    "3. **Salary increase per year of experience:** Estimated salary increase per year (tech roles): $9,278.57\n",
    "4. **Remote vs office percentage:** \n",
    "In-Office: 21.36%\n",
    "Remote: 0.67%\n",
    "5. **Highest paying non-tech industry:** Commercial Building Material Distribution\n",
    "\n",
    "\n",
    "**Key insights:**\n",
    "- Insight 1 - Master's degree is not that significant in salary increases.\n",
    "- Insight 2 - Salary gaps between men and women persist even within the same roles\n",
    "- Insight 3 - Certain industries outside tech, like finance or healthcare, can offer high median salaries despite smaller representation in the dataset.\n",
    "\n",
    "**Challenges faced:**\n",
    "- Challenge 1 and how you solved it - Making inferences just from job context was hard and time consuming. I had to produce a keyword list and check the actual data then refine the list repeatedly.\n",
    "- Challenge 2 and how you solved it - Cursor deleted some of my previous work and I was unable to properly restore it. Next time, I will have to be more specific about what I am prompting.\n",
    "\n",
    "**What you learned about vibe coding:**\n",
    "- Learning 1 - While vibe coding can handle repetitive tasks, decisions like what counts as “remote” or “large company” still need human judgment.\n",
    "- Learning 2 - The first output is rarely perfect, so you learn to refine instructions and outputs like debugging a conversation\n",
    "- Learning 3 - Sometimes it produces overly detailed code so I have learn to extract only what’s relevant\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
