{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. üôÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you‚Äôll‚Äïof course‚Äïovercome them with what you learned in class! üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>car racing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0    2.4       2          1               430           NaN           315.0   \n",
       "1  3.654       1          1               610           3.0           420.0   \n",
       "2    3.3       1          1               720           4.0           420.0   \n",
       "3    3.2       1          1               430           3.0           420.0   \n",
       "4    3.5       1          1               720           2.0           420.0   \n",
       "\n",
       "   coffee                      comfort_food        comfort_food_reasons  \\\n",
       "0       1                              none       we dont have comfort    \n",
       "1       2       chocolate, chips, ice cream        Stress, bored, anger   \n",
       "2       2   frozen yogurt, pizza, fast food             stress, sadness   \n",
       "3       2  Pizza, Mac and cheese, ice cream                     Boredom   \n",
       "4       2      Ice cream, chocolate, chips   Stress, boredom, cravings    \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "0                         9.0  ...   1.0     1.0          1            1165.0   \n",
       "1                         1.0  ...   1.0     1.0          2             725.0   \n",
       "2                         1.0  ...   1.0     2.0          5            1165.0   \n",
       "3                         2.0  ...   1.0     2.0          5             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             940.0   \n",
       "\n",
       "   turkey_calories  type_sports veggies_day  vitamins  waffle_calories  \\\n",
       "0              345   car racing           5         1             1315   \n",
       "1              690  Basketball            4         2              900   \n",
       "2              500         none           5         1              900   \n",
       "3              690          NaN           3         1             1315   \n",
       "4              500     Softball           4         2              760   \n",
       "\n",
       "                     weight  \n",
       "0                       187  \n",
       "1                       155  \n",
       "2  I'm not answering this.   \n",
       "3             Not sure, 240  \n",
       "4                       190  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = '../data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)\n",
    "df_food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 61)\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "count = df_food.shape\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA                  object\n",
      "Gender                int64\n",
      "breakfast             int64\n",
      "calories_chicken      int64\n",
      "calories_day        float64\n",
      "                     ...   \n",
      "type_sports          object\n",
      "veggies_day           int64\n",
      "vitamins              int64\n",
      "waffle_calories       int64\n",
      "weight               object\n",
      "Length: 61, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "col_types = df_food.dtypes\n",
    "print(col_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we‚Äôd like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. ‚Ä¶and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories_day                    weight  Gender\n",
      "0           NaN                       187       2\n",
      "1           3.0                       155       1\n",
      "2           4.0  I'm not answering this.        1\n",
      "3           3.0             Not sure, 240       1\n",
      "4           2.0                       190       1\n",
      "(125, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove ‚Äòem.\n",
    "keep_cols = df_food[['calories_day','weight','Gender']]\n",
    "print(keep_cols.head())\n",
    "print(keep_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "# Count ‚Äòem.\n",
    "nan_count = df_food.isnull().sum().sum() \n",
    "# the first .sum() counts per col; the second .sum() counts for the entire df\n",
    "print(nan_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s‚Äïthe entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     calories_day                    weight  Gender\n",
      "1             3.0                       155       1\n",
      "2             4.0  I'm not answering this.        1\n",
      "3             3.0             Not sure, 240       1\n",
      "4             2.0                       190       1\n",
      "5             3.0                       190       1\n",
      "..            ...                       ...     ...\n",
      "118           3.0                       140       1\n",
      "119           3.0                       185       2\n",
      "120           4.0                       156       1\n",
      "121           2.0                       180       1\n",
      "123           4.0                       135       2\n",
      "\n",
      "[104 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop ‚Äòem.\n",
    "no_nans = keep_cols.dropna()\n",
    "print(no_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. ü§î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     calories_day  weight  Gender\n",
      "1             3.0   155.0       1\n",
      "4             2.0   190.0       1\n",
      "5             3.0   190.0       1\n",
      "6             3.0   180.0       2\n",
      "7             3.0   137.0       1\n",
      "..            ...     ...     ...\n",
      "118           3.0   140.0       1\n",
      "119           3.0   185.0       2\n",
      "120           4.0   156.0       1\n",
      "121           2.0   180.0       1\n",
      "123           4.0   135.0       2\n",
      "\n",
      "[101 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fix that.\n",
    "#print(no_nans.dtypes) # weight is object dtype\n",
    "\n",
    "df_food_fixed = df_food[['calories_day', 'weight', 'Gender']].copy()\n",
    "df_food_fixed['weight'] = pd.to_numeric(df_food_fixed['weight'], errors='coerce')\n",
    "df_food_fixed = df_food_fixed.dropna()\n",
    "print(df_food_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! üòÅ\n",
    "\n",
    "Let‚Äôs save it somewhere to be shipped off to another teammate. üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "df_food_fixed.to_csv('../data/cleaned_food_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What industry do you work in?</th>\n",
       "      <th>Job title</th>\n",
       "      <th>If your job title needs additional context, please clarify here:</th>\n",
       "      <th>What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)</th>\n",
       "      <th>How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.</th>\n",
       "      <th>Please indicate the currency</th>\n",
       "      <th>If \"Other,\" please indicate the currency here:</th>\n",
       "      <th>If your income needs additional context, please provide it here:</th>\n",
       "      <th>What country do you work in?</th>\n",
       "      <th>If you're in the U.S., what state do you work in?</th>\n",
       "      <th>What city do you work in?</th>\n",
       "      <th>How many years of professional work experience do you have overall?</th>\n",
       "      <th>How many years of professional work experience do you have in your field?</th>\n",
       "      <th>What is your highest level of education completed?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your race? (Choose all that apply.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp How old are you?  What industry do you work in?  \\\n",
       "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  Job title  \\\n",
       "0        Research and Instruction Librarian   \n",
       "1  Change & Internal Communications Manager   \n",
       "2                      Marketing Specialist   \n",
       "3                           Program Manager   \n",
       "4                        Accounting Manager   \n",
       "\n",
       "  If your job title needs additional context, please clarify here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
       "0                                             55,000                                                                                                                                                                                     \n",
       "1                                             54,600                                                                                                                                                                                     \n",
       "2                                             34,000                                                                                                                                                                                     \n",
       "3                                             62,000                                                                                                                                                                                     \n",
       "4                                             60,000                                                                                                                                                                                     \n",
       "\n",
       "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
       "0                                                0.0                                                                                                                                                \n",
       "1                                             4000.0                                                                                                                                                \n",
       "2                                                NaN                                                                                                                                                \n",
       "3                                             3000.0                                                                                                                                                \n",
       "4                                             7000.0                                                                                                                                                \n",
       "\n",
       "  Please indicate the currency  \\\n",
       "0                          USD   \n",
       "1                          GBP   \n",
       "2                          USD   \n",
       "3                          USD   \n",
       "4                          USD   \n",
       "\n",
       "  If \"Other,\" please indicate the currency here:   \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "  If your income needs additional context, please provide it here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What country do you work in?  \\\n",
       "0                United States   \n",
       "1               United Kingdom   \n",
       "2                           US   \n",
       "3                          USA   \n",
       "4                           US   \n",
       "\n",
       "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
       "0                                     Massachusetts                    Boston   \n",
       "1                                               NaN                 Cambridge   \n",
       "2                                         Tennessee               Chattanooga   \n",
       "3                                         Wisconsin                 Milwaukee   \n",
       "4                                    South Carolina                Greenville   \n",
       "\n",
       "  How many years of professional work experience do you have overall?  \\\n",
       "0                                          5-7 years                    \n",
       "1                                       8 - 10 years                    \n",
       "2                                        2 - 4 years                    \n",
       "3                                       8 - 10 years                    \n",
       "4                                       8 - 10 years                    \n",
       "\n",
       "  How many years of professional work experience do you have in your field?  \\\n",
       "0                                          5-7 years                          \n",
       "1                                          5-7 years                          \n",
       "2                                        2 - 4 years                          \n",
       "3                                          5-7 years                          \n",
       "4                                          5-7 years                          \n",
       "\n",
       "  What is your highest level of education completed? What is your gender?  \\\n",
       "0                                    Master's degree                Woman   \n",
       "1                                     College degree           Non-binary   \n",
       "2                                     College degree                Woman   \n",
       "3                                     College degree                Woman   \n",
       "4                                     College degree                Woman   \n",
       "\n",
       "  What is your race? (Choose all that apply.)  \n",
       "0                                       White  \n",
       "1                                       White  \n",
       "2                                       White  \n",
       "3                                       White  \n",
       "4                                       White  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "df_salary = pd.read_csv('../data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv', sep='\\t')\n",
    "df_salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? üôÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28062, 18)\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. I‚Äôm dead serious.\n",
    "count = df_salary.shape\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                                                                                                                                                                                                                                object\n",
      "How old are you?                                                                                                                                                                                                                         object\n",
      "What industry do you work in?                                                                                                                                                                                                            object\n",
      "Job title                                                                                                                                                                                                                                object\n",
      "If your job title needs additional context, please clarify here:                                                                                                                                                                         object\n",
      "What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)     object\n",
      "How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                          float64\n",
      "Please indicate the currency                                                                                                                                                                                                             object\n",
      "If \"Other,\" please indicate the currency here:                                                                                                                                                                                           object\n",
      "If your income needs additional context, please provide it here:                                                                                                                                                                         object\n",
      "What country do you work in?                                                                                                                                                                                                             object\n",
      "If you're in the U.S., what state do you work in?                                                                                                                                                                                        object\n",
      "What city do you work in?                                                                                                                                                                                                                object\n",
      "How many years of professional work experience do you have overall?                                                                                                                                                                      object\n",
      "How many years of professional work experience do you have in your field?                                                                                                                                                                object\n",
      "What is your highest level of education completed?                                                                                                                                                                                       object\n",
      "What is your gender?                                                                                                                                                                                                                     object\n",
      "What is your race? (Choose all that apply.)                                                                                                                                                                                              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "col_types = df_salary.dtypes\n",
    "print(col_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh‚Ä¶ Ugh! Give these columns easier names to work with first. üôÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                       industry  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                      title title_context  salary  \\\n",
       "0        Research and Instruction Librarian           NaN  55,000   \n",
       "1  Change & Internal Communications Manager           NaN  54,600   \n",
       "2                      Marketing Specialist           NaN  34,000   \n",
       "3                           Program Manager           NaN  62,000   \n",
       "4                        Accounting Manager           NaN  60,000   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context  \\\n",
       "0                      0.0      USD            NaN            NaN   \n",
       "1                   4000.0      GBP            NaN            NaN   \n",
       "2                      NaN      USD            NaN            NaN   \n",
       "3                   3000.0      USD            NaN            NaN   \n",
       "4                   7000.0      USD            NaN            NaN   \n",
       "\n",
       "          country           state         city     total_yoe    field_yoe  \\\n",
       "0   United States   Massachusetts       Boston     5-7 years    5-7 years   \n",
       "1  United Kingdom             NaN    Cambridge  8 - 10 years    5-7 years   \n",
       "2              US       Tennessee  Chattanooga   2 - 4 years  2 - 4 years   \n",
       "3             USA       Wisconsin    Milwaukee  8 - 10 years    5-7 years   \n",
       "4              US  South Carolina   Greenville  8 - 10 years    5-7 years   \n",
       "\n",
       "  highest_education_completed      gender   race  \n",
       "0             Master's degree       Woman  White  \n",
       "1              College degree  Non-binary  White  \n",
       "2              College degree       Woman  White  \n",
       "3              College degree       Woman  White  \n",
       "4              College degree       Woman  White  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename ‚Äòem.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed\tgender, race\n",
    "\n",
    "new_colnames = ['timestamp', 'age', 'industry', 'title', 'title_context', \n",
    "                'salary', 'additional_compensation', 'currency', 'other_currency', \n",
    "                'salary_context', 'country', 'state', 'city', 'total_yoe', \n",
    "                'field_yoe', 'highest_education_completed', 'gender', 'race']\n",
    "\n",
    "df_salary.columns = new_colnames\n",
    "\n",
    "df_salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It‚Äôs a lot, and that should not have been easy. üòè"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôre going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry\n",
      "Computing or Tech                        4699\n",
      "Education (Higher Education)             2464\n",
      "Nonprofits                               2419\n",
      "Health care                              1896\n",
      "Government and Public Administration     1889\n",
      "                                         ... \n",
      "Warehousing                                 1\n",
      "Education (Early Childhood Education)       1\n",
      "SAAS                                        1\n",
      "Health and Safety                           1\n",
      "Aerospace Manufacturing                     1\n",
      "Name: count, Length: 1219, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "print(df_salary['industry'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you‚Äôre looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187,500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110,000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144,600</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    age           industry  \\\n",
       "1   4/27/2021 11:02:22  25-34  Computing or Tech   \n",
       "8   4/27/2021 11:03:01  45-54  Computing or Tech   \n",
       "43  4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "44  4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "46  4/27/2021 11:04:07  35-44  Computing or Tech   \n",
       "\n",
       "                                       title                 title_context  \\\n",
       "1   Change & Internal Communications Manager                           NaN   \n",
       "8                            Systems Analyst  Data developer/ETL Developer   \n",
       "43               Principal Software Engineer                           NaN   \n",
       "44                      Intelligence Analyst                           NaN   \n",
       "46                          Mobile developer                           NaN   \n",
       "\n",
       "     salary  additional_compensation currency other_currency  \\\n",
       "1    54,600                   4000.0      GBP            NaN   \n",
       "8   112,000                  10000.0      USD            NaN   \n",
       "43  187,500                   5000.0      USD            NaN   \n",
       "44  110,000                  20000.0      USD            NaN   \n",
       "46  144,600                   2500.0      USD            NaN   \n",
       "\n",
       "                   salary_context         country          state  \\\n",
       "1                             NaN  United Kingdom            NaN   \n",
       "8                             NaN              US       Missouri   \n",
       "43                            NaN   United States   Pennsylvania   \n",
       "44  Around 20,000 a year in stock             USA       Virginia   \n",
       "46                            NaN             USA  Massachusetts   \n",
       "\n",
       "             city      total_yoe      field_yoe highest_education_completed  \\\n",
       "1       Cambridge   8 - 10 years      5-7 years              College degree   \n",
       "8       St. Louis  21 - 30 years  21 - 30 years              College degree   \n",
       "43     Pittsburgh   8 - 10 years      5-7 years              College degree   \n",
       "44  Arlington, VA   8 - 10 years   8 - 10 years             Master's degree   \n",
       "46         Boston      5-7 years      5-7 years                         PhD   \n",
       "\n",
       "        gender   race  \n",
       "1   Non-binary  White  \n",
       "8        Woman  White  \n",
       "43       Woman  White  \n",
       "44         Man  White  \n",
       "46       Woman  White  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "df_salary_tech = df_salary[df_salary['industry'] == 'Computing or Tech']\n",
    "df_salary_tech.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry\n",
      "Computing or Tech    4699\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check \n",
    "print(df_salary_tech['industry'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars üíµ is a euro üí∂ or a pound üí∑? That sounds like a problem for another day. ü´†\n",
    "\n",
    "For now, let‚Äôs just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187,500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110,000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144,600</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4/27/2021 11:04:09</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Design Director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200,850</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    age           industry                        title  \\\n",
       "8   4/27/2021 11:03:01  45-54  Computing or Tech              Systems Analyst   \n",
       "43  4/27/2021 11:04:04  25-34  Computing or Tech  Principal Software Engineer   \n",
       "44  4/27/2021 11:04:04  25-34  Computing or Tech         Intelligence Analyst   \n",
       "46  4/27/2021 11:04:07  35-44  Computing or Tech             Mobile developer   \n",
       "47  4/27/2021 11:04:09  35-44  Computing or Tech      Product Design Director   \n",
       "\n",
       "                   title_context   salary  additional_compensation currency  \\\n",
       "8   Data developer/ETL Developer  112,000                  10000.0      USD   \n",
       "43                           NaN  187,500                   5000.0      USD   \n",
       "44                           NaN  110,000                  20000.0      USD   \n",
       "46                           NaN  144,600                   2500.0      USD   \n",
       "47                           NaN  200,850                  40000.0      USD   \n",
       "\n",
       "   other_currency                 salary_context        country  \\\n",
       "8             NaN                            NaN             US   \n",
       "43            NaN                            NaN  United States   \n",
       "44            NaN  Around 20,000 a year in stock            USA   \n",
       "46            NaN                            NaN            USA   \n",
       "47            NaN                            NaN            USA   \n",
       "\n",
       "             state           city      total_yoe      field_yoe  \\\n",
       "8         Missouri      St. Louis  21 - 30 years  21 - 30 years   \n",
       "43    Pennsylvania     Pittsburgh   8 - 10 years      5-7 years   \n",
       "44        Virginia  Arlington, VA   8 - 10 years   8 - 10 years   \n",
       "46   Massachusetts         Boston      5-7 years      5-7 years   \n",
       "47  North Carolina    Chapel Hill  11 - 20 years  11 - 20 years   \n",
       "\n",
       "   highest_education_completed gender   race  \n",
       "8               College degree  Woman  White  \n",
       "43              College degree  Woman  White  \n",
       "44             Master's degree    Man  White  \n",
       "46                         PhD  Woman  White  \n",
       "47              College degree  Woman  White  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "df_salary_tech_usd = df_salary_tech[df_salary_tech['currency'] == 'USD']\n",
    "df_salary_tech_usd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States               1576\n",
      "USA                         1222\n",
      "US                           412\n",
      "U.S.                         108\n",
      "United States of America      90\n",
      "                            ... \n",
      "Ghana                          1\n",
      "Nigeria                        1\n",
      "ss                             1\n",
      "Nigeria                        1\n",
      "Burma                          1\n",
      "Name: count, Length: 76, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "print(df_salary_tech_usd['country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can‚Äôt get our answers with what we currently have, so you‚Äôll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value‚Äïsay, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187,500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110,000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>US</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144,600</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4/27/2021 11:04:09</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Design Director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200,850</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    age           industry                        title  \\\n",
       "8   4/27/2021 11:03:01  45-54  Computing or Tech              Systems Analyst   \n",
       "43  4/27/2021 11:04:04  25-34  Computing or Tech  Principal Software Engineer   \n",
       "44  4/27/2021 11:04:04  25-34  Computing or Tech         Intelligence Analyst   \n",
       "46  4/27/2021 11:04:07  35-44  Computing or Tech             Mobile developer   \n",
       "47  4/27/2021 11:04:09  35-44  Computing or Tech      Product Design Director   \n",
       "\n",
       "                   title_context   salary  additional_compensation currency  \\\n",
       "8   Data developer/ETL Developer  112,000                  10000.0      USD   \n",
       "43                           NaN  187,500                   5000.0      USD   \n",
       "44                           NaN  110,000                  20000.0      USD   \n",
       "46                           NaN  144,600                   2500.0      USD   \n",
       "47                           NaN  200,850                  40000.0      USD   \n",
       "\n",
       "   other_currency                 salary_context country           state  \\\n",
       "8             NaN                            NaN      US        Missouri   \n",
       "43            NaN                            NaN      US    Pennsylvania   \n",
       "44            NaN  Around 20,000 a year in stock      US        Virginia   \n",
       "46            NaN                            NaN      US   Massachusetts   \n",
       "47            NaN                            NaN      US  North Carolina   \n",
       "\n",
       "             city      total_yoe      field_yoe highest_education_completed  \\\n",
       "8       St. Louis  21 - 30 years  21 - 30 years              College degree   \n",
       "43     Pittsburgh   8 - 10 years      5-7 years              College degree   \n",
       "44  Arlington, VA   8 - 10 years   8 - 10 years             Master's degree   \n",
       "46         Boston      5-7 years      5-7 years                         PhD   \n",
       "47    Chapel Hill  11 - 20 years  11 - 20 years              College degree   \n",
       "\n",
       "   gender   race  \n",
       "8   Woman  White  \n",
       "43  Woman  White  \n",
       "44    Man  White  \n",
       "46  Woman  White  \n",
       "47  Woman  White  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace them all with 'US'.\n",
    "vals_to_replace = ['United States', 'USA', 'US', 'U.S.', 'United States of America']\n",
    "df_salary_tech_usd = df_salary_tech[df_salary_tech['currency'] == 'USD'].copy()\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].replace(vals_to_replace, 'US')\n",
    "\n",
    "df_salary_tech_usd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "US                3408\n",
      "United States       68\n",
      "Usa                 59\n",
      "USA                 56\n",
      "usa                 28\n",
      "                  ... \n",
      "Ghana                1\n",
      "Nigeria              1\n",
      "ss                   1\n",
      "Nigeria              1\n",
      "Burma                1\n",
      "Name: count, Length: 72, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count again.\n",
    "print(df_salary_tech_usd['country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "#normalize\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].str.lower().str.strip()\n",
    "values_to_replace = ['united states', 'united states of america', 'usa', 'u.s.', 'u.s.a.', 'us', 'america', 'u.s.a', 'u.s', 'united state of america', 'unitedstates']\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].replace(values_to_replace, 'US')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "US                      3715\n",
      "canada                     5\n",
      "israel                     5\n",
      "australia                  2\n",
      "france                     2\n",
      "poland                     2\n",
      "brazil                     2\n",
      "singapore                  2\n",
      "spain                      2\n",
      "india                      2\n",
      "unite states               2\n",
      "new zealand                2\n",
      "denmark                    2\n",
      "nigeria                    2\n",
      "united kingdom             2\n",
      "united state               1\n",
      "puerto rico                1\n",
      "uniyed states              1\n",
      "cuba                       1\n",
      "international              1\n",
      "italy                      1\n",
      "danmark                    1\n",
      "uruguay                    1\n",
      "isa                        1\n",
      "united stateds             1\n",
      "united stated              1\n",
      "remote (philippines)       1\n",
      "pakistan                   1\n",
      "mexico                     1\n",
      "san francisco              1\n",
      "netherlands                1\n",
      "romania                    1\n",
      "japan                      1\n",
      "united stares              1\n",
      "china                      1\n",
      "australian                 1\n",
      "jamaica                    1\n",
      "thailand                   1\n",
      "unites states              1\n",
      "colombia                   1\n",
      "ghana                      1\n",
      "ss                         1\n",
      "burma                      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BONUS CREDIT: if you‚Äôve resolved it, let‚Äôs see how well you did by counting the number of instances of each unique value.\n",
    "print(df_salary_tech_usd['country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It‚Äôs looking good so far. Let‚Äôs find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1943\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1943\u001b[39m     res_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2460\u001b[39m, in \u001b[36mGroupBy.mean.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2458\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._cython_agg_general(\n\u001b[32m   2459\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2460\u001b[39m         alt=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2461\u001b[39m         numeric_only=numeric_only,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:6560\u001b[39m, in \u001b[36mSeries.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6552\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m   6554\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6558\u001b[39m     **kwargs,\n\u001b[32m   6559\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:12439\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12433\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12434\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12437\u001b[39m     **kwargs,\n\u001b[32m  12438\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12440\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12441\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:12396\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12394\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:6468\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6464\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6465\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6466\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6467\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:1701\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1700\u001b[39m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1701\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert string \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1702\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert string '75,00070,00072,00052,00029,120105,000120,00052000550009500035000035000' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the minimum, mean, and maximum salary in USD by U.S. state.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m salary_by_state = \u001b[43mdf_salary_tech_usd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msalary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:257\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = engine\n\u001b[32m    256\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:362\u001b[39m, in \u001b[36mSeriesGroupBy._aggregate_multiple_funcs\u001b[39m\u001b[34m(self, arg, *args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[32m    361\u001b[39m         key = base.OutputKey(label=name, position=idx)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         results[key] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results.values()):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:249\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    248\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc.Iterable):\n\u001b[32m    252\u001b[39m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[32m    254\u001b[39m     func = maybe_mangle_lambdas(func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2458\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2452\u001b[39m         grouped_mean,\n\u001b[32m   2453\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2454\u001b[39m         engine_kwargs,\n\u001b[32m   2455\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2456\u001b[39m     )\n\u001b[32m   2457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2458\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2459\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2460\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2004\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   2001\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   2002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m2004\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2005\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   2006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33midxmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33midxmax\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/base.py:367\u001b[39m, in \u001b[36mSingleDataManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[32m    366\u001b[39m     arr = \u001b[38;5;28mself\u001b[39m.array\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     index = default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[32m    370\u001b[39m     mgr = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_array(res, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2001\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1998\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2001\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2002\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1947\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1945\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1949\u001b[39m dtype = ser.dtype\n\u001b[32m   1950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "salary_by_state = df_salary_tech_usd.groupby('state')['salary'].agg(['min', 'mean', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn‚Äôt numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Fix it.\n",
    "df_salary_tech_usd['salary'] = pd.to_numeric(df_salary_tech_usd['salary'], errors='coerce')\n",
    "df_salary_tech_usd = df_salary_tech_usd.dropna(subset=['salary'])\n",
    "print(df_salary_tech_usd['salary'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     min           mean        max\n",
      "state                                                             \n",
      "Alabama                          35000.0  117400.000000   350000.0\n",
      "Arizona                          35000.0   97833.333333   145000.0\n",
      "Arkansas                             4.0   58001.000000    95000.0\n",
      "California                           0.0  153286.988827   520000.0\n",
      "California, Colorado            176000.0  176000.000000   176000.0\n",
      "California, Maryland             81500.0   81500.000000    81500.0\n",
      "California, Oregon              200000.0  200000.000000   200000.0\n",
      "Colorado                         49400.0  109291.891892   165000.0\n",
      "Connecticut                      68000.0  161610.000000   270000.0\n",
      "Delaware                        169000.0  169000.000000   169000.0\n",
      "District of Columbia             59000.0  142923.076923   200000.0\n",
      "District of Columbia, Virginia  109200.0  109200.000000   109200.0\n",
      "Florida                          28800.0  210711.000000  2600000.0\n",
      "Georgia                          29120.0  115297.647059   242000.0\n",
      "Idaho                            74860.0  105465.000000   170000.0\n",
      "Illinois                         36000.0  117555.571429   228800.0\n",
      "Indiana                          15000.0   82875.000000   140000.0\n",
      "Iowa                             63000.0  101200.000000   142000.0\n",
      "Kansas                           41500.0  109666.666667   167000.0\n",
      "Kentucky                         62000.0  102500.000000   125000.0\n",
      "Louisiana                        75000.0   80500.000000    84000.0\n",
      "Louisiana, Washington           117000.0  117000.000000   117000.0\n",
      "Maine                            50000.0  103833.333333   173000.0\n",
      "Maryland                         62000.0  119955.461538   176000.0\n",
      "Massachusetts                    41000.0  125899.155844   400000.0\n",
      "Michigan                         41600.0   95758.823529   235000.0\n",
      "Michigan, Texas, Washington     340000.0  340000.000000   340000.0\n",
      "Minnesota                        52124.0  101064.941176   210000.0\n",
      "Missouri                            80.0   80339.923077   200000.0\n",
      "Montana                          65000.0  112666.666667   145000.0\n",
      "Nebraska                         43000.0   76736.000000   140000.0\n",
      "Nevada                          107100.0  124550.000000   142000.0\n",
      "New Hampshire                       55.0   87175.833333   130000.0\n",
      "New Jersey                       67500.0  124090.909091   192000.0\n",
      "New Jersey, New York            135000.0  137500.000000   140000.0\n",
      "New Mexico                       82000.0   95733.333333   115200.0\n",
      "New York                         14000.0  146594.112150   590000.0\n",
      "North Carolina                   29000.0   97841.666667   165000.0\n",
      "Ohio                             42000.0  137066.666667   954000.0\n",
      "Oklahoma                         36958.0   84802.571429   180000.0\n",
      "Oregon                           16200.0  122640.000000   230000.0\n",
      "Pennsylvania                     52000.0  116826.388889   237000.0\n",
      "Rhode Island                     76000.0   99475.000000   122950.0\n",
      "South Carolina                   40000.0   40000.000000    40000.0\n",
      "Tennessee                        61500.0   91750.000000   144000.0\n",
      "Texas                            10700.0  103685.245902   190000.0\n",
      "Utah                             33280.0  105023.333333   176000.0\n",
      "Vermont                          91250.0  105625.000000   120000.0\n",
      "Virginia                         58750.0  115086.696970   378000.0\n",
      "Washington                          72.0  136923.916667   300000.0\n",
      "West Virginia                   120000.0  120000.000000   120000.0\n",
      "Wisconsin                            1.0  145806.888889   920000.0\n"
     ]
    }
   ],
   "source": [
    "salary_by_state = df_salary_tech_usd.groupby('state')['salary'].agg(['min', 'mean', 'max'])\n",
    "print(salary_by_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let‚Äôs narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     min           mean       max\n",
      "state                                                            \n",
      "Alabama                          52000.0  138000.000000  350000.0\n",
      "Arizona                          35000.0   97833.333333  145000.0\n",
      "Arkansas                         60000.0   77333.333333   95000.0\n",
      "California                           0.0  153754.893258  520000.0\n",
      "California, Colorado            176000.0  176000.000000  176000.0\n",
      "California, Maryland             81500.0   81500.000000   81500.0\n",
      "California, Oregon              200000.0  200000.000000  200000.0\n",
      "Colorado                         49400.0  109291.891892  165000.0\n",
      "Connecticut                      68000.0  161610.000000  270000.0\n",
      "Delaware                        169000.0  169000.000000  169000.0\n",
      "District of Columbia             59000.0  142923.076923  200000.0\n",
      "District of Columbia, Virginia  109200.0  109200.000000  109200.0\n",
      "Florida                          28800.0  102106.954545  170000.0\n",
      "Georgia                          29120.0  115488.484848  242000.0\n",
      "Idaho                            74860.0  105465.000000  170000.0\n",
      "Illinois                         36000.0  119248.382353  228800.0\n",
      "Indiana                          15000.0   82875.000000  140000.0\n",
      "Iowa                             63000.0  101200.000000  142000.0\n",
      "Kansas                           41500.0  109666.666667  167000.0\n",
      "Kentucky                         62000.0  102500.000000  125000.0\n",
      "Louisiana                        75000.0   80500.000000   84000.0\n",
      "Louisiana, Washington           117000.0  117000.000000  117000.0\n",
      "Maine                            50000.0  103833.333333  173000.0\n",
      "Maryland                         62000.0  119955.461538  176000.0\n",
      "Massachusetts                    41000.0  125660.986842  400000.0\n",
      "Michigan                         41600.0   95758.823529  235000.0\n",
      "Michigan, Texas, Washington     340000.0  340000.000000  340000.0\n",
      "Minnesota                        52124.0  102381.500000  210000.0\n",
      "Missouri                            80.0   80339.923077  200000.0\n",
      "Montana                          65000.0  112666.666667  145000.0\n",
      "Nebraska                         43000.0   76736.000000  140000.0\n",
      "Nevada                          107100.0  124550.000000  142000.0\n",
      "New Hampshire                       55.0   87175.833333  130000.0\n",
      "New Jersey                       67500.0  124090.909091  192000.0\n",
      "New Jersey, New York            135000.0  137500.000000  140000.0\n",
      "New Mexico                       82000.0   95733.333333  115200.0\n",
      "New York                         14000.0  146594.112150  590000.0\n",
      "North Carolina                   29000.0   97250.000000  165000.0\n",
      "Ohio                             42000.0  137066.666667  954000.0\n",
      "Oklahoma                         36958.0   84802.571429  180000.0\n",
      "Oregon                           16200.0  122640.000000  230000.0\n",
      "Pennsylvania                     52000.0  116826.388889  237000.0\n",
      "Rhode Island                     76000.0   99475.000000  122950.0\n",
      "Tennessee                        61500.0   91750.000000  144000.0\n",
      "Texas                            10700.0  103685.245902  190000.0\n",
      "Utah                             33280.0  105023.333333  176000.0\n",
      "Vermont                          91250.0  105625.000000  120000.0\n",
      "Virginia                         58750.0  115086.696970  378000.0\n",
      "Washington                          72.0  137427.774648  300000.0\n",
      "West Virginia                   120000.0  120000.000000  120000.0\n",
      "Wisconsin                            1.0  145806.888889  920000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2983/301426315.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary_tech_usd['timestamp'] = pd.to_datetime(df_salary_tech_usd['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "df_salary_tech_usd['timestamp'] = pd.to_datetime(df_salary_tech_usd['timestamp'])\n",
    "df_salary_filtered = df_salary_tech_usd[df_salary_tech_usd['timestamp'].dt.year.isin([2021, 2022, 2023])].copy()\n",
    "salary_by_state_filtered = df_salary_filtered.groupby('state')['salary'].agg(['min', 'mean', 'max'])\n",
    "print(salary_by_state_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you‚Äôve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let‚Äôs back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         min           mean         max\n",
      "state                                                  \n",
      "Alabama                 54.0   70454.170732    350000.0\n",
      "Alabama, California  29120.0   29120.000000     29120.0\n",
      "Alabama, Oregon      50000.0   50000.000000     50000.0\n",
      "Alaska               47840.0  737319.200000  10000000.0\n",
      "Arizona              26500.0   86190.060241    380000.0\n",
      "...                      ...            ...         ...\n",
      "Virginia                57.0   96315.936073   1300000.0\n",
      "Washington              72.0   98283.044983    300000.0\n",
      "West Virginia            0.0   52754.375000    120000.0\n",
      "Wisconsin                1.0   83000.628788    920000.0\n",
      "Wyoming              42500.0   59906.333333     98000.0\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_salary['salary'] = pd.to_numeric(df_salary['salary'], errors='coerce')\n",
    "df_salary = df_salary.dropna(subset=['salary'])\n",
    "\n",
    "df_salary['country'] = df_salary['country'].str.lower().str.strip()\n",
    "values_to_replace = ['united states', 'united states of america', 'usa', 'u.s.', 'u.s.a.', 'us', 'america', 'u.s.a', 'u.s', 'united state of america', 'unitedstates']\n",
    "df_salary['country'] = df_salary['country'].replace(values_to_replace, 'US')\n",
    "df_salary_us = df_salary[df_salary['country'] == 'US'].copy()\n",
    "\n",
    "salary_by_state = df_salary_us.groupby('state')['salary'].agg(['min', 'mean', 'max'])\n",
    "print(salary_by_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_789cb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_789cb_level0_col0\" class=\"col_heading level0 col0\" >min</th>\n",
       "      <th id=\"T_789cb_level0_col1\" class=\"col_heading level0 col1\" >mean</th>\n",
       "      <th id=\"T_789cb_level0_col2\" class=\"col_heading level0 col2\" >max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >state</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row0\" class=\"row_heading level0 row0\" >Alabama</th>\n",
       "      <td id=\"T_789cb_row0_col0\" class=\"data row0 col0\" >$54.00</td>\n",
       "      <td id=\"T_789cb_row0_col1\" class=\"data row0 col1\" >$70,454.17</td>\n",
       "      <td id=\"T_789cb_row0_col2\" class=\"data row0 col2\" >$350,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row1\" class=\"row_heading level0 row1\" >Alabama, California</th>\n",
       "      <td id=\"T_789cb_row1_col0\" class=\"data row1 col0\" >$29,120.00</td>\n",
       "      <td id=\"T_789cb_row1_col1\" class=\"data row1 col1\" >$29,120.00</td>\n",
       "      <td id=\"T_789cb_row1_col2\" class=\"data row1 col2\" >$29,120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row2\" class=\"row_heading level0 row2\" >Alabama, Oregon</th>\n",
       "      <td id=\"T_789cb_row2_col0\" class=\"data row2 col0\" >$50,000.00</td>\n",
       "      <td id=\"T_789cb_row2_col1\" class=\"data row2 col1\" >$50,000.00</td>\n",
       "      <td id=\"T_789cb_row2_col2\" class=\"data row2 col2\" >$50,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row3\" class=\"row_heading level0 row3\" >Alaska</th>\n",
       "      <td id=\"T_789cb_row3_col0\" class=\"data row3 col0\" >$47,840.00</td>\n",
       "      <td id=\"T_789cb_row3_col1\" class=\"data row3 col1\" >$737,319.20</td>\n",
       "      <td id=\"T_789cb_row3_col2\" class=\"data row3 col2\" >$10,000,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row4\" class=\"row_heading level0 row4\" >Arizona</th>\n",
       "      <td id=\"T_789cb_row4_col0\" class=\"data row4 col0\" >$26,500.00</td>\n",
       "      <td id=\"T_789cb_row4_col1\" class=\"data row4 col1\" >$86,190.06</td>\n",
       "      <td id=\"T_789cb_row4_col2\" class=\"data row4 col2\" >$380,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row5\" class=\"row_heading level0 row5\" >Arizona, California</th>\n",
       "      <td id=\"T_789cb_row5_col0\" class=\"data row5 col0\" >$90,000.00</td>\n",
       "      <td id=\"T_789cb_row5_col1\" class=\"data row5 col1\" >$90,000.00</td>\n",
       "      <td id=\"T_789cb_row5_col2\" class=\"data row5 col2\" >$90,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row6\" class=\"row_heading level0 row6\" >Arizona, New York</th>\n",
       "      <td id=\"T_789cb_row6_col0\" class=\"data row6 col0\" >$72,000.00</td>\n",
       "      <td id=\"T_789cb_row6_col1\" class=\"data row6 col1\" >$72,000.00</td>\n",
       "      <td id=\"T_789cb_row6_col2\" class=\"data row6 col2\" >$72,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row7\" class=\"row_heading level0 row7\" >Arkansas</th>\n",
       "      <td id=\"T_789cb_row7_col0\" class=\"data row7 col0\" >$28,080.00</td>\n",
       "      <td id=\"T_789cb_row7_col1\" class=\"data row7 col1\" >$65,005.67</td>\n",
       "      <td id=\"T_789cb_row7_col2\" class=\"data row7 col2\" >$145,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row8\" class=\"row_heading level0 row8\" >California</th>\n",
       "      <td id=\"T_789cb_row8_col0\" class=\"data row8 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row8_col1\" class=\"data row8 col1\" >$113,595.41</td>\n",
       "      <td id=\"T_789cb_row8_col2\" class=\"data row8 col2\" >$520,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row9\" class=\"row_heading level0 row9\" >California, Colorado</th>\n",
       "      <td id=\"T_789cb_row9_col0\" class=\"data row9 col0\" >$176,000.00</td>\n",
       "      <td id=\"T_789cb_row9_col1\" class=\"data row9 col1\" >$176,000.00</td>\n",
       "      <td id=\"T_789cb_row9_col2\" class=\"data row9 col2\" >$176,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row10\" class=\"row_heading level0 row10\" >California, District of Columbia, Illinois, Iowa, Maryland, Minnesota</th>\n",
       "      <td id=\"T_789cb_row10_col0\" class=\"data row10 col0\" >$130,000.00</td>\n",
       "      <td id=\"T_789cb_row10_col1\" class=\"data row10 col1\" >$130,000.00</td>\n",
       "      <td id=\"T_789cb_row10_col2\" class=\"data row10 col2\" >$130,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row11\" class=\"row_heading level0 row11\" >California, Illinois, Massachusetts, North Carolina, South Carolina, Virginia</th>\n",
       "      <td id=\"T_789cb_row11_col0\" class=\"data row11 col0\" >$85,000.00</td>\n",
       "      <td id=\"T_789cb_row11_col1\" class=\"data row11 col1\" >$85,000.00</td>\n",
       "      <td id=\"T_789cb_row11_col2\" class=\"data row11 col2\" >$85,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row12\" class=\"row_heading level0 row12\" >California, Maryland</th>\n",
       "      <td id=\"T_789cb_row12_col0\" class=\"data row12 col0\" >$81,500.00</td>\n",
       "      <td id=\"T_789cb_row12_col1\" class=\"data row12 col1\" >$81,500.00</td>\n",
       "      <td id=\"T_789cb_row12_col2\" class=\"data row12 col2\" >$81,500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row13\" class=\"row_heading level0 row13\" >California, New York</th>\n",
       "      <td id=\"T_789cb_row13_col0\" class=\"data row13 col0\" >$48,000.00</td>\n",
       "      <td id=\"T_789cb_row13_col1\" class=\"data row13 col1\" >$48,000.00</td>\n",
       "      <td id=\"T_789cb_row13_col2\" class=\"data row13 col2\" >$48,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row14\" class=\"row_heading level0 row14\" >California, Oregon</th>\n",
       "      <td id=\"T_789cb_row14_col0\" class=\"data row14 col0\" >$200,000.00</td>\n",
       "      <td id=\"T_789cb_row14_col1\" class=\"data row14 col1\" >$200,000.00</td>\n",
       "      <td id=\"T_789cb_row14_col2\" class=\"data row14 col2\" >$200,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row15\" class=\"row_heading level0 row15\" >Colorado</th>\n",
       "      <td id=\"T_789cb_row15_col0\" class=\"data row15 col0\" >$65.00</td>\n",
       "      <td id=\"T_789cb_row15_col1\" class=\"data row15 col1\" >$87,244.09</td>\n",
       "      <td id=\"T_789cb_row15_col2\" class=\"data row15 col2\" >$200,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row16\" class=\"row_heading level0 row16\" >Connecticut</th>\n",
       "      <td id=\"T_789cb_row16_col0\" class=\"data row16 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row16_col1\" class=\"data row16 col1\" >$88,467.54</td>\n",
       "      <td id=\"T_789cb_row16_col2\" class=\"data row16 col2\" >$270,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row17\" class=\"row_heading level0 row17\" >Delaware</th>\n",
       "      <td id=\"T_789cb_row17_col0\" class=\"data row17 col0\" >$35,000.00</td>\n",
       "      <td id=\"T_789cb_row17_col1\" class=\"data row17 col1\" >$103,455.56</td>\n",
       "      <td id=\"T_789cb_row17_col2\" class=\"data row17 col2\" >$220,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row18\" class=\"row_heading level0 row18\" >Delaware, Pennsylvania</th>\n",
       "      <td id=\"T_789cb_row18_col0\" class=\"data row18 col0\" >$35,000.00</td>\n",
       "      <td id=\"T_789cb_row18_col1\" class=\"data row18 col1\" >$35,000.00</td>\n",
       "      <td id=\"T_789cb_row18_col2\" class=\"data row18 col2\" >$35,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row19\" class=\"row_heading level0 row19\" >District of Columbia</th>\n",
       "      <td id=\"T_789cb_row19_col0\" class=\"data row19 col0\" >$40.00</td>\n",
       "      <td id=\"T_789cb_row19_col1\" class=\"data row19 col1\" >$110,014.61</td>\n",
       "      <td id=\"T_789cb_row19_col2\" class=\"data row19 col2\" >$1,250,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row20\" class=\"row_heading level0 row20\" >District of Columbia, Virginia</th>\n",
       "      <td id=\"T_789cb_row20_col0\" class=\"data row20 col0\" >$80,900.00</td>\n",
       "      <td id=\"T_789cb_row20_col1\" class=\"data row20 col1\" >$101,700.00</td>\n",
       "      <td id=\"T_789cb_row20_col2\" class=\"data row20 col2\" >$115,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row21\" class=\"row_heading level0 row21\" >District of Columbia, Washington</th>\n",
       "      <td id=\"T_789cb_row21_col0\" class=\"data row21 col0\" >$35,000.00</td>\n",
       "      <td id=\"T_789cb_row21_col1\" class=\"data row21 col1\" >$35,000.00</td>\n",
       "      <td id=\"T_789cb_row21_col2\" class=\"data row21 col2\" >$35,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row22\" class=\"row_heading level0 row22\" >Florida</th>\n",
       "      <td id=\"T_789cb_row22_col0\" class=\"data row22 col0\" >$150.00</td>\n",
       "      <td id=\"T_789cb_row22_col1\" class=\"data row22 col1\" >$92,868.04</td>\n",
       "      <td id=\"T_789cb_row22_col2\" class=\"data row22 col2\" >$2,600,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row23\" class=\"row_heading level0 row23\" >Florida, New Hampshire, Wisconsin</th>\n",
       "      <td id=\"T_789cb_row23_col0\" class=\"data row23 col0\" >$70,000.00</td>\n",
       "      <td id=\"T_789cb_row23_col1\" class=\"data row23 col1\" >$70,000.00</td>\n",
       "      <td id=\"T_789cb_row23_col2\" class=\"data row23 col2\" >$70,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row24\" class=\"row_heading level0 row24\" >Georgia</th>\n",
       "      <td id=\"T_789cb_row24_col0\" class=\"data row24 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row24_col1\" class=\"data row24 col1\" >$86,112.10</td>\n",
       "      <td id=\"T_789cb_row24_col2\" class=\"data row24 col2\" >$860,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row25\" class=\"row_heading level0 row25\" >Hawaii</th>\n",
       "      <td id=\"T_789cb_row25_col0\" class=\"data row25 col0\" >$32,460.00</td>\n",
       "      <td id=\"T_789cb_row25_col1\" class=\"data row25 col1\" >$65,270.00</td>\n",
       "      <td id=\"T_789cb_row25_col2\" class=\"data row25 col2\" >$142,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row26\" class=\"row_heading level0 row26\" >Idaho</th>\n",
       "      <td id=\"T_789cb_row26_col0\" class=\"data row26 col0\" >$38.00</td>\n",
       "      <td id=\"T_789cb_row26_col1\" class=\"data row26 col1\" >$73,159.97</td>\n",
       "      <td id=\"T_789cb_row26_col2\" class=\"data row26 col2\" >$300,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row27\" class=\"row_heading level0 row27\" >Illinois</th>\n",
       "      <td id=\"T_789cb_row27_col0\" class=\"data row27 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row27_col1\" class=\"data row27 col1\" >$87,751.61</td>\n",
       "      <td id=\"T_789cb_row27_col2\" class=\"data row27 col2\" >$340,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row28\" class=\"row_heading level0 row28\" >Illinois, North Carolina</th>\n",
       "      <td id=\"T_789cb_row28_col0\" class=\"data row28 col0\" >$52,000.00</td>\n",
       "      <td id=\"T_789cb_row28_col1\" class=\"data row28 col1\" >$52,000.00</td>\n",
       "      <td id=\"T_789cb_row28_col2\" class=\"data row28 col2\" >$52,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row29\" class=\"row_heading level0 row29\" >Indiana</th>\n",
       "      <td id=\"T_789cb_row29_col0\" class=\"data row29 col0\" >$105.00</td>\n",
       "      <td id=\"T_789cb_row29_col1\" class=\"data row29 col1\" >$80,689.09</td>\n",
       "      <td id=\"T_789cb_row29_col2\" class=\"data row29 col2\" >$925,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row30\" class=\"row_heading level0 row30\" >Indiana, Massachusetts</th>\n",
       "      <td id=\"T_789cb_row30_col0\" class=\"data row30 col0\" >$132,000.00</td>\n",
       "      <td id=\"T_789cb_row30_col1\" class=\"data row30 col1\" >$132,000.00</td>\n",
       "      <td id=\"T_789cb_row30_col2\" class=\"data row30 col2\" >$132,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row31\" class=\"row_heading level0 row31\" >Iowa</th>\n",
       "      <td id=\"T_789cb_row31_col0\" class=\"data row31 col0\" >$13,000.00</td>\n",
       "      <td id=\"T_789cb_row31_col1\" class=\"data row31 col1\" >$68,420.60</td>\n",
       "      <td id=\"T_789cb_row31_col2\" class=\"data row31 col2\" >$142,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row32\" class=\"row_heading level0 row32\" >Iowa, Nebraska</th>\n",
       "      <td id=\"T_789cb_row32_col0\" class=\"data row32 col0\" >$48,000.00</td>\n",
       "      <td id=\"T_789cb_row32_col1\" class=\"data row32 col1\" >$48,000.00</td>\n",
       "      <td id=\"T_789cb_row32_col2\" class=\"data row32 col2\" >$48,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row33\" class=\"row_heading level0 row33\" >Kansas</th>\n",
       "      <td id=\"T_789cb_row33_col0\" class=\"data row33 col0\" >$52.00</td>\n",
       "      <td id=\"T_789cb_row33_col1\" class=\"data row33 col1\" >$69,062.87</td>\n",
       "      <td id=\"T_789cb_row33_col2\" class=\"data row33 col2\" >$167,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row34\" class=\"row_heading level0 row34\" >Kansas, Missouri</th>\n",
       "      <td id=\"T_789cb_row34_col0\" class=\"data row34 col0\" >$64,000.00</td>\n",
       "      <td id=\"T_789cb_row34_col1\" class=\"data row34 col1\" >$64,000.00</td>\n",
       "      <td id=\"T_789cb_row34_col2\" class=\"data row34 col2\" >$64,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row35\" class=\"row_heading level0 row35\" >Kentucky</th>\n",
       "      <td id=\"T_789cb_row35_col0\" class=\"data row35 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row35_col1\" class=\"data row35 col1\" >$66,174.88</td>\n",
       "      <td id=\"T_789cb_row35_col2\" class=\"data row35 col2\" >$175,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row36\" class=\"row_heading level0 row36\" >Louisiana</th>\n",
       "      <td id=\"T_789cb_row36_col0\" class=\"data row36 col0\" >$20,000.00</td>\n",
       "      <td id=\"T_789cb_row36_col1\" class=\"data row36 col1\" >$75,958.37</td>\n",
       "      <td id=\"T_789cb_row36_col2\" class=\"data row36 col2\" >$200,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row37\" class=\"row_heading level0 row37\" >Louisiana, Washington</th>\n",
       "      <td id=\"T_789cb_row37_col0\" class=\"data row37 col0\" >$117,000.00</td>\n",
       "      <td id=\"T_789cb_row37_col1\" class=\"data row37 col1\" >$117,000.00</td>\n",
       "      <td id=\"T_789cb_row37_col2\" class=\"data row37 col2\" >$117,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row38\" class=\"row_heading level0 row38\" >Maine</th>\n",
       "      <td id=\"T_789cb_row38_col0\" class=\"data row38 col0\" >$26,000.00</td>\n",
       "      <td id=\"T_789cb_row38_col1\" class=\"data row38 col1\" >$65,832.91</td>\n",
       "      <td id=\"T_789cb_row38_col2\" class=\"data row38 col2\" >$173,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row39\" class=\"row_heading level0 row39\" >Maryland</th>\n",
       "      <td id=\"T_789cb_row39_col0\" class=\"data row39 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row39_col1\" class=\"data row39 col1\" >$89,330.62</td>\n",
       "      <td id=\"T_789cb_row39_col2\" class=\"data row39 col2\" >$353,200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row40\" class=\"row_heading level0 row40\" >Maryland, New York</th>\n",
       "      <td id=\"T_789cb_row40_col0\" class=\"data row40 col0\" >$14,000.00</td>\n",
       "      <td id=\"T_789cb_row40_col1\" class=\"data row40 col1\" >$14,000.00</td>\n",
       "      <td id=\"T_789cb_row40_col2\" class=\"data row40 col2\" >$14,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row41\" class=\"row_heading level0 row41\" >Maryland, Virginia</th>\n",
       "      <td id=\"T_789cb_row41_col0\" class=\"data row41 col0\" >$78,000.00</td>\n",
       "      <td id=\"T_789cb_row41_col1\" class=\"data row41 col1\" >$78,000.00</td>\n",
       "      <td id=\"T_789cb_row41_col2\" class=\"data row41 col2\" >$78,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row42\" class=\"row_heading level0 row42\" >Massachusetts</th>\n",
       "      <td id=\"T_789cb_row42_col0\" class=\"data row42 col0\" >$155.00</td>\n",
       "      <td id=\"T_789cb_row42_col1\" class=\"data row42 col1\" >$99,883.13</td>\n",
       "      <td id=\"T_789cb_row42_col2\" class=\"data row42 col2\" >$400,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row43\" class=\"row_heading level0 row43\" >Massachusetts, New Hampshire</th>\n",
       "      <td id=\"T_789cb_row43_col0\" class=\"data row43 col0\" >$60,000.00</td>\n",
       "      <td id=\"T_789cb_row43_col1\" class=\"data row43 col1\" >$60,000.00</td>\n",
       "      <td id=\"T_789cb_row43_col2\" class=\"data row43 col2\" >$60,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row44\" class=\"row_heading level0 row44\" >Michigan</th>\n",
       "      <td id=\"T_789cb_row44_col0\" class=\"data row44 col0\" >$55.00</td>\n",
       "      <td id=\"T_789cb_row44_col1\" class=\"data row44 col1\" >$77,974.41</td>\n",
       "      <td id=\"T_789cb_row44_col2\" class=\"data row44 col2\" >$240,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row45\" class=\"row_heading level0 row45\" >Michigan, Texas, Washington</th>\n",
       "      <td id=\"T_789cb_row45_col0\" class=\"data row45 col0\" >$340,000.00</td>\n",
       "      <td id=\"T_789cb_row45_col1\" class=\"data row45 col1\" >$340,000.00</td>\n",
       "      <td id=\"T_789cb_row45_col2\" class=\"data row45 col2\" >$340,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row46\" class=\"row_heading level0 row46\" >Minnesota</th>\n",
       "      <td id=\"T_789cb_row46_col0\" class=\"data row46 col0\" >$40.00</td>\n",
       "      <td id=\"T_789cb_row46_col1\" class=\"data row46 col1\" >$83,530.27</td>\n",
       "      <td id=\"T_789cb_row46_col2\" class=\"data row46 col2\" >$215,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row47\" class=\"row_heading level0 row47\" >Mississippi</th>\n",
       "      <td id=\"T_789cb_row47_col0\" class=\"data row47 col0\" >$30,000.00</td>\n",
       "      <td id=\"T_789cb_row47_col1\" class=\"data row47 col1\" >$59,661.54</td>\n",
       "      <td id=\"T_789cb_row47_col2\" class=\"data row47 col2\" >$125,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row48\" class=\"row_heading level0 row48\" >Mississippi, Missouri</th>\n",
       "      <td id=\"T_789cb_row48_col0\" class=\"data row48 col0\" >$110,000.00</td>\n",
       "      <td id=\"T_789cb_row48_col1\" class=\"data row48 col1\" >$110,000.00</td>\n",
       "      <td id=\"T_789cb_row48_col2\" class=\"data row48 col2\" >$110,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row49\" class=\"row_heading level0 row49\" >Missouri</th>\n",
       "      <td id=\"T_789cb_row49_col0\" class=\"data row49 col0\" >$70.00</td>\n",
       "      <td id=\"T_789cb_row49_col1\" class=\"data row49 col1\" >$67,863.57</td>\n",
       "      <td id=\"T_789cb_row49_col2\" class=\"data row49 col2\" >$200,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row50\" class=\"row_heading level0 row50\" >Montana</th>\n",
       "      <td id=\"T_789cb_row50_col0\" class=\"data row50 col0\" >$19,200.00</td>\n",
       "      <td id=\"T_789cb_row50_col1\" class=\"data row50 col1\" >$71,369.27</td>\n",
       "      <td id=\"T_789cb_row50_col2\" class=\"data row50 col2\" >$145,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row51\" class=\"row_heading level0 row51\" >Nebraska</th>\n",
       "      <td id=\"T_789cb_row51_col0\" class=\"data row51 col0\" >$18,000.00</td>\n",
       "      <td id=\"T_789cb_row51_col1\" class=\"data row51 col1\" >$80,069.48</td>\n",
       "      <td id=\"T_789cb_row51_col2\" class=\"data row51 col2\" >$224,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row52\" class=\"row_heading level0 row52\" >Nevada</th>\n",
       "      <td id=\"T_789cb_row52_col0\" class=\"data row52 col0\" >$55.00</td>\n",
       "      <td id=\"T_789cb_row52_col1\" class=\"data row52 col1\" >$82,215.48</td>\n",
       "      <td id=\"T_789cb_row52_col2\" class=\"data row52 col2\" >$165,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row53\" class=\"row_heading level0 row53\" >New Hampshire</th>\n",
       "      <td id=\"T_789cb_row53_col0\" class=\"data row53 col0\" >$55.00</td>\n",
       "      <td id=\"T_789cb_row53_col1\" class=\"data row53 col1\" >$68,619.19</td>\n",
       "      <td id=\"T_789cb_row53_col2\" class=\"data row53 col2\" >$208,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row54\" class=\"row_heading level0 row54\" >New Jersey</th>\n",
       "      <td id=\"T_789cb_row54_col0\" class=\"data row54 col0\" >$14,850.00</td>\n",
       "      <td id=\"T_789cb_row54_col1\" class=\"data row54 col1\" >$130,590.36</td>\n",
       "      <td id=\"T_789cb_row54_col2\" class=\"data row54 col2\" >$5,000,044.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row55\" class=\"row_heading level0 row55\" >New Jersey, New York</th>\n",
       "      <td id=\"T_789cb_row55_col0\" class=\"data row55 col0\" >$135,000.00</td>\n",
       "      <td id=\"T_789cb_row55_col1\" class=\"data row55 col1\" >$138,666.67</td>\n",
       "      <td id=\"T_789cb_row55_col2\" class=\"data row55 col2\" >$141,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row56\" class=\"row_heading level0 row56\" >New Jersey, Pennsylvania</th>\n",
       "      <td id=\"T_789cb_row56_col0\" class=\"data row56 col0\" >$40,200.00</td>\n",
       "      <td id=\"T_789cb_row56_col1\" class=\"data row56 col1\" >$91,600.00</td>\n",
       "      <td id=\"T_789cb_row56_col2\" class=\"data row56 col2\" >$143,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row57\" class=\"row_heading level0 row57\" >New Mexico</th>\n",
       "      <td id=\"T_789cb_row57_col0\" class=\"data row57 col0\" >$78.00</td>\n",
       "      <td id=\"T_789cb_row57_col1\" class=\"data row57 col1\" >$74,496.76</td>\n",
       "      <td id=\"T_789cb_row57_col2\" class=\"data row57 col2\" >$177,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row58\" class=\"row_heading level0 row58\" >New York</th>\n",
       "      <td id=\"T_789cb_row58_col0\" class=\"data row58 col0\" >$80.00</td>\n",
       "      <td id=\"T_789cb_row58_col1\" class=\"data row58 col1\" >$106,151.05</td>\n",
       "      <td id=\"T_789cb_row58_col2\" class=\"data row58 col2\" >$590,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row59\" class=\"row_heading level0 row59\" >New York, Oregon, Vermont</th>\n",
       "      <td id=\"T_789cb_row59_col0\" class=\"data row59 col0\" >$53,000.00</td>\n",
       "      <td id=\"T_789cb_row59_col1\" class=\"data row59 col1\" >$53,000.00</td>\n",
       "      <td id=\"T_789cb_row59_col2\" class=\"data row59 col2\" >$53,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row60\" class=\"row_heading level0 row60\" >New York, Virginia</th>\n",
       "      <td id=\"T_789cb_row60_col0\" class=\"data row60 col0\" >$65,000.00</td>\n",
       "      <td id=\"T_789cb_row60_col1\" class=\"data row60 col1\" >$65,000.00</td>\n",
       "      <td id=\"T_789cb_row60_col2\" class=\"data row60 col2\" >$65,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row61\" class=\"row_heading level0 row61\" >North Carolina</th>\n",
       "      <td id=\"T_789cb_row61_col0\" class=\"data row61 col0\" >$15,000.00</td>\n",
       "      <td id=\"T_789cb_row61_col1\" class=\"data row61 col1\" >$77,376.28</td>\n",
       "      <td id=\"T_789cb_row61_col2\" class=\"data row61 col2\" >$165,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row62\" class=\"row_heading level0 row62\" >North Dakota</th>\n",
       "      <td id=\"T_789cb_row62_col0\" class=\"data row62 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row62_col1\" class=\"data row62 col1\" >$62,217.33</td>\n",
       "      <td id=\"T_789cb_row62_col2\" class=\"data row62 col2\" >$96,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row63\" class=\"row_heading level0 row63\" >Ohio</th>\n",
       "      <td id=\"T_789cb_row63_col0\" class=\"data row63 col0\" >$36.00</td>\n",
       "      <td id=\"T_789cb_row63_col1\" class=\"data row63 col1\" >$78,497.75</td>\n",
       "      <td id=\"T_789cb_row63_col2\" class=\"data row63 col2\" >$954,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row64\" class=\"row_heading level0 row64\" >Oklahoma</th>\n",
       "      <td id=\"T_789cb_row64_col0\" class=\"data row64 col0\" >$25,000.00</td>\n",
       "      <td id=\"T_789cb_row64_col1\" class=\"data row64 col1\" >$62,752.59</td>\n",
       "      <td id=\"T_789cb_row64_col2\" class=\"data row64 col2\" >$180,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row65\" class=\"row_heading level0 row65\" >Oregon</th>\n",
       "      <td id=\"T_789cb_row65_col0\" class=\"data row65 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row65_col1\" class=\"data row65 col1\" >$90,415.27</td>\n",
       "      <td id=\"T_789cb_row65_col2\" class=\"data row65 col2\" >$230,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row66\" class=\"row_heading level0 row66\" >Oregon, Washington</th>\n",
       "      <td id=\"T_789cb_row66_col0\" class=\"data row66 col0\" >$52,900.00</td>\n",
       "      <td id=\"T_789cb_row66_col1\" class=\"data row66 col1\" >$52,900.00</td>\n",
       "      <td id=\"T_789cb_row66_col2\" class=\"data row66 col2\" >$52,900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row67\" class=\"row_heading level0 row67\" >Pennsylvania</th>\n",
       "      <td id=\"T_789cb_row67_col0\" class=\"data row67 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row67_col1\" class=\"data row67 col1\" >$80,780.87</td>\n",
       "      <td id=\"T_789cb_row67_col2\" class=\"data row67 col2\" >$252,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row68\" class=\"row_heading level0 row68\" >Pennsylvania, Rhode Island</th>\n",
       "      <td id=\"T_789cb_row68_col0\" class=\"data row68 col0\" >$62,000.00</td>\n",
       "      <td id=\"T_789cb_row68_col1\" class=\"data row68 col1\" >$62,000.00</td>\n",
       "      <td id=\"T_789cb_row68_col2\" class=\"data row68 col2\" >$62,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row69\" class=\"row_heading level0 row69\" >Rhode Island</th>\n",
       "      <td id=\"T_789cb_row69_col0\" class=\"data row69 col0\" >$27,040.00</td>\n",
       "      <td id=\"T_789cb_row69_col1\" class=\"data row69 col1\" >$73,162.63</td>\n",
       "      <td id=\"T_789cb_row69_col2\" class=\"data row69 col2\" >$150,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row70\" class=\"row_heading level0 row70\" >South Carolina</th>\n",
       "      <td id=\"T_789cb_row70_col0\" class=\"data row70 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row70_col1\" class=\"data row70 col1\" >$62,532.66</td>\n",
       "      <td id=\"T_789cb_row70_col2\" class=\"data row70 col2\" >$223,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row71\" class=\"row_heading level0 row71\" >South Dakota</th>\n",
       "      <td id=\"T_789cb_row71_col0\" class=\"data row71 col0\" >$33,000.00</td>\n",
       "      <td id=\"T_789cb_row71_col1\" class=\"data row71 col1\" >$46,625.00</td>\n",
       "      <td id=\"T_789cb_row71_col2\" class=\"data row71 col2\" >$60,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row72\" class=\"row_heading level0 row72\" >Tennessee</th>\n",
       "      <td id=\"T_789cb_row72_col0\" class=\"data row72 col0\" >$24,000.00</td>\n",
       "      <td id=\"T_789cb_row72_col1\" class=\"data row72 col1\" >$77,698.92</td>\n",
       "      <td id=\"T_789cb_row72_col2\" class=\"data row72 col2\" >$275,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row73\" class=\"row_heading level0 row73\" >Texas</th>\n",
       "      <td id=\"T_789cb_row73_col0\" class=\"data row73 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row73_col1\" class=\"data row73 col1\" >$88,968.44</td>\n",
       "      <td id=\"T_789cb_row73_col2\" class=\"data row73 col2\" >$300,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row74\" class=\"row_heading level0 row74\" >Utah</th>\n",
       "      <td id=\"T_789cb_row74_col0\" class=\"data row74 col0\" >$28,000.00</td>\n",
       "      <td id=\"T_789cb_row74_col1\" class=\"data row74 col1\" >$91,167.66</td>\n",
       "      <td id=\"T_789cb_row74_col2\" class=\"data row74 col2\" >$576,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row75\" class=\"row_heading level0 row75\" >Vermont</th>\n",
       "      <td id=\"T_789cb_row75_col0\" class=\"data row75 col0\" >$41,600.00</td>\n",
       "      <td id=\"T_789cb_row75_col1\" class=\"data row75 col1\" >$64,849.18</td>\n",
       "      <td id=\"T_789cb_row75_col2\" class=\"data row75 col2\" >$120,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row76\" class=\"row_heading level0 row76\" >Virginia</th>\n",
       "      <td id=\"T_789cb_row76_col0\" class=\"data row76 col0\" >$57.00</td>\n",
       "      <td id=\"T_789cb_row76_col1\" class=\"data row76 col1\" >$96,315.94</td>\n",
       "      <td id=\"T_789cb_row76_col2\" class=\"data row76 col2\" >$1,300,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row77\" class=\"row_heading level0 row77\" >Washington</th>\n",
       "      <td id=\"T_789cb_row77_col0\" class=\"data row77 col0\" >$72.00</td>\n",
       "      <td id=\"T_789cb_row77_col1\" class=\"data row77 col1\" >$98,283.04</td>\n",
       "      <td id=\"T_789cb_row77_col2\" class=\"data row77 col2\" >$300,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row78\" class=\"row_heading level0 row78\" >West Virginia</th>\n",
       "      <td id=\"T_789cb_row78_col0\" class=\"data row78 col0\" >$0.00</td>\n",
       "      <td id=\"T_789cb_row78_col1\" class=\"data row78 col1\" >$52,754.38</td>\n",
       "      <td id=\"T_789cb_row78_col2\" class=\"data row78 col2\" >$120,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row79\" class=\"row_heading level0 row79\" >Wisconsin</th>\n",
       "      <td id=\"T_789cb_row79_col0\" class=\"data row79 col0\" >$1.00</td>\n",
       "      <td id=\"T_789cb_row79_col1\" class=\"data row79 col1\" >$83,000.63</td>\n",
       "      <td id=\"T_789cb_row79_col2\" class=\"data row79 col2\" >$920,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_789cb_level0_row80\" class=\"row_heading level0 row80\" >Wyoming</th>\n",
       "      <td id=\"T_789cb_row80_col0\" class=\"data row80 col0\" >$42,500.00</td>\n",
       "      <td id=\"T_789cb_row80_col1\" class=\"data row80 col1\" >$59,906.33</td>\n",
       "      <td id=\"T_789cb_row80_col2\" class=\"data row80 col2\" >$98,000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x76966fe7a8d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_salary_table = salary_by_state.style.format('${:,.2f}')\n",
    "formatted_salary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "California              738\n",
      "New York                594\n",
      "Massachusetts           398\n",
      "Texas                   370\n",
      "Illinois                320\n",
      "Washington              289\n",
      "Pennsylvania            268\n",
      "Ohio                    222\n",
      "Virginia                219\n",
      "District of Columbia    218\n",
      "Minnesota               188\n",
      "Florida                 188\n",
      "Georgia                 174\n",
      "Oregon                  171\n",
      "North Carolina          171\n",
      "Maryland                159\n",
      "Colorado                158\n",
      "Michigan                157\n",
      "Wisconsin               132\n",
      "New Jersey              119\n",
      "Missouri                114\n",
      "Indiana                  94\n",
      "Arizona                  83\n",
      "Tennessee                76\n",
      "Connecticut              69\n",
      "Kentucky                 65\n",
      "Utah                     50\n",
      "Maine                    47\n",
      "Iowa                     42\n",
      "Alabama                  41\n",
      "Kansas                   38\n",
      "South Carolina           38\n",
      "Louisiana                38\n",
      "Idaho                    37\n",
      "New Hampshire            36\n",
      "Nebraska                 31\n",
      "Oklahoma                 29\n",
      "New Mexico               25\n",
      "Nevada                   25\n",
      "Arkansas                 24\n",
      "Montana                  22\n",
      "Rhode Island             19\n",
      "Vermont                  17\n",
      "Alaska                   15\n",
      "North Dakota             15\n",
      "Mississippi              13\n",
      "Delaware                  9\n",
      "West Virginia             8\n",
      "Hawaii                    8\n",
      "Wyoming                   6\n",
      "South Dakota              4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_single_states = df_salary_us[~df_salary_us['state'].str.contains(',', na=False)]\n",
    "print(df_single_states['state'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum‚Äïsay 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you‚Äïlike say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* üòú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m salary_quantiles = \u001b[43mdf_single_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msalary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m sorted_quantiles = salary_quantiles.sort_values(by=\u001b[32m0.5\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(sorted_quantiles)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:257\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = engine\n\u001b[32m    256\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:362\u001b[39m, in \u001b[36mSeriesGroupBy._aggregate_multiple_funcs\u001b[39m\u001b[34m(self, arg, *args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[32m    361\u001b[39m         key = base.OutputKey(label=name, position=idx)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         results[key] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results.values()):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:294\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._python_agg_general(func, *args, **kwargs)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[32m    299\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._aggregate_named(func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:327\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m res = obj._constructor(result, name=obj.name)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj._values, np.ndarray):\n\u001b[32m    858\u001b[39m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    882\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(obj, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[32m    889\u001b[39m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:324\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    322\u001b[39m     alias = com._builtin_table_alias[func]\n\u001b[32m    323\u001b[39m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m    327\u001b[39m result = \u001b[38;5;28mself\u001b[39m._grouper.agg_series(obj, f)\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "salary_quantiles = df_single_states.groupby('state')['salary'].agg(['count', 0.0, 0.05, 0.25, 0.50, 0.75, 0.95, 1.0])\n",
    "sorted_quantiles = salary_quantiles.sort_values(by=0.5)\n",
    "print(sorted_quantiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
