{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. üôÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you‚Äôll‚Äïof course‚Äïovercome them with what you learned in class! üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = '../data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>car racing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>wine. mac and cheese, pizza, ice cream</td>\n",
       "      <td>boredom and sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>2.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza / Wings / Cheesecake</td>\n",
       "      <td>Loneliness / Homesick / Sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>basketball</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3.882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>rice, potato, seaweed soup</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>580.0</td>\n",
       "      <td>690</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mac n Cheese, Lasagna, Pizza</td>\n",
       "      <td>happiness, they are some of my favorite foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolates, pizza, and Ritz.</td>\n",
       "      <td>hormones, Premenstrual syndrome.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0      2.4       2          1               430           NaN           315.0   \n",
       "1    3.654       1          1               610           3.0           420.0   \n",
       "2      3.3       1          1               720           4.0           420.0   \n",
       "3      3.2       1          1               430           3.0           420.0   \n",
       "4      3.5       1          1               720           2.0           420.0   \n",
       "..     ...     ...        ...               ...           ...             ...   \n",
       "120    3.5       1          1               610           4.0           420.0   \n",
       "121      3       1          1               265           2.0           315.0   \n",
       "122  3.882       1          1               720           NaN           420.0   \n",
       "123      3       2          1               720           4.0           420.0   \n",
       "124    3.9       1          1               430           NaN           315.0   \n",
       "\n",
       "     coffee                             comfort_food  \\\n",
       "0         1                                     none   \n",
       "1         2              chocolate, chips, ice cream   \n",
       "2         2          frozen yogurt, pizza, fast food   \n",
       "3         2         Pizza, Mac and cheese, ice cream   \n",
       "4         2             Ice cream, chocolate, chips    \n",
       "..      ...                                      ...   \n",
       "120       2  wine. mac and cheese, pizza, ice cream    \n",
       "121       2               Pizza / Wings / Cheesecake   \n",
       "122       1               rice, potato, seaweed soup   \n",
       "123       1             Mac n Cheese, Lasagna, Pizza   \n",
       "124       2             Chocolates, pizza, and Ritz.   \n",
       "\n",
       "                              comfort_food_reasons  \\\n",
       "0                            we dont have comfort    \n",
       "1                             Stress, bored, anger   \n",
       "2                                  stress, sadness   \n",
       "3                                          Boredom   \n",
       "4                       Stress, boredom, cravings    \n",
       "..                                             ...   \n",
       "120                           boredom and sadness    \n",
       "121                Loneliness / Homesick / Sadness   \n",
       "122                                        sadness   \n",
       "123  happiness, they are some of my favorite foods   \n",
       "124               hormones, Premenstrual syndrome.   \n",
       "\n",
       "     comfort_food_reasons_coded  ...  soup  sports  thai_food  \\\n",
       "0                           9.0  ...   1.0     1.0          1   \n",
       "1                           1.0  ...   1.0     1.0          2   \n",
       "2                           1.0  ...   1.0     2.0          5   \n",
       "3                           2.0  ...   1.0     2.0          5   \n",
       "4                           1.0  ...   1.0     1.0          4   \n",
       "..                          ...  ...   ...     ...        ...   \n",
       "120                         NaN  ...   1.0     1.0          5   \n",
       "121                         NaN  ...   1.0     NaN          4   \n",
       "122                         NaN  ...   1.0     2.0          5   \n",
       "123                         NaN  ...   2.0     2.0          1   \n",
       "124                         NaN  ...   1.0     2.0          2   \n",
       "\n",
       "    tortilla_calories  turkey_calories  type_sports veggies_day  vitamins  \\\n",
       "0              1165.0              345   car racing           5         1   \n",
       "1               725.0              690  Basketball            4         2   \n",
       "2              1165.0              500         none           5         1   \n",
       "3               725.0              690          NaN           3         1   \n",
       "4               940.0              500     Softball           4         2   \n",
       "..                ...              ...          ...         ...       ...   \n",
       "120             940.0              500     Softball           5         1   \n",
       "121             940.0              500  basketball            5         2   \n",
       "122             580.0              690         none           4         2   \n",
       "123             940.0              500          NaN           3         1   \n",
       "124             725.0              345          NaN           4         2   \n",
       "\n",
       "     waffle_calories                    weight  \n",
       "0               1315                       187  \n",
       "1                900                       155  \n",
       "2                900  I'm not answering this.   \n",
       "3               1315             Not sure, 240  \n",
       "4                760                       190  \n",
       "..               ...                       ...  \n",
       "120             1315                       156  \n",
       "121             1315                       180  \n",
       "122             1315                       120  \n",
       "123             1315                       135  \n",
       "124              575                       135  \n",
       "\n",
       "[125 rows x 61 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food #125 rows x 61 cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "\n",
    "df_food.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we‚Äôd like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. ‚Ä¶and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories_day</th>\n",
       "      <th>weight</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Not sure, 240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4.0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2.0</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.0</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     calories_day                    weight  Gender\n",
       "0             NaN                       187       2\n",
       "1             3.0                       155       1\n",
       "2             4.0  I'm not answering this.        1\n",
       "3             3.0             Not sure, 240       1\n",
       "4             2.0                       190       1\n",
       "..            ...                       ...     ...\n",
       "120           4.0                       156       1\n",
       "121           2.0                       180       1\n",
       "122           NaN                       120       1\n",
       "123           4.0                       135       2\n",
       "124           NaN                       135       1\n",
       "\n",
       "[125 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['calories_day', 'weight', 'Gender']\n",
    "\n",
    "df_food = df_food[data]\n",
    "\n",
    "df_food\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories_day    19\n",
       "weight           2\n",
       "Gender           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count 'em.\n",
    "df_food.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s‚Äïthe entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'em.\n",
    "df_food = df_food.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. ü§î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/nzr_jy21479579073nm09q3m0000gn/T/ipykernel_54263/353942866.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_food['calories_day'] = pd.to_numeric(df_food['calories_day'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Fix that.\n",
    "df_food['calories_day'] = pd.to_numeric(df_food['calories_day'], errors='coerce')\n",
    "df_food = df_food.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! üòÅ\n",
    "\n",
    "Let‚Äôs save it somewhere to be shipped off to another teammate. üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "df_food.to_csv('../data/food_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "salary_data_path = '../data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv'\n",
    "df_salary = pd.read_csv(salary_data_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? üôÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 28062\n",
      "Number of columns: 18\n",
      "\n",
      "Shape:  (28062, 18)\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. I'm dead serious.\n",
    "print(f\"Number of rows: {len(df_salary)}\")\n",
    "print(f\"Number of columns: {len(df_salary.columns)}\")\n",
    "print(\"\\nShape: \", df_salary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "'Timestamp'\n",
      "'How old are you?'\n",
      "'What industry do you work in?'\n",
      "'Job title'\n",
      "'If your job title needs additional context, please clarify here:'\n",
      "'What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)'\n",
      "'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.'\n",
      "'Please indicate the currency'\n",
      "'If \"Other,\" please indicate the currency here: '\n",
      "'If your income needs additional context, please provide it here:'\n",
      "'What country do you work in?'\n",
      "'If you're in the U.S., what state do you work in?'\n",
      "'What city do you work in?'\n",
      "'How many years of professional work experience do you have overall?'\n",
      "'How many years of professional work experience do you have in your field?'\n",
      "'What is your highest level of education completed?'\n",
      "'What is your gender?'\n",
      "'What is your race? (Choose all that apply.)'\n",
      "\n",
      "Column types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28062 entries, 0 to 28061\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                                                                                                                                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                                                --------------  -----  \n",
      " 0   Timestamp                                                                                                                                                                                                                             28062 non-null  object \n",
      " 1   How old are you?                                                                                                                                                                                                                      28062 non-null  object \n",
      " 2   What industry do you work in?                                                                                                                                                                                                         27988 non-null  object \n",
      " 3   Job title                                                                                                                                                                                                                             28061 non-null  object \n",
      " 4   If your job title needs additional context, please clarify here:                                                                                                                                                                      7262 non-null   object \n",
      " 5   What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  28062 non-null  object \n",
      " 6   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                        20766 non-null  float64\n",
      " 7   Please indicate the currency                                                                                                                                                                                                          28062 non-null  object \n",
      " 8   If \"Other,\" please indicate the currency here:                                                                                                                                                                                        206 non-null    object \n",
      " 9   If your income needs additional context, please provide it here:                                                                                                                                                                      3042 non-null   object \n",
      " 10  What country do you work in?                                                                                                                                                                                                          28062 non-null  object \n",
      " 11  If you're in the U.S., what state do you work in?                                                                                                                                                                                     23039 non-null  object \n",
      " 12  What city do you work in?                                                                                                                                                                                                             27980 non-null  object \n",
      " 13  How many years of professional work experience do you have overall?                                                                                                                                                                   28062 non-null  object \n",
      " 14  How many years of professional work experience do you have in your field?                                                                                                                                                             28062 non-null  object \n",
      " 15  What is your highest level of education completed?                                                                                                                                                                                    27840 non-null  object \n",
      " 16  What is your gender?                                                                                                                                                                                                                  27891 non-null  object \n",
      " 17  What is your race? (Choose all that apply.)                                                                                                                                                                                           27885 non-null  object \n",
      "dtypes: float64(1), object(17)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "print(\"Column names:\")\n",
    "for col in df_salary.columns:\n",
    "    print(f\"'{col}'\")\n",
    "\n",
    "print(\"\\nColumn types:\")\n",
    "df_salary.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh‚Ä¶ Ugh! Give these columns easier names to work with first. üôÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'em.\n",
    "column_mapping = {\n",
    "    'Timestamp': 'timestamp',\n",
    "    'How old are you?': 'age',\n",
    "    'What industry do you work in?': 'industry',\n",
    "    'Job title': 'title',\n",
    "    'If your job title needs additional context, please clarify here:': 'title_context',\n",
    "    \"What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)\": 'salary',\n",
    "    'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.': 'additional_compensation',\n",
    "    'Please indicate the currency': 'currency',\n",
    "    'If \"Other,\" please indicate the currency here: ': 'other_currency',\n",
    "    'If your income needs additional context, please provide it here:': 'salary_context',\n",
    "    'What country do you work in?': 'country',\n",
    "    \"If you're in the U.S., what state do you work in?\": 'state',\n",
    "    'What city do you work in?': 'city',\n",
    "    'How many years of professional work experience do you have overall?': 'total_yoe',\n",
    "    'How many years of professional work experience do you have in your field?': 'field_yoe',\n",
    "    'What is your highest level of education completed?': 'highest_education_completed',\n",
    "    'What is your gender?': 'gender',\n",
    "    'What is your race? (Choose all that apply.)': 'race'\n",
    "}\n",
    "\n",
    "df_salary = df_salary.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It‚Äôs a lot, and that should not have been easy. üòè"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôre going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 industries by count:\n",
      "industry\n",
      "Computing or Tech                       4699\n",
      "Education (Higher Education)            2464\n",
      "Nonprofits                              2419\n",
      "Health care                             1896\n",
      "Government and Public Administration    1889\n",
      "Accounting, Banking & Finance           1809\n",
      "Engineering or Manufacturing            1695\n",
      "Marketing, Advertising & PR             1133\n",
      "Law                                     1097\n",
      "Business or Consulting                   852\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "industry_counts = df_salary['industry'].value_counts()\n",
    "print(\"Top 10 industries by count:\")\n",
    "print(industry_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you‚Äôre looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "df_salary_tech = df_salary[df_salary['industry'] == 'Computing or Tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique industries in filtered dataset:\n",
      "['Computing or Tech']\n",
      "\n",
      "Number of records: 4699\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "print(\"Unique industries in filtered dataset:\")\n",
    "print(df_salary_tech['industry'].unique())\n",
    "print(\"\\nNumber of records:\", len(df_salary_tech))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars üíµ is a euro üí∂ or a pound üí∑? That sounds like a problem for another day. ü´†\n",
    "\n",
    "For now, let‚Äôs just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "df_salary_tech = df_salary_tech[df_salary_tech['currency'] == 'USD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 countries by count:\n",
      "country\n",
      "United States                1576\n",
      "USA                          1222\n",
      "US                            412\n",
      "U.S.                          108\n",
      "United States of America       90\n",
      "United States                  68\n",
      "Usa                            59\n",
      "USA                            56\n",
      "usa                            28\n",
      "United states                  23\n",
      "united states                  14\n",
      "Us                             12\n",
      "us                              9\n",
      "U.S.A.                          7\n",
      "United States of America        7\n",
      "Israel                          5\n",
      "Canada                          4\n",
      "UnitedStates                    2\n",
      "New Zealand                     2\n",
      "united States                   2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "country_counts = df_salary_tech['country'].value_counts()\n",
    "print(\"Top 20 countries by count:\")\n",
    "print(country_counts.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can‚Äôt get our answers with what we currently have, so you‚Äôll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value‚Äïsay, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace them all with 'US'.\n",
    "us_variants = ['United States', 'USA', 'US', 'U.S.', 'United States of America', 'United states',\n",
    "               'Usa', 'usa', 'united states', 'Us', 'us', 'U.S.A.', 'UnitedStates', 'united States']\n",
    "\n",
    "for variant in us_variants:\n",
    "    df_salary_tech.loc[df_salary_tech['country'] == variant, 'country'] = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries after cleanup:\n",
      "country\n",
      "US                           3564\n",
      "United States                  68\n",
      "USA                            56\n",
      "United States of America        7\n",
      "Israel                          5\n",
      "                             ... \n",
      "Uruguay                         1\n",
      "Canada                          1\n",
      "United Stateds                  1\n",
      "ISA                             1\n",
      "Burma                           1\n",
      "Name: count, Length: 63, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count again.\n",
    "country_counts = df_salary_tech['country'].value_counts()\n",
    "print(\"Countries after cleanup:\")\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "def standardize_us(country):\n",
    "    if pd.isna(country):\n",
    "        return country\n",
    "\n",
    "    country = str(country).strip().lower()\n",
    "\n",
    "    # Check if it's some variant of 'United States'\n",
    "    if ('united' in country and 'state' in country) or \\\n",
    "       any(us_var in country for us_var in ['us', 'usa', 'u.s', 'u.s.a']):\n",
    "        return 'US'\n",
    "\n",
    "    return country\n",
    "\n",
    "# Apply the standardization\n",
    "df_salary_tech['country'] = df_salary_tech['country'].apply(standardize_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 countries after cleanup:\n",
      "country\n",
      "US                3720\n",
      "israel               5\n",
      "canada               5\n",
      "denmark              2\n",
      "spain                2\n",
      "singapore            2\n",
      "united kingdom       2\n",
      "india                2\n",
      "brazil               2\n",
      "new zealand          2\n",
      "poland               2\n",
      "unite states         2\n",
      "nigeria              2\n",
      "france               2\n",
      "japan                1\n",
      "united stares        1\n",
      "romania              1\n",
      "jamaica              1\n",
      "china                1\n",
      "unites states        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BONUS CREDIT: if you've resolved it, let's see how well you did by counting the number of instances of each unique value.\n",
    "country_counts = df_salary_tech['country'].value_counts()\n",
    "print(\"Top 20 countries after cleanup:\")\n",
    "print(country_counts.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It‚Äôs looking good so far. Let‚Äôs find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn‚Äôt numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/m6/nzr_jy21479579073nm09q3m0000gn/T/ipykernel_54263/847955200.py:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df_salary_tech['salary'] = df_salary_tech['salary'].replace('[\\$,]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Fix it.\n",
    "# First, let's clean up the salary column\n",
    "df_salary_tech['salary'] = df_salary_tech['salary'].replace('[\\$,]', '', regex=True)\n",
    "df_salary_tech['salary'] = pd.to_numeric(df_salary_tech['salary'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary statistics by state (sorted by mean salary):\n",
      "                                min       mean      max\n",
      "state                                                  \n",
      "Michigan, Texas, Washington  340000  340000.00   340000\n",
      "California, Oregon           200000  200000.00   200000\n",
      "California, Colorado         176000  176000.00   176000\n",
      "Georgia, Massachusetts       175000  175000.00   175000\n",
      "Florida                       28800  157457.23  2600000\n",
      "...                             ...        ...      ...\n",
      "Louisiana                     35360   83269.09   150000\n",
      "Massachusetts, Pennsylvania   83000   83000.00    83000\n",
      "Arkansas                      55000   81682.30   144000\n",
      "California, Maryland          81500   81500.00    81500\n",
      "Alabama, Montana              72000   72000.00    72000\n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Try it again. Yeah!\n",
    "# Filter for US records only\n",
    "us_data = df_salary_tech[df_salary_tech['country'] == 'US']\n",
    "\n",
    "# Group by state and calculate statistics\n",
    "state_stats = us_data.groupby('state')['salary'].agg(['min', 'mean', 'max']).round(2)\n",
    "state_stats = state_stats.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Salary statistics by state (sorted by mean salary):\")\n",
    "print(state_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let‚Äôs narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary statistics by state for 2021-2022 (sorted by mean salary):\n",
      "                                  min       mean     max\n",
      "state                                                   \n",
      "Michigan, Texas, Washington    340000  340000.00  340000\n",
      "California, Oregon             200000  200000.00  200000\n",
      "California, Colorado           176000  176000.00  176000\n",
      "Georgia, Massachusetts         175000  175000.00  175000\n",
      "Alabama, District of Columbia  156000  156000.00  156000\n",
      "...                               ...        ...     ...\n",
      "Louisiana                       35360   83269.09  150000\n",
      "Massachusetts, Pennsylvania     83000   83000.00   83000\n",
      "Arkansas                        55000   81682.30  144000\n",
      "California, Maryland            81500   81500.00   81500\n",
      "Alabama, Montana                72000   72000.00   72000\n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df_salary_tech['timestamp'] = pd.to_datetime(df_salary_tech['timestamp'])\n",
    "\n",
    "# Create a filtered DataFrame\n",
    "df_recent = df_salary_tech[\n",
    "    (df_salary_tech['timestamp'].dt.year >= 2021) &\n",
    "    (df_salary_tech['timestamp'].dt.year <= 2022) &\n",
    "    (df_salary_tech['country'] == 'US')\n",
    "]\n",
    "\n",
    "# Calculate statistics\n",
    "state_stats_recent = df_recent.groupby('state')['salary'].agg(['min', 'mean', 'max']).round(2)\n",
    "state_stats_recent = state_stats_recent.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Salary statistics by state for 2021-2022 (sorted by mean salary):\")\n",
    "print(state_stats_recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you‚Äôve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let‚Äôs back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary statistics by state for all industries (sorted by mean salary):\n",
      "                                                       min       mean  \\\n",
      "state                                                                   \n",
      "Michigan, Texas, Washington                         340000  340000.00   \n",
      "Indiana, Ohio                                       245000  245000.00   \n",
      "Alaska                                               27040  232275.08   \n",
      "Colorado, Nevada                                    190000  190000.00   \n",
      "California, Montana                                 185000  185000.00   \n",
      "...                                                    ...        ...   \n",
      "Delaware, Pennsylvania                               35000   35000.00   \n",
      "District of Columbia, Washington                     35000   35000.00   \n",
      "Alabama, California                                  29120   29120.00   \n",
      "District of Columbia, Maryland, Pennsylvania, V...   27040   27040.00   \n",
      "Maryland, New York                                   14000   14000.00   \n",
      "\n",
      "                                                         max  \n",
      "state                                                         \n",
      "Michigan, Texas, Washington                           340000  \n",
      "Indiana, Ohio                                         245000  \n",
      "Alaska                                              10000000  \n",
      "Colorado, Nevada                                      190000  \n",
      "California, Montana                                   185000  \n",
      "...                                                      ...  \n",
      "Delaware, Pennsylvania                                 35000  \n",
      "District of Columbia, Washington                       35000  \n",
      "Alabama, California                                    29120  \n",
      "District of Columbia, Maryland, Pennsylvania, V...     27040  \n",
      "Maryland, New York                                     14000  \n",
      "\n",
      "[130 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/m6/nzr_jy21479579073nm09q3m0000gn/T/ipykernel_54263/228111693.py:3: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df_salary['salary'] = df_salary['salary'].replace('[\\$,]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply same steps to full dataset\n",
    "# Clean salary data\n",
    "df_salary['salary'] = df_salary['salary'].replace('[\\$,]', '', regex=True)\n",
    "df_salary['salary'] = pd.to_numeric(df_salary['salary'], errors='coerce')\n",
    "\n",
    "# Clean country data\n",
    "df_salary['country'] = df_salary['country'].apply(standardize_us)\n",
    "\n",
    "# Filter for US and USD\n",
    "df_salary_clean = df_salary[\n",
    "    (df_salary['country'] == 'US') &\n",
    "    (df_salary['currency'] == 'USD')\n",
    "]\n",
    "\n",
    "# Calculate statistics\n",
    "all_state_stats = df_salary_clean.groupby('state')['salary'].agg(['min', 'mean', 'max']).round(2)\n",
    "all_state_stats = all_state_stats.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Salary statistics by state for all industries (sorted by mean salary):\")\n",
    "print(all_state_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary statistics by state for all industries (sorted by mean salary):\n",
      "                                                       min        mean  \\\n",
      "state                                                                    \n",
      "Michigan, Texas, Washington                         340000 $340,000.00   \n",
      "Indiana, Ohio                                       245000 $245,000.00   \n",
      "Alaska                                               27040 $232,275.08   \n",
      "Colorado, Nevada                                    190000 $190,000.00   \n",
      "California, Montana                                 185000 $185,000.00   \n",
      "...                                                    ...         ...   \n",
      "Delaware, Pennsylvania                               35000  $35,000.00   \n",
      "District of Columbia, Washington                     35000  $35,000.00   \n",
      "Alabama, California                                  29120  $29,120.00   \n",
      "District of Columbia, Maryland, Pennsylvania, V...   27040  $27,040.00   \n",
      "Maryland, New York                                   14000  $14,000.00   \n",
      "\n",
      "                                                         max  \n",
      "state                                                         \n",
      "Michigan, Texas, Washington                           340000  \n",
      "Indiana, Ohio                                         245000  \n",
      "Alaska                                              10000000  \n",
      "Colorado, Nevada                                      190000  \n",
      "California, Montana                                   185000  \n",
      "...                                                      ...  \n",
      "Delaware, Pennsylvania                                 35000  \n",
      "District of Columbia, Washington                       35000  \n",
      "Alabama, California                                    29120  \n",
      "District of Columbia, Maryland, Pennsylvania, V...     27040  \n",
      "Maryland, New York                                     14000  \n",
      "\n",
      "[130 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Format the table with currency formatting\n",
    "pd.options.display.float_format = '${:,.2f}'.format\n",
    "\n",
    "print(\"Salary statistics by state for all industries (sorted by mean salary):\")\n",
    "print(all_state_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary statistics by single states (sorted by mean salary):\n",
      "                        min        mean       max\n",
      "state                                            \n",
      "Alaska                27040 $232,275.08  10000000\n",
      "California                0 $114,349.58    875000\n",
      "Washington               72 $107,888.45   1260000\n",
      "District of Columbia     40 $106,662.21   1334782\n",
      "New York                 80 $105,281.29   3000000\n",
      "New Jersey            14850 $101,132.50   5000044\n",
      "Massachusetts           155  $98,733.04   1650000\n",
      "Virginia                 57  $94,689.10   1300000\n",
      "Connecticut               0  $93,572.51   1900000\n",
      "Illinois                  0  $90,366.20   1100000\n",
      "Colorado                 65  $89,671.73    630000\n",
      "Maryland                  0  $89,437.60    353200\n",
      "Oregon                    0  $89,010.77    320000\n",
      "Texas                     0  $88,889.84   1200000\n",
      "Delaware              35000  $87,502.46    220000\n",
      "Georgia                   0  $86,772.42    860000\n",
      "Utah                  18720  $86,462.05    576000\n",
      "Florida                 150  $83,580.73   2600000\n",
      "Pennsylvania              0  $83,246.47   1100000\n",
      "New Mexico               78  $81,900.23    300000\n",
      "Minnesota                40  $81,777.93    321250\n",
      "North Carolina         4000  $80,999.28    560000\n",
      "Nevada                   55  $80,812.60    425000\n",
      "Arizona               12000  $79,863.53    380000\n",
      "Hawaii                12000  $77,699.47    500000\n",
      "Rhode Island          18000  $77,301.97    200000\n",
      "Michigan                 55  $76,628.81    500000\n",
      "Wisconsin                 1  $76,416.31    920000\n",
      "Ohio                     36  $75,989.98    954000\n",
      "Tennessee             20800  $75,916.77    657900\n",
      "Missouri                 70  $75,242.10    335000\n",
      "Arkansas              26000  $74,712.41    488000\n",
      "New Hampshire            55  $73,277.58    208000\n",
      "Louisiana             17000  $72,963.20    253300\n",
      "Indiana                 105  $72,820.48    925000\n",
      "Kansas                   52  $72,063.20    734400\n",
      "Nebraska              18000  $71,789.83    224000\n",
      "Alabama                  54  $71,092.09    350000\n",
      "Vermont               24960  $70,534.93    200000\n",
      "Idaho                    38  $70,439.80    312000\n",
      "Iowa                  13000  $68,835.44    200000\n",
      "Oklahoma              18000  $66,131.17    180000\n",
      "Kentucky                  0  $65,872.58    208000\n",
      "South Carolina            0  $65,774.50    250000\n",
      "Maine                 22000  $64,920.46    173000\n",
      "South Dakota          29000  $64,214.36    150000\n",
      "North Dakota              0  $62,174.34    150000\n",
      "Montana               19200  $61,358.68    172000\n",
      "Mississippi           25000  $61,282.45    130000\n",
      "Wyoming               29000  $58,896.65    140000\n",
      "West Virginia             0  $58,664.17    125000\n"
     ]
    }
   ],
   "source": [
    "# Filter out multi-state entries\n",
    "single_state_data = df_salary_clean[~df_salary_clean['state'].str.contains(',', na=False)]\n",
    "\n",
    "# Calculate statistics for single states only\n",
    "single_state_stats = single_state_data.groupby('state')['salary'].agg(['min', 'mean', 'max']).round(2)\n",
    "single_state_stats = single_state_stats.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Salary statistics by single states (sorted by mean salary):\")\n",
    "print(single_state_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum‚Äïsay 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you‚Äïlike say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* üòú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary statistics by state with quantiles and count (sorted by median salary):\n",
      "\n",
      "Columns:\n",
      "count: Number of data points\n",
      "p0: Minimum (0th percentile)\n",
      "p5: 5th percentile\n",
      "p25: 25th percentile\n",
      "p50: Median (50th percentile)\n",
      "p75: 75th percentile\n",
      "p95: 95th percentile\n",
      "p100: Maximum (100th percentile)\n",
      "\n",
      "Data:\n",
      "                      count          p0          p5         p25          p50  \\\n",
      "state                                                                          \n",
      "California             2589       $0.00  $42,000.00  $72,000.00  $100,360.00   \n",
      "Washington             1181      $72.00  $40,000.00  $65,000.00   $91,000.00   \n",
      "New York               2169      $80.00  $40,688.00  $64,480.00   $90,000.00   \n",
      "District of Columbia    975      $40.00  $48,000.00  $66,700.00   $90,000.00   \n",
      "Massachusetts          1518     $155.00  $42,000.00  $64,000.00   $86,000.00   \n",
      "Maryland                563       $0.00  $40,100.00  $60,000.00   $82,000.00   \n",
      "Connecticut             236       $0.00  $33,787.50  $61,750.00   $81,900.00   \n",
      "Delaware                 46  $35,000.00  $41,704.00  $58,869.75   $81,322.50   \n",
      "Virginia                780      $57.00  $37,380.00  $58,750.00   $80,616.50   \n",
      "Oregon                  620       $0.00  $36,380.00  $58,800.00   $78,000.00   \n",
      "Texas                  1258       $0.00  $35,155.80  $55,000.00   $76,000.00   \n",
      "Colorado                630      $65.00  $38,939.00  $58,000.00   $76,000.00   \n",
      "Illinois               1205       $0.00  $37,452.00  $56,000.00   $76,000.00   \n",
      "Minnesota               717      $40.00  $39,520.00  $55,000.00   $75,000.00   \n",
      "New Jersey              396  $14,850.00  $35,270.00  $57,750.00   $75,000.00   \n",
      "Georgia                 534       $0.00  $32,000.00  $53,125.00   $75,000.00   \n",
      "North Carolina          600   $4,000.00  $34,491.00  $51,000.00   $73,500.00   \n",
      "Utah                    207  $18,720.00  $33,796.00  $54,175.00   $72,807.00   \n",
      "Alaska                   64  $27,040.00  $40,000.00  $56,500.00   $72,400.00   \n",
      "Rhode Island             76  $18,000.00  $35,950.00  $51,250.00   $71,500.00   \n",
      "Nevada                   92      $55.00  $33,753.10  $51,500.00   $70,500.00   \n",
      "Pennsylvania            940       $0.00  $33,142.50  $52,000.00   $70,492.00   \n",
      "New Mexico               98      $78.00  $33,892.00  $52,000.00   $69,000.00   \n",
      "Michigan                543      $55.00  $32,000.00  $52,260.00   $67,500.00   \n",
      "Ohio                    652      $36.00  $33,000.00  $50,000.00   $67,250.00   \n",
      "Florida                 518     $150.00  $31,200.00  $47,880.00   $67,000.00   \n",
      "Arizona                 300  $12,000.00  $34,000.00  $50,000.00   $66,850.00   \n",
      "Wisconsin               468       $1.00  $34,000.00  $50,000.00   $66,280.00   \n",
      "Missouri                340      $70.00  $30,500.00  $47,755.00   $65,260.00   \n",
      "New Hampshire           118      $55.00  $30,983.20  $46,200.00   $65,000.00   \n",
      "Indiana                 328     $105.00  $33,050.00  $48,825.00   $65,000.00   \n",
      "Nebraska                108  $18,000.00  $32,947.85  $45,073.50   $64,000.00   \n",
      "Tennessee               281  $20,800.00  $33,000.00  $47,500.00   $63,500.00   \n",
      "Hawaii                   30  $12,000.00  $31,107.00  $53,250.00   $62,850.00   \n",
      "Louisiana               129  $17,000.00  $30,272.00  $47,000.00   $62,500.00   \n",
      "Iowa                    178  $13,000.00  $30,000.00  $47,840.00   $62,500.00   \n",
      "Vermont                  67  $24,960.00  $32,300.00  $50,000.00   $62,000.00   \n",
      "Kansas                  153      $52.00  $33,600.00  $45,000.00   $61,000.00   \n",
      "South Dakota             25  $29,000.00  $31,560.00  $45,750.00   $60,000.00   \n",
      "Alabama                 117      $54.00  $27,600.00  $45,600.00   $60,000.00   \n",
      "Idaho                    97      $38.00  $30,960.00  $46,000.00   $60,000.00   \n",
      "Arkansas                 69  $26,000.00  $30,680.00  $46,000.00   $60,000.00   \n",
      "Kentucky                190       $0.00  $29,000.00  $43,545.00   $59,317.50   \n",
      "North Dakota             35       $0.00  $27,584.00  $45,000.00   $59,000.00   \n",
      "Maine                   125  $22,000.00  $34,511.20  $43,000.00   $58,500.00   \n",
      "South Carolina          146       $0.00  $29,152.50  $43,140.00   $56,250.00   \n",
      "Oklahoma                113  $18,000.00  $27,521.60  $43,000.00   $54,000.00   \n",
      "Mississippi              49  $25,000.00  $31,080.00  $36,663.00   $53,000.00   \n",
      "Wyoming                  23  $29,000.00  $31,803.20  $43,250.00   $50,004.00   \n",
      "West Virginia            41       $0.00  $27,000.00  $41,000.00   $49,088.00   \n",
      "Montana                  63  $19,200.00  $33,557.20  $37,250.00   $48,000.00   \n",
      "\n",
      "                              p75          p95            p100  \n",
      "state                                                           \n",
      "California            $147,000.00  $220,000.00     $875,000.00  \n",
      "Washington            $135,000.00  $201,000.00   $1,260,000.00  \n",
      "New York              $127,000.00  $210,600.00   $3,000,000.00  \n",
      "District of Columbia  $125,000.00  $189,300.00   $1,334,782.00  \n",
      "Massachusetts         $120,000.00  $180,300.00   $1,650,000.00  \n",
      "Maryland              $110,000.00  $165,000.00     $353,200.00  \n",
      "Connecticut           $100,000.00  $162,500.00   $1,900,000.00  \n",
      "Delaware              $105,750.00  $164,247.50     $220,000.00  \n",
      "Virginia              $115,000.00  $180,000.00   $1,300,000.00  \n",
      "Oregon                $110,000.00  $185,000.00     $320,000.00  \n",
      "Texas                 $110,000.00  $175,000.00   $1,200,000.00  \n",
      "Colorado              $110,750.00  $165,275.00     $630,000.00  \n",
      "Illinois              $110,000.00  $171,600.00   $1,100,000.00  \n",
      "Minnesota             $100,000.00  $150,000.00     $321,250.00  \n",
      "New Jersey            $104,250.00  $177,600.00   $5,000,044.00  \n",
      "Georgia               $105,000.00  $173,700.00     $860,000.00  \n",
      "North Carolina         $98,000.00  $150,000.00     $560,000.00  \n",
      "Utah                  $100,500.00  $175,700.00     $576,000.00  \n",
      "Alaska                 $90,500.00  $144,550.00  $10,000,000.00  \n",
      "Rhode Island           $93,875.00  $134,250.00     $200,000.00  \n",
      "Nevada                 $95,100.00  $167,250.00     $425,000.00  \n",
      "Pennsylvania          $100,200.00  $165,100.00   $1,100,000.00  \n",
      "New Mexico            $107,000.00  $166,800.00     $300,000.00  \n",
      "Michigan               $90,500.00  $147,819.20     $500,000.00  \n",
      "Ohio                   $89,261.25  $150,000.00     $954,000.00  \n",
      "Florida                $97,875.00  $162,150.00   $2,600,000.00  \n",
      "Arizona               $100,000.00  $155,100.00     $380,000.00  \n",
      "Wisconsin              $90,000.00  $146,300.00     $920,000.00  \n",
      "Missouri               $94,125.00  $145,000.00     $335,000.00  \n",
      "New Hampshire          $88,875.00  $142,734.75     $208,000.00  \n",
      "Indiana                $84,752.50  $134,300.00     $925,000.00  \n",
      "Nebraska               $88,250.00  $138,250.00     $224,000.00  \n",
      "Tennessee              $85,000.00  $157,000.00     $657,900.00  \n",
      "Hawaii                 $75,000.00  $123,100.00     $500,000.00  \n",
      "Louisiana              $85,000.00  $150,000.00     $253,300.00  \n",
      "Iowa                   $87,500.00  $123,087.50     $200,000.00  \n",
      "Vermont                $83,000.00  $124,400.00     $200,000.00  \n",
      "Kansas                 $81,000.00  $125,000.00     $734,400.00  \n",
      "South Dakota           $66,805.00  $126,800.00     $150,000.00  \n",
      "Alabama                $85,000.00  $141,200.00     $350,000.00  \n",
      "Idaho                  $78,000.00  $130,000.00     $312,000.00  \n",
      "Arkansas               $85,000.00  $144,600.00     $488,000.00  \n",
      "Kentucky               $78,000.00  $130,000.00     $208,000.00  \n",
      "North Dakota           $75,000.00  $110,500.00     $150,000.00  \n",
      "Maine                  $83,000.00  $114,800.00     $173,000.00  \n",
      "South Carolina         $78,937.50  $128,148.75     $250,000.00  \n",
      "Oklahoma               $80,000.00  $142,200.00     $180,000.00  \n",
      "Mississippi            $82,000.00  $113,600.00     $130,000.00  \n",
      "Wyoming                $71,500.00   $97,200.00     $140,000.00  \n",
      "West Virginia          $71,400.00  $117,516.00     $125,000.00  \n",
      "Montana                $83,500.00  $125,800.00     $172,000.00  \n"
     ]
    }
   ],
   "source": [
    "# Reset display format for numbers\n",
    "pd.options.display.float_format = None\n",
    "\n",
    "# Calculate quantiles and count for each state\n",
    "quantiles = [0, 0.05, 0.25, 0.50, 0.75, 0.95, 1.0]\n",
    "state_stats = single_state_data.groupby('state')['salary'].agg([\n",
    "    ('count', 'count'),\n",
    "    *[(f'p{int(q*100)}', lambda x, q=q: x.quantile(q)) for q in quantiles]\n",
    "]).round(2)\n",
    "\n",
    "# Sort by median (p50)\n",
    "state_stats = state_stats.sort_values('p50', ascending=False)\n",
    "\n",
    "# Format currency for all columns except count\n",
    "for col in state_stats.columns[1:]:  # Skip 'count'\n",
    "    state_stats[col] = state_stats[col].apply(lambda x: f\"${x:,.2f}\")\n",
    "\n",
    "print(\"Salary statistics by state with quantiles and count (sorted by median salary):\")\n",
    "print(\"\\nColumns:\")\n",
    "print(\"count: Number of data points\")\n",
    "print(\"p0: Minimum (0th percentile)\")\n",
    "print(\"p5: 5th percentile\")\n",
    "print(\"p25: 25th percentile\")\n",
    "print(\"p50: Median (50th percentile)\")\n",
    "print(\"p75: 75th percentile\")\n",
    "print(\"p95: 95th percentile\")\n",
    "print(\"p100: Maximum (100th percentile)\")\n",
    "print(\"\\nData:\")\n",
    "print(state_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
