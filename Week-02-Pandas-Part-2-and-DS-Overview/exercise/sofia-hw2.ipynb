{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. üôÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you‚Äôll‚Äïof course‚Äïovercome them with what you learned in class! üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "# making a change here to test...\n",
    "\n",
    "# test pull request 0512pm\n",
    "food_data_set_path = '../data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "print(df_food.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0      2.4       2          1               430           NaN           315.0   \n",
       "1    3.654       1          1               610           3.0           420.0   \n",
       "2      3.3       1          1               720           4.0           420.0   \n",
       "3      3.2       1          1               430           3.0           420.0   \n",
       "4      3.5       1          1               720           2.0           420.0   \n",
       "..     ...     ...        ...               ...           ...             ...   \n",
       "120    3.5       1          1               610           4.0           420.0   \n",
       "121      3       1          1               265           2.0           315.0   \n",
       "122  3.882       1          1               720           NaN           420.0   \n",
       "123      3       2          1               720           4.0           420.0   \n",
       "124    3.9       1          1               430           NaN           315.0   \n",
       "\n",
       "     coffee                             comfort_food  \\\n",
       "0         1                                     none   \n",
       "1         2              chocolate, chips, ice cream   \n",
       "2         2          frozen yogurt, pizza, fast food   \n",
       "3         2         Pizza, Mac and cheese, ice cream   \n",
       "4         2             Ice cream, chocolate, chips    \n",
       "..      ...                                      ...   \n",
       "120       2  wine. mac and cheese, pizza, ice cream    \n",
       "121       2               Pizza / Wings / Cheesecake   \n",
       "122       1               rice, potato, seaweed soup   \n",
       "123       1             Mac n Cheese, Lasagna, Pizza   \n",
       "124       2             Chocolates, pizza, and Ritz.   \n",
       "\n",
       "                              comfort_food_reasons  \\\n",
       "0                            we dont have comfort    \n",
       "1                             Stress, bored, anger   \n",
       "2                                  stress, sadness   \n",
       "3                                          Boredom   \n",
       "4                       Stress, boredom, cravings    \n",
       "..                                             ...   \n",
       "120                           boredom and sadness    \n",
       "121                Loneliness / Homesick / Sadness   \n",
       "122                                        sadness   \n",
       "123  happiness, they are some of my favorite foods   \n",
       "124               hormones, Premenstrual syndrome.   \n",
       "\n",
       "     comfort_food_reasons_coded  ...  soup  sports  thai_food  \\\n",
       "0                           9.0  ...   1.0     1.0          1   \n",
       "1                           1.0  ...   1.0     1.0          2   \n",
       "2                           1.0  ...   1.0     2.0          5   \n",
       "3                           2.0  ...   1.0     2.0          5   \n",
       "4                           1.0  ...   1.0     1.0          4   \n",
       "..                          ...  ...   ...     ...        ...   \n",
       "120                         NaN  ...   1.0     1.0          5   \n",
       "121                         NaN  ...   1.0     NaN          4   \n",
       "122                         NaN  ...   1.0     2.0          5   \n",
       "123                         NaN  ...   2.0     2.0          1   \n",
       "124                         NaN  ...   1.0     2.0          2   \n",
       "\n",
       "    tortilla_calories  turkey_calories  type_sports veggies_day  vitamins  \\\n",
       "0              1165.0              345   car racing           5         1   \n",
       "1               725.0              690  Basketball            4         2   \n",
       "2              1165.0              500         none           5         1   \n",
       "3               725.0              690          NaN           3         1   \n",
       "4               940.0              500     Softball           4         2   \n",
       "..                ...              ...          ...         ...       ...   \n",
       "120             940.0              500     Softball           5         1   \n",
       "121             940.0              500  basketball            5         2   \n",
       "122             580.0              690         none           4         2   \n",
       "123             940.0              500          NaN           3         1   \n",
       "124             725.0              345          NaN           4         2   \n",
       "\n",
       "     waffle_calories                    weight  \n",
       "0               1315                       187  \n",
       "1                900                       155  \n",
       "2                900  I'm not answering this.   \n",
       "3               1315             Not sure, 240  \n",
       "4                760                       190  \n",
       "..               ...                       ...  \n",
       "120             1315                       156  \n",
       "121             1315                       180  \n",
       "122             1315                       120  \n",
       "123             1315                       135  \n",
       "124              575                       135  \n",
       "\n",
       "[125 rows x 61 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "# \n",
    "df_food.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we‚Äôd like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. ‚Ä¶and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories_day</th>\n",
       "      <th>Gender</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calories_day  Gender                    weight\n",
       "0           NaN       2                       187\n",
       "1           3.0       1                       155\n",
       "2           4.0       1  I'm not answering this. \n",
       "3           3.0       1             Not sure, 240\n",
       "4           2.0       1                       190"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove ‚Äòem.\n",
    "df_food_clean=df_food[['calories_day', 'Gender', 'weight']]\n",
    "df_food_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPA                  2\n",
       "Gender               0\n",
       "breakfast            0\n",
       "calories_chicken     0\n",
       "calories_day        19\n",
       "                    ..\n",
       "type_sports         26\n",
       "veggies_day          0\n",
       "vitamins             0\n",
       "waffle_calories      0\n",
       "weight               2\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ‚Äòem.\n",
    "print(\"Missing values in each column:\")\n",
    "df_food_clean.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s‚Äïthe entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ‚Äòem.\n",
    "df_food_clean.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. ü§î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix that.\n",
    "\n",
    "df_food_clean['weight'] = pd.to_numeric(df_food['weight'], errors='coerce')\n",
    "df_food_clean['calories_day'] = pd.to_numeric(df_food['calories_day'], errors='coerce')\n",
    "df_food_clean.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! üòÅ\n",
    "\n",
    "Let‚Äôs save it somewhere to be shipped off to another teammate. üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "df_food_clean.to_csv(\"clean_food.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "\n",
    "df_salary = pd.read_csv('/Users/sofia_7ayz6l2/OneDrive/Documents/ctp_repo/ds-fall-2025-fri-1230/Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv', sep='\\t')\n",
    "\n",
    "df_salary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? üôÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Salary Survey data set has 28062 rows and 18 columns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28062, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. I‚Äôm dead serious.\n",
    "print(f\"The Salary Survey data set has {df_salary.shape[0]} rows and {df_salary.shape[1]} columns.\")\n",
    "df_salary.shape # (28062, 18) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the column names and their types.\n",
    "df_salary.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh‚Ä¶ Ugh! Give these columns easier names to work with first. üôÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                       industry  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                      title title_context  salary  \\\n",
       "0        Research and Instruction Librarian           NaN  55,000   \n",
       "1  Change & Internal Communications Manager           NaN  54,600   \n",
       "2                      Marketing Specialist           NaN  34,000   \n",
       "3                           Program Manager           NaN  62,000   \n",
       "4                        Accounting Manager           NaN  60,000   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context  \\\n",
       "0                      0.0      USD            NaN            NaN   \n",
       "1                   4000.0      GBP            NaN            NaN   \n",
       "2                      NaN      USD            NaN            NaN   \n",
       "3                   3000.0      USD            NaN            NaN   \n",
       "4                   7000.0      USD            NaN            NaN   \n",
       "\n",
       "          country           state         city     total_yoe    field_yoe  \\\n",
       "0   United States   Massachusetts       Boston     5-7 years    5-7 years   \n",
       "1  United Kingdom             NaN    Cambridge  8 - 10 years    5-7 years   \n",
       "2              US       Tennessee  Chattanooga   2 - 4 years  2 - 4 years   \n",
       "3             USA       Wisconsin    Milwaukee  8 - 10 years    5-7 years   \n",
       "4              US  South Carolina   Greenville  8 - 10 years    5-7 years   \n",
       "\n",
       "  highest_education_completed      gender   race  \n",
       "0             Master's degree       Woman  White  \n",
       "1              College degree  Non-binary  White  \n",
       "2              College degree       Woman  White  \n",
       "3              College degree       Woman  White  \n",
       "4              College degree       Woman  White  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename ‚Äòem.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed\tgender, race\n",
    "\n",
    "df_salary.columns = ['timestamp', 'age', 'industry', 'title', 'title_context', 'salary', 'additional_compensation', 'currency', 'other_currency', 'salary_context', 'country', 'state', 'city', 'total_yoe', 'field_yoe', 'highest_education_completed', 'gender', 'race']\n",
    "df_salary.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It‚Äôs a lot, and that should not have been easy. üòè"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôre going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech                       4699\n",
       "Education (Higher Education)            2464\n",
       "Nonprofits                              2419\n",
       "Health care                             1896\n",
       "Government and Public Administration    1889\n",
       "Accounting, Banking & Finance           1809\n",
       "Engineering or Manufacturing            1695\n",
       "Marketing, Advertising & PR             1133\n",
       "Law                                     1097\n",
       "Business or Consulting                   852\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "\n",
    "df_salary['industry'].value_counts().head(10) # show first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you‚Äôre looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "\n",
    "\n",
    "df_salary_tech = df_salary[df_salary['industry']== \"Computing or Tech\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech    4699\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check \n",
    "df_salary_tech['industry'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars üíµ is a euro üí∂ or a pound üí∑? That sounds like a problem for another day. ü´†\n",
    "\n",
    "For now, let‚Äôs just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "\n",
    "df_salary_tech = df_salary_tech[df_salary_tech['currency'] == 'USD'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "US                3408\n",
       "United States       68\n",
       "Usa                 59\n",
       "USA                 56\n",
       "usa                 28\n",
       "United states       23\n",
       "united states       14\n",
       "Us                  12\n",
       "us                   9\n",
       "U.S.A.               7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "\n",
    "df_salary_tech['country'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can‚Äôt get our answers with what we currently have, so you‚Äôll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value‚Äïsay, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the country abbreviat.\n",
    "us_nicknames = [\n",
    "    'United States', 'USA', 'US', 'United States of America', 'U.S.'\n",
    "]\n",
    "\n",
    "# Replace all of them with 'US'\n",
    "df_salary_tech['country'] = df_salary_tech['country'].replace(us_nicknames, 'US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "US                3408\n",
       "United States       68\n",
       "Usa                 59\n",
       "USA                 56\n",
       "usa                 28\n",
       "United states       23\n",
       "united states       14\n",
       "Us                  12\n",
       "us                   9\n",
       "U.S.A.               7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count again.\n",
    "\n",
    "df_salary_tech['country'].value_counts().head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "\n",
    "df_salary_usd = df_salary_tech[df_salary_tech['currency'] == 'USD'].copy()\n",
    "\n",
    "df_salary_usd['country'] = df_salary_usd['country'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BONUS CREDIT: if you‚Äôve resolved it, let‚Äôs see how well you did by counting the number of instances of each unique value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It‚Äôs looking good so far. Let‚Äôs find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_salary</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Michigan, Texas, Washington</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>340000.000000</td>\n",
       "      <td>340000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>28800.0</td>\n",
       "      <td>210711.000000</td>\n",
       "      <td>2600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Oregon</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Colorado</th>\n",
       "      <td>176000.0</td>\n",
       "      <td>176000.000000</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>169000.0</td>\n",
       "      <td>169000.000000</td>\n",
       "      <td>169000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>161610.000000</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>153286.988827</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>146594.112150</td>\n",
       "      <td>590000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>1.0</td>\n",
       "      <td>145806.888889</td>\n",
       "      <td>920000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>59000.0</td>\n",
       "      <td>142923.076923</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             min_salary    mean_salary  max_salary\n",
       "state                                                             \n",
       "Michigan, Texas, Washington    340000.0  340000.000000    340000.0\n",
       "Florida                         28800.0  210711.000000   2600000.0\n",
       "California, Oregon             200000.0  200000.000000    200000.0\n",
       "California, Colorado           176000.0  176000.000000    176000.0\n",
       "Delaware                       169000.0  169000.000000    169000.0\n",
       "Connecticut                     68000.0  161610.000000    270000.0\n",
       "California                          0.0  153286.988827    520000.0\n",
       "New York                        14000.0  146594.112150    590000.0\n",
       "Wisconsin                           1.0  145806.888889    920000.0\n",
       "District of Columbia            59000.0  142923.076923    200000.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "\n",
    "state_salary_stats = df_salary_usd.groupby('state')['salary'].agg(min_salary='min', mean_salary='mean', max_salary='max')\n",
    "\n",
    "state_salary_stats = state_salary_stats.sort_values(by='mean_salary', ascending=False)\n",
    "\n",
    "state_salary_stats.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn‚Äôt numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix it.\n",
    "\n",
    "\n",
    "df_salary_tech['salary'] = (df_salary_usd['salary'].astype(str).str.replace(',', ''))       \n",
    "\n",
    "df_salary_tech['salary'] = pd.to_numeric(df_salary_usd['salary'], errors='coerce')\n",
    "\n",
    "df_salary_tech.dropna(subset=['salary'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Michigan, Texas, Washington</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>340000.000000</td>\n",
       "      <td>340000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>28800.0</td>\n",
       "      <td>210711.000000</td>\n",
       "      <td>2600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Oregon</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Colorado</th>\n",
       "      <td>176000.0</td>\n",
       "      <td>176000.000000</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>169000.0</td>\n",
       "      <td>169000.000000</td>\n",
       "      <td>169000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>161610.000000</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>153286.988827</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>146594.112150</td>\n",
       "      <td>590000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>1.0</td>\n",
       "      <td>145806.888889</td>\n",
       "      <td>920000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>59000.0</td>\n",
       "      <td>142923.076923</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  min           mean        max\n",
       "state                                                          \n",
       "Michigan, Texas, Washington  340000.0  340000.000000   340000.0\n",
       "Florida                       28800.0  210711.000000  2600000.0\n",
       "California, Oregon           200000.0  200000.000000   200000.0\n",
       "California, Colorado         176000.0  176000.000000   176000.0\n",
       "Delaware                     169000.0  169000.000000   169000.0\n",
       "Connecticut                   68000.0  161610.000000   270000.0\n",
       "California                        0.0  153286.988827   520000.0\n",
       "New York                      14000.0  146594.112150   590000.0\n",
       "Wisconsin                         1.0  145806.888889   920000.0\n",
       "District of Columbia          59000.0  142923.076923   200000.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it again. Yeah!\n",
    "\n",
    "salary_summary_by_state = df_salary_tech.groupby('state')['salary'].agg(['min', 'mean', 'max'])\n",
    "\n",
    "# Sort by the mean salary in descending order\n",
    "salary_summary_by_state_sorted = salary_summary_by_state.sort_values(by='mean', ascending=False)\n",
    "\n",
    "salary_summary_by_state_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let‚Äôs narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Michigan, Texas, Washington</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>340000.000000</td>\n",
       "      <td>340000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Oregon</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Colorado</th>\n",
       "      <td>176000.0</td>\n",
       "      <td>176000.000000</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>169000.0</td>\n",
       "      <td>169000.000000</td>\n",
       "      <td>169000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>161610.000000</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>153754.893258</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>146594.112150</td>\n",
       "      <td>590000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>1.0</td>\n",
       "      <td>145806.888889</td>\n",
       "      <td>920000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>59000.0</td>\n",
       "      <td>142923.076923</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>52000.0</td>\n",
       "      <td>138000.000000</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  min           mean       max\n",
       "state                                                         \n",
       "Michigan, Texas, Washington  340000.0  340000.000000  340000.0\n",
       "California, Oregon           200000.0  200000.000000  200000.0\n",
       "California, Colorado         176000.0  176000.000000  176000.0\n",
       "Delaware                     169000.0  169000.000000  169000.0\n",
       "Connecticut                   68000.0  161610.000000  270000.0\n",
       "California                        0.0  153754.893258  520000.0\n",
       "New York                      14000.0  146594.112150  590000.0\n",
       "Wisconsin                         1.0  145806.888889  920000.0\n",
       "District of Columbia          59000.0  142923.076923  200000.0\n",
       "Alabama                       52000.0  138000.000000  350000.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "\n",
    "df_salary_tech['timestamp'] = pd.to_datetime(df_salary_tech['timestamp'])\n",
    "\n",
    "# filter 4 2021-23 using .dt \n",
    "df_recent = df_salary_tech[df_salary_tech['timestamp'].dt.year.isin([2021, 2022, 2023])].copy()\n",
    "\n",
    "# new summary\n",
    "recent_summary = df_recent.groupby('state')['salary'].agg(['min', 'mean', 'max']).sort_values(by='mean', ascending=False)\n",
    "\n",
    "recent_summary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you‚Äôve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let‚Äôs back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum‚Äïsay 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you‚Äïlike say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* üòú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
